{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import copy\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from utils.funcs import *\n",
    "from utils.vec import generate_vector\n",
    "from model import DASTNet, Domain_classifier_DG\n",
    "from PaperCrawlerUtil.common_util import *\n",
    "from PaperCrawlerUtil.research_util import *\n",
    "import ast\n",
    "\n",
    "basic_config(logs_style=LOG_STYLE_ALL)\n",
    "\n",
    "\n",
    "def arg_parse(parser):\n",
    "    parser.add_argument('--dataset', type=str, default='8', help='dataset')\n",
    "    parser.add_argument('--seed', type=int, default=0, help='seed')\n",
    "    parser.add_argument('--division_seed', type=int, default=0, help='division_seed')\n",
    "    parser.add_argument('--model', type=str, default='DASTNet', help='model')\n",
    "    parser.add_argument('--labelrate', type=float, default=23, help='percent')\n",
    "    parser.add_argument('--patience', type=int, default=200, help='patience')\n",
    "    parser.add_argument(\"--hidden_dim\", type=int, default=64)\n",
    "    parser.add_argument(\"--vec_dim\", type=int, default=64)\n",
    "    parser.add_argument(\"--enc_dim\", type=int, default=64)\n",
    "    parser.add_argument(\"--walk_length\", \"--wl\", type=int, default=8)\n",
    "    parser.add_argument(\"--num_walks\", type=int, default=200)\n",
    "    parser.add_argument(\"--theta\", type=float, default=1)\n",
    "    parser.add_argument(\"--p\", type=float, default=1)\n",
    "    parser.add_argument(\"--q\", type=float, default=1)\n",
    "    parser.add_argument(\"--learning_rate\", \"--lr\", type=float, default=1e-4)\n",
    "    parser.add_argument(\"--epoch\", type=int, default=40)\n",
    "    parser.add_argument('--device', type=int, default=0, help='CUDA Device')\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=64)\n",
    "    parser.add_argument(\"--seq_len\", type=int, default=6)\n",
    "    parser.add_argument(\"--pre_len\", type=int, default=1)\n",
    "    parser.add_argument(\"--split_ratio\", type=float, default=0.7)\n",
    "    parser.add_argument(\"--alpha\", type=float, default=0.1)\n",
    "    parser.add_argument(\"--beta\", type=float, default=0.2)\n",
    "    parser.add_argument(\"--normalize\", type=bool, default=True)\n",
    "    parser.add_argument('--val', action='store_true', default=False, help='eval')\n",
    "    parser.add_argument('--test', action='store_true', default=False, help='test')\n",
    "    parser.add_argument('--train', action='store_true', default=False, help='train')\n",
    "    parser.add_argument('--etype', type=str, default=\"gin\", choices=[\"gin\"], help='feature type')\n",
    "    parser.add_argument('--dataname', type=str, default='Bike', help='Within [Bike, Taxi]')\n",
    "    parser.add_argument('--datatype', type=str, default='pickup', help='Within [pickup, dropoff]')\n",
    "    parser.add_argument('--data_amount', type=int, default=3, help='0: full data, 30/7/3 correspond to days of data')\n",
    "    parser.add_argument('--need_third', type=int, default=0)\n",
    "    parser.add_argument(\"--c\", type=str, default=\"default\", help=\"research record\")\n",
    "    parser.add_argument(\"--machine_code\", type=str, default=\"my-1060\", help=\"code of machine\")\n",
    "    parser.add_argument(\"--need_remark\", type=int, default=0)\n",
    "    parser.add_argument(\"--fine_epoch\", type=int, default=500)\n",
    "    parser.add_argument(\"--need_road\", type=bool, default=True)\n",
    "    parser.add_argument(\"--cut_data\", type=int, default=3312)\n",
    "    parser.add_argument(\"--normal\", type=int, default=2)\n",
    "    return parser.parse_args(args=[])\n",
    "\n",
    "\n",
    "def select_mask(a):\n",
    "    if a == 420:\n",
    "        return dcmask\n",
    "    elif a == 476:\n",
    "        return chimask\n",
    "    elif a == 460:\n",
    "        return nymask\n",
    "\n",
    "\n",
    "def train(dur, model, optimizer, total_step, start_step):\n",
    "    t0 = time.time()\n",
    "    train_mae, val_mae, train_rmse, val_rmse, train_acc = list(), list(), list(), list(), list()\n",
    "    train_correct = 0\n",
    "\n",
    "    model.train()\n",
    "    if type == 'pretrain':\n",
    "        domain_classifier.train()\n",
    "\n",
    "    for i, (feat, label) in enumerate(train_dataloader.get_iterator()):\n",
    "        mask = select_mask(feat.shape[2])\n",
    "        Reverse = False\n",
    "        if i > 0:\n",
    "            if train_acc[-1] > 0.333333:\n",
    "                Reverse = True\n",
    "        p = float(i + start_step) / total_step\n",
    "        constant = 2. / (1. + np.exp(-10 * p)) - 1\n",
    "\n",
    "        feat = torch.FloatTensor(feat).to(device)\n",
    "        label = torch.FloatTensor(label).to(device)\n",
    "        if torch.sum(scaler.inverse_transform(label)) <= 0.001:\n",
    "            continue\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        if args.model not in ['DCRNN', 'STGCN', 'HA']:\n",
    "            if type == 'pretrain':\n",
    "                pred, shared_pems04_feat, shared_pems07_feat, shared_pems08_feat = model(vec_pems04, vec_pems07,\n",
    "                                                                                         vec_pems08, feat, False,\n",
    "                                                                                         args.need_road)\n",
    "            elif type == 'fine-tune':\n",
    "                pred = model(vec_pems04, vec_pems07, vec_pems08, feat, False, args.need_road)\n",
    "\n",
    "            pred = pred.transpose(1, 2).reshape((-1, feat.size(2)))\n",
    "            label = label.reshape((-1, label.size(2)))\n",
    "\n",
    "            if type == 'pretrain':\n",
    "                pems04_pred = domain_classifier(shared_pems04_feat, constant, Reverse)\n",
    "                pems07_pred = domain_classifier(shared_pems07_feat, constant, Reverse)\n",
    "                pems08_pred = domain_classifier(shared_pems08_feat, constant, Reverse)\n",
    "\n",
    "                pems04_label = 0 * torch.ones(pems04_pred.shape[0]).long().to(device)\n",
    "                pems07_label = 1 * torch.ones(pems07_pred.shape[0]).long().to(device)\n",
    "                pems08_label = 2 * torch.ones(pems08_pred.shape[0]).long().to(device)\n",
    "\n",
    "                pems04_pred_label = pems04_pred.max(1, keepdim=True)[1]\n",
    "                pems04_correct = pems04_pred_label.eq(pems04_label.view_as(pems04_pred_label)).sum()\n",
    "                pems07_pred_label = pems07_pred.max(1, keepdim=True)[1]\n",
    "                pems07_correct = pems07_pred_label.eq(pems07_label.view_as(pems07_pred_label)).sum()\n",
    "                pems08_pred_label = pems08_pred.max(1, keepdim=True)[1]\n",
    "                pems08_correct = pems08_pred_label.eq(pems08_label.view_as(pems08_pred_label)).sum()\n",
    "\n",
    "                pems04_loss = domain_criterion(pems04_pred, pems04_label)\n",
    "                pems07_loss = domain_criterion(pems07_pred, pems07_label)\n",
    "                pems08_loss = domain_criterion(pems08_pred, pems08_label)\n",
    "\n",
    "                domain_loss = pems04_loss + pems07_loss + pems08_loss\n",
    "\n",
    "        if type == 'pretrain':\n",
    "            train_correct = pems04_correct + pems08_correct\n",
    "\n",
    "        mae_train, rmse_train, mape_train = masked_loss(scaler.inverse_transform(pred), scaler.inverse_transform(label),\n",
    "                                                        maskp=mask, maxs=maxs, mins=mins)\n",
    "\n",
    "        if type == 'pretrain':\n",
    "            if i == 1:\n",
    "                log(mae_train, domain_loss)\n",
    "            loss = mae_train + args.beta * (args.theta * domain_loss)\n",
    "        elif type == 'fine-tune':\n",
    "            loss = mae_train\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_mae.append(mae_train.item())\n",
    "        train_rmse.append(rmse_train.item())\n",
    "\n",
    "        if type == 'pretrain':\n",
    "            train_acc.append(train_correct.item() / 855)\n",
    "        elif type == 'fine-tune':\n",
    "            train_acc.append(0)\n",
    "\n",
    "    if type == 'pretrain':\n",
    "        domain_classifier.eval()\n",
    "    model.eval()\n",
    "\n",
    "    for i, (feat, label) in enumerate(val_dataloader.get_iterator()):\n",
    "        mask = select_mask(feat.shape[2])\n",
    "        feat = torch.FloatTensor(feat).to(device)\n",
    "        label = torch.FloatTensor(label).to(device)\n",
    "        if torch.sum(scaler.inverse_transform(label)) <= 0.001:\n",
    "            continue\n",
    "        pred = model(vec_pems04, vec_pems07, vec_pems08, feat, True, args.need_road)\n",
    "        pred = pred.transpose(1, 2).reshape((-1, feat.size(2)))\n",
    "        label = label.reshape((-1, label.size(2)))\n",
    "        mae_val, rmse_val, mape_val = masked_loss(scaler.inverse_transform(pred), scaler.inverse_transform(label),\n",
    "                                                  maskp=mask, maxs=maxs, mins=mins)\n",
    "        mae_val = mae_val * (maxs - mins)\n",
    "        rmse_val = rmse_val * (maxs - mins)\n",
    "\n",
    "        val_mae.append(mae_val.item())\n",
    "        val_rmse.append(rmse_val.item())\n",
    "\n",
    "    test_mae, test_rmse, test_mape = test()\n",
    "    dur.append(time.time() - t0)\n",
    "    return np.mean(train_mae), np.mean(train_rmse), np.mean(val_mae), np.mean(\n",
    "        val_rmse), test_mae, test_rmse, test_mape, np.mean(train_acc)\n",
    "\n",
    "\n",
    "def test():\n",
    "    if type == 'pretrain':\n",
    "        domain_classifier.eval()\n",
    "    model.eval()\n",
    "\n",
    "    test_mape, test_rmse, test_mae = list(), list(), list()\n",
    "\n",
    "    for i, (feat, label) in enumerate(test_dataloader.get_iterator()):\n",
    "        feat = torch.FloatTensor(feat).to(device)\n",
    "        label = torch.FloatTensor(label).to(device)\n",
    "        mask = select_mask(feat.shape[2])\n",
    "        if torch.sum(scaler.inverse_transform(label)) <= 0.001:\n",
    "            continue\n",
    "\n",
    "        pred = model(vec_pems04, vec_pems07, vec_pems08, feat, True, args.need_road)\n",
    "        pred = pred.transpose(1, 2).reshape((-1, feat.size(2)))\n",
    "        label = label.reshape((-1, label.size(2)))\n",
    "        mae_test, rmse_test, mape_test = masked_loss(scaler.inverse_transform(pred), scaler.inverse_transform(label),maskp=mask, maxs=maxs, mins=mins)\n",
    "        mae_test, rmse_test, mape_test = masked_loss0(scaler.inverse_transform(pred), scaler.inverse_transform(label))\n",
    "        # mae_test, rmse_test, mape_test = masked_loss2(scaler.inverse_transform(pred), scaler.inverse_transform(label),\n",
    "        #                                              maskp=mask, maxs=maxs, mins=mins)\n",
    "        mae_test = mae_test\n",
    "        rmse_test = rmse_test\n",
    "        mape_test = mape_test\n",
    "        test_mae.append(mae_test.item())\n",
    "        test_rmse.append(rmse_test.item())\n",
    "        test_mape.append(mape_test.item())\n",
    "\n",
    "    test_rmse = np.mean(test_rmse)\n",
    "    # test_rmse = np.sqrt(np.mean(test_rmse))\n",
    "    test_mae = np.mean(test_mae)\n",
    "    test_mape = np.mean(test_mape)\n",
    "\n",
    "    return test_mae, test_rmse, test_mape\n",
    "\n",
    "\n",
    "def model_train(args, model, optimizer):\n",
    "    dur = []\n",
    "    epoch = 1\n",
    "    best = 999999999999999\n",
    "    acc = list()\n",
    "\n",
    "    step_per_epoch = train_dataloader.get_num_batch()\n",
    "    total_step = 200 * step_per_epoch\n",
    "\n",
    "    while epoch <= args.epoch:\n",
    "        start_step = epoch * step_per_epoch\n",
    "        if type == 'fine-tune' and epoch > 1000:\n",
    "            args.val = True\n",
    "        mae_train, rmse_train, mae_val, rmse_val, mae_test, rmse_test, mape_test, train_acc = train(dur, model,\n",
    "                                                                                                    optimizer,\n",
    "                                                                                                    total_step,\n",
    "                                                                                                    start_step)\n",
    "        log(f'Epoch {epoch} | acc_train: {train_acc: .4f} | mae_train: {mae_train: .4f} | rmse_train: {rmse_train: .4f} | mae_val: {mae_val: .4f} | rmse_val: {rmse_val: .4f} | mae_test: {mae_test: .4f} | rmse_test: {rmse_test: .4f} | mape_test: {mape_test: .4f} | Time(s) {dur[-1]: .4f}')\n",
    "        epoch += 1\n",
    "        acc.append(train_acc)\n",
    "        if mae_val <= best:\n",
    "            if type == 'fine-tune' and mae_val > 0.001:\n",
    "                best = mae_val\n",
    "                state = dict([('model', copy.deepcopy(model.state_dict())),\n",
    "                              ('optim', copy.deepcopy(optimizer.state_dict())),\n",
    "                              ('domain_classifier', copy.deepcopy(domain_classifier.state_dict()))])\n",
    "                cnt = 0\n",
    "            elif type == 'pretrain':\n",
    "                best = mae_val\n",
    "                state = dict([('model', copy.deepcopy(model.state_dict())),\n",
    "                              ('optim', copy.deepcopy(optimizer.state_dict())),\n",
    "                              ('domain_classifier', copy.deepcopy(domain_classifier.state_dict()))])\n",
    "                cnt = 0\n",
    "        else:\n",
    "            cnt += 1\n",
    "        if cnt == args.patience or epoch > args.epoch:\n",
    "            print(f'Stop!!')\n",
    "            print(f'Avg acc: {np.mean(acc)}')\n",
    "            break\n",
    "    print(\"Optimization Finished!\")\n",
    "    return state\n",
    "\n",
    "\n",
    "args = arg_parse(argparse.ArgumentParser())\n",
    "if args.normal == \"2\":\n",
    "    class StandardScaler:\n",
    "        \"\"\"\n",
    "        Standard the input\n",
    "        \"\"\"\n",
    "\n",
    "        def __init__(self, mean, std):\n",
    "            self.mean = mean\n",
    "            self.std = std\n",
    "\n",
    "        def transform(self, data):\n",
    "            return (data - self.mean) / self.std\n",
    "\n",
    "        def inverse_transform(self, data):\n",
    "            return (data * self.std) + self.mean\n",
    "\n",
    "device = torch.device(\"cuda:\" + str(args.device) if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'device: {device}')\n",
    "if args.c != \"default\":\n",
    "    c = ast.literal_eval(args.c)\n",
    "    record = ResearchRecord(**c)\n",
    "    record_id = record.insert(__file__, get_timestamp(), args.__str__())\n",
    "torch.manual_seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "\n",
    "if args.labelrate > 100:\n",
    "    args.labelrate = 100\n",
    "\n",
    "adj_pems04, adj_pems07, adj_pems08 = load_all_adj(device)\n",
    "vec_pems04 = vec_pems07 = vec_pems08 = None, None, None\n",
    "dc = np.load(\"./data/DC/{}DC_{}.npy\".format(args.dataname, args.datatype))\n",
    "dc, maxs, mins = min_max_normalize(dc)\n",
    "print(maxs, mins)\n",
    "if args.normal != \"1\":\n",
    "    maxs = 2\n",
    "    mins = 1\n",
    "\n",
    "dcmask = dc.sum(0) > 0\n",
    "\n",
    "chi = np.load(\"./data/CHI/{}CHI_{}.npy\".format(args.dataname, args.datatype))\n",
    "chi = min_max_normalize(chi)[0]\n",
    "chimask = chi.sum(0) > 0\n",
    "\n",
    "ny = np.load(\"./data/NY/{}NY_{}.npy\".format(args.dataname, args.datatype))\n",
    "ny = min_max_normalize(ny)[0]\n",
    "nymask = ny.sum(0) > 0\n",
    "\n",
    "cur_dir = os.getcwd()\n",
    "if cur_dir[-2:] == 'sh':\n",
    "    cur_dir = cur_dir[:-2]\n",
    "\n",
    "pems04_emb_path = os.path.join('{}'.format(cur_dir), 'embeddings', 'node2vec', 'pems04',\n",
    "                               '{}{}_vecdim.pkl'.format(args.vec_dim, args.datatype))\n",
    "pems07_emb_path = os.path.join('{}'.format(cur_dir), 'embeddings', 'node2vec', 'pems07',\n",
    "                               '{}{}_vecdim.pkl'.format(args.vec_dim, args.datatype))\n",
    "pems08_emb_path = os.path.join('{}'.format(cur_dir), 'embeddings', 'node2vec', 'pems08',\n",
    "                               '{}{}_vecdim.pkl'.format(args.vec_dim, args.datatype))\n",
    "\n",
    "for i in [pems04_emb_path, pems07_emb_path, pems08_emb_path]:\n",
    "    a = i.split(\"/\")\n",
    "    b = []\n",
    "    for i in a:\n",
    "        if \"pkl\" in i:\n",
    "            continue\n",
    "        else:\n",
    "            b.append(i)\n",
    "    local_path_generate(folder_name=\"/\".join(b), create_folder_only=True)\n",
    "\n",
    "if os.path.exists(pems04_emb_path):\n",
    "    print(f'Loading pems04 embedding...')\n",
    "    vec_pems04 = torch.load(pems04_emb_path, map_location='cpu')\n",
    "    vec_pems04 = vec_pems04.to(device)\n",
    "else:\n",
    "    print(f'Generating pems04 embedding...')\n",
    "    args.dataset = '4'\n",
    "    vec_pems04, _ = generate_vector(adj_pems04.cpu().numpy(), args)\n",
    "    vec_pems04 = vec_pems04.to(device)\n",
    "    print(f'Saving pems04 embedding...')\n",
    "    torch.save(vec_pems04.cpu(), pems04_emb_path)\n",
    "\n",
    "if os.path.exists(pems07_emb_path):\n",
    "    print(f'Loading pems07 embedding...')\n",
    "    vec_pems07 = torch.load(pems07_emb_path, map_location='cpu')\n",
    "    vec_pems07 = vec_pems07.to(device)\n",
    "else:\n",
    "    print(f'Generating pems07 embedding...')\n",
    "    args.dataset = '7'\n",
    "    vec_pems07, _ = generate_vector(adj_pems07.cpu().numpy(), args)\n",
    "    vec_pems07 = vec_pems07.to(device)\n",
    "    print(f'Saving pems07 embedding...')\n",
    "    torch.save(vec_pems07.cpu(), pems07_emb_path)\n",
    "\n",
    "if os.path.exists(pems08_emb_path):\n",
    "    print(f'Loading pems08 embedding...')\n",
    "    vec_pems08 = torch.load(pems08_emb_path, map_location='cpu')\n",
    "    vec_pems08 = vec_pems08.to(device)\n",
    "else:\n",
    "    print(f'Generating pems08 embedding...')\n",
    "    args.dataset = '8'\n",
    "    vec_pems08, _ = generate_vector(adj_pems08.cpu().numpy(), args)\n",
    "    vec_pems08 = vec_pems08.to(device)\n",
    "    print(f'Saving pems08 embedding...')\n",
    "    torch.save(vec_pems08.cpu(), pems08_emb_path)\n",
    "\n",
    "print(f'Successfully load embeddings, 4: {vec_pems04.shape}, 7: {vec_pems07.shape}, 8: {vec_pems08.shape}')\n",
    "\n",
    "domain_criterion = torch.nn.NLLLoss()\n",
    "domain_classifier = Domain_classifier_DG(num_class=3, encode_dim=args.enc_dim)\n",
    "\n",
    "domain_classifier = domain_classifier.to(device)\n",
    "state = g = None, None\n",
    "\n",
    "batch_seen = 0\n",
    "cur_dir = os.getcwd()\n",
    "if cur_dir[-2:] == 'sh':\n",
    "    cur_dir = cur_dir[:-2]\n",
    "assert args.model in [\"DASTNet\"]\n",
    "\n",
    "bak_epoch = args.epoch\n",
    "bak_val = args.val\n",
    "bak_test = args.test\n",
    "type = 'pretrain'\n",
    "pretrain_model_path = os.path.join('{}'.format(cur_dir), 'pretrained', 'transfer_models',\n",
    "                                   '{}'.format(args.dataset), '{}_prelen'.format(args.pre_len),\n",
    "                                   'flow_model4_{}_epoch_{}{}{}{}{}{}{}{}.pkl'.format(args.model, args.epoch,\n",
    "                                                                                      args.dataname,\n",
    "                                                                                      args.datatype,\n",
    "                                                                                      str(args.learning_rate),\n",
    "                                                                                      str(args.batch_size),\n",
    "                                                                                      str(args.split_ratio),\n",
    "                                                                                      args.seq_len,\n",
    "                                                                                      args.pre_len))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class VGRU_FEAT(nn.Module):\n",
    "    def __init__(self, hidden_dim: int, output_dim: int, encode_dim: int):\n",
    "        super(VGRU_FEAT, self).__init__()\n",
    "        self._encode_dim = encode_dim\n",
    "        self._hidden_dim = hidden_dim\n",
    "        self._output_dim = output_dim\n",
    "        self.l1 = nn.Linear(6, 32)\n",
    "        self.l2 = nn.Linear(32, 64)\n",
    "\n",
    "    def forward(self, inputs, feat, need_road=True):\n",
    "        batch_size, seq_len, num_nodes = inputs.shape\n",
    "        inputs = inputs.transpose(1, 2)\n",
    "        t = self.l1(inputs)\n",
    "        t = self.l2(t)\n",
    "        return t\n",
    "\n",
    "\n",
    "\n",
    "class Extractor_N2V(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim: int, encode_dim, device, batch_size, etype):\n",
    "        super(Extractor_N2V, self).__init__()\n",
    "        self.device = device\n",
    "        self.batch_size = batch_size\n",
    "        self.etype = etype\n",
    "        self._input_dim = input_dim\n",
    "        self._encode_dim = encode_dim\n",
    "        self._hidden_dim = hidden_dim\n",
    "        self.adj_encoderlayer1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.adj_encoderlayer2 = nn.Linear(hidden_dim, encode_dim)\n",
    "        self.batch_norm = nn.BatchNorm1d(encode_dim)\n",
    "        self.eps1 = nn.Parameter(torch.tensor([1.0]))\n",
    "\n",
    "    def forward(self, h, adj):\n",
    "        h = self.adj_encoderlayer1(h.float())\n",
    "        h = self.batch_norm(h.float())\n",
    "        h = self.adj_encoderlayer2(h.float())\n",
    "\n",
    "        return h\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class DASTNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, encode_dim, device, batch_size, etype, pre_len, dataset, ft_dataset,\n",
    "                 adj_pems04, adj_pems07, adj_pems08):\n",
    "        super(DASTNet, self).__init__()\n",
    "        self.dataset = dataset\n",
    "        self.finetune_dataset = ft_dataset\n",
    "        self.pems04_adj = adj_pems04\n",
    "        self.pems07_adj = adj_pems07\n",
    "        self.pems08_adj = adj_pems08\n",
    "        self.batch_size = batch_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.encode_dim = encode_dim\n",
    "        self.device = device\n",
    "\n",
    "        self.pems04_featExtractor = Extractor_N2V(input_dim, hidden_dim, encode_dim, device, batch_size, etype).to(device)\n",
    "        self.pems07_featExtractor = Extractor_N2V(input_dim, hidden_dim, encode_dim, device, batch_size, etype).to(device)\n",
    "        self.pems08_featExtractor = Extractor_N2V(input_dim, hidden_dim, encode_dim, device, batch_size, etype).to(device)\n",
    "        self.shared_pems04_featExtractor = Extractor_N2V(input_dim, hidden_dim, encode_dim, device, batch_size, etype).to(device)\n",
    "        self.shared_pems07_featExtractor = Extractor_N2V(input_dim, hidden_dim, encode_dim, device, batch_size, etype).to(device)\n",
    "        self.shared_pems08_featExtractor = Extractor_N2V(input_dim, hidden_dim, encode_dim, device, batch_size, etype).to(device)\n",
    "\n",
    "        self.speed_predictor = VGRU_FEAT(hidden_dim=hidden_dim, output_dim=pre_len, encode_dim=encode_dim).to(device)\n",
    "        self.pems04_linear = nn.Linear(hidden_dim, pre_len, )\n",
    "        self.pems07_linear = nn.Linear(hidden_dim, pre_len, )\n",
    "        self.pems08_linear = nn.Linear(hidden_dim, pre_len, )\n",
    "\n",
    "        self.weight_feat_private = nn.Parameter(torch.tensor([1.0]).to(self.device))\n",
    "        self.weight_feat_shared = nn.Parameter(torch.tensor([0.0]).to(self.device))\n",
    "        self.private_pems04_linear = nn.Linear(hidden_dim, hidden_dim, )\n",
    "        self.private_pems07_linear = nn.Linear(hidden_dim, hidden_dim, )\n",
    "        self.private_pems08_linear = nn.Linear(hidden_dim, hidden_dim, )\n",
    "        self.shared_pems04_linear = nn.Linear(hidden_dim, hidden_dim, )\n",
    "        self.shared_pems07_linear = nn.Linear(hidden_dim, hidden_dim, )\n",
    "        self.shared_pems08_linear = nn.Linear(hidden_dim, hidden_dim, )\n",
    "        self.combine_pems04_linear = nn.Linear(hidden_dim, hidden_dim, )\n",
    "        self.combine_pems07_linear = nn.Linear(hidden_dim, hidden_dim, )\n",
    "        self.combine_pems08_linear = nn.Linear(hidden_dim, hidden_dim, )\n",
    "\n",
    "    def forward(self, vec_pems04, vec_pems07, vec_pems08, feat, eval, need_road=True, flag=True):\n",
    "        if self.dataset != self.finetune_dataset or flag == False:\n",
    "            if not eval:\n",
    "                shared_pems04_feat = self.shared_pems04_featExtractor(vec_pems04, self.pems04_adj).to(self.device)\n",
    "                shared_pems07_feat = self.shared_pems07_featExtractor(vec_pems07, self.pems07_adj).to(self.device)\n",
    "                shared_pems08_feat = self.shared_pems08_featExtractor(vec_pems08, self.pems08_adj).to(self.device)\n",
    "            else:\n",
    "                if self.dataset == '4' or self.dataset == 'ny':\n",
    "                    shared_pems04_feat = self.shared_pems04_featExtractor(vec_pems04, self.pems04_adj).to(self.device)\n",
    "                elif self.dataset == '7' or self.dataset == 'chi':\n",
    "                    shared_pems07_feat = self.shared_pems07_featExtractor(vec_pems07, self.pems07_adj).to(self.device)\n",
    "                elif self.dataset == '8' or self.dataset == 'dc':\n",
    "                    shared_pems08_feat = self.shared_pems08_featExtractor(vec_pems08, self.pems08_adj).to(self.device)\n",
    "            if self.dataset == '4' or self.dataset == 'ny':\n",
    "                h_pems04 = shared_pems04_feat.expand(self.batch_size, self.pems04_adj.shape[0], self.encode_dim)\n",
    "                pred = self.speed_predictor(feat, h_pems04, need_road)\n",
    "                pred = self.pems04_linear(pred)\n",
    "                pred = pred.reshape((self.batch_size, self.pems04_adj.shape[0], -1))\n",
    "            elif self.dataset == '7' or self.dataset == 'chi':\n",
    "                h_pems07 = shared_pems07_feat.expand(self.batch_size, self.pems07_adj.shape[0], self.encode_dim)\n",
    "                pred = self.speed_predictor(feat, h_pems07, need_road)\n",
    "                pred = self.pems07_linear(pred)\n",
    "                pred = pred.reshape((self.batch_size, self.pems07_adj.shape[0], -1))\n",
    "            elif self.dataset == '8' or self.dataset == 'dc':\n",
    "                h_pems08 = shared_pems08_feat.expand(self.batch_size, self.pems08_adj.shape[0], self.encode_dim)\n",
    "                pred = self.speed_predictor(feat, h_pems08, need_road)\n",
    "                pred = self.pems08_linear(pred)\n",
    "                pred = pred.reshape((self.batch_size, self.pems08_adj.shape[0], -1))\n",
    "\n",
    "            if not eval:\n",
    "                return pred, shared_pems04_feat, shared_pems07_feat, shared_pems08_feat\n",
    "            else:\n",
    "                return pred\n",
    "        else:\n",
    "            if self.dataset == '4' or self.dataset == 'ny':\n",
    "                shared_pems04_feat = self.shared_pems04_featExtractor(vec_pems04, self.pems04_adj).to(self.device)\n",
    "                pems04_feat = self.pems04_featExtractor(vec_pems04, self.pems04_adj).to(self.device)\n",
    "                pems04_feat = self.combine_pems04_linear(self.private_pems04_linear(pems04_feat) + self.shared_pems04_linear(shared_pems04_feat))\n",
    "                h_pems04 = pems04_feat.expand(self.batch_size, self.pems04_adj.shape[0], self.encode_dim)\n",
    "                pred = self.speed_predictor(feat, h_pems04, need_road)\n",
    "                pred = self.pems04_linear(pred)\n",
    "                pred = pred.reshape((self.batch_size, self.pems04_adj.shape[0], -1))\n",
    "            elif self.dataset == '7' or self.dataset == 'chi':\n",
    "                shared_pems07_feat = self.shared_pems07_featExtractor(vec_pems07, self.pems07_adj).to(self.device)\n",
    "                pems07_feat = self.pems07_featExtractor(vec_pems07, self.pems07_adj).to(self.device)\n",
    "                pems07_feat = self.combine_pems07_linear(self.private_pems07_linear(pems07_feat) + self.shared_pems07_linear(shared_pems07_feat))\n",
    "                h_pems07 = pems07_feat.expand(self.batch_size, self.pems07_adj.shape[0], self.encode_dim)\n",
    "                pred = self.speed_predictor(feat, h_pems07, need_road)\n",
    "                pred = self.pems07_linear(pred)\n",
    "                pred = pred.reshape((self.batch_size, self.pems07_adj.shape[0], -1))\n",
    "            elif self.dataset == '8' or self.dataset == 'dc':\n",
    "                shared_pems08_feat = self.shared_pems08_featExtractor(vec_pems08, self.pems08_adj).to(self.device)\n",
    "                pems08_feat = self.pems08_featExtractor(vec_pems08, self.pems08_adj).to(self.device)\n",
    "                pems08_feat = self.combine_pems08_linear(self.private_pems08_linear(pems08_feat) + self.shared_pems08_linear(shared_pems08_feat))\n",
    "                h_pems08 = pems08_feat.expand(self.batch_size, self.pems08_adj.shape[0], self.encode_dim)\n",
    "                pred = self.speed_predictor(feat, h_pems08, need_road)\n",
    "                pred = self.pems08_linear(pred)\n",
    "                pred = pred.reshape((self.batch_size, self.pems08_adj.shape[0], -1))\n",
    "\n",
    "            return pred\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 10:07:43   文件夹E:\\git-code\\DASTNet\\pretrained\\transfer_models\\8\\1_prelen存在 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model at E:\\git-code\\DASTNet\\pretrained\\transfer_models\\8\\1_prelen\\flow_model4_DASTNet_epoch_40Bikepickup0.0001640.761.pkl\n",
      "\n",
      "\n",
      "*******************************************************************************************\n",
      "dataset: 8, model: DASTNet, pre_len: 1, labelrate: 23, seed: 0\n",
      "*******************************************************************************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 10:07:43   0.31684923652604263 2.080296444738055 \n",
      "2023-05-01 10:07:44   Epoch 1 | acc_train:  0.0000 | mae_train:  2.0997 | rmse_train:  5.8922 | mae_val:  2.7027 | rmse_val:  7.3825 | mae_test:  5.1072 | rmse_test:  10.1652 | mape_test:  0.7296 | Time(s)  0.2294 \n",
      "2023-05-01 10:07:44   Epoch 2 | acc_train:  0.0000 | mae_train:  2.0899 | rmse_train:  5.8657 | mae_val:  2.6897 | rmse_val:  7.3463 | mae_test:  5.0683 | rmse_test:  10.1023 | mape_test:  0.7256 | Time(s)  0.2101 \n",
      "2023-05-01 10:07:44   Epoch 3 | acc_train:  0.0000 | mae_train:  2.0740 | rmse_train:  5.8217 | mae_val:  2.6725 | rmse_val:  7.2977 | mae_test:  5.0163 | rmse_test:  10.0186 | mape_test:  0.7206 | Time(s)  0.1705 \n",
      "2023-05-01 10:07:44   Epoch 4 | acc_train:  0.0000 | mae_train:  2.0542 | rmse_train:  5.7668 | mae_val:  2.6529 | rmse_val:  7.2413 | mae_test:  4.9575 | rmse_test:  9.9225 | mape_test:  0.7152 | Time(s)  0.1711 \n",
      "2023-05-01 10:07:44   Epoch 5 | acc_train:  0.0000 | mae_train:  2.0318 | rmse_train:  5.7050 | mae_val:  2.6321 | rmse_val:  7.1805 | mae_test:  4.8964 | rmse_test:  9.8223 | mape_test:  0.7097 | Time(s)  0.1571 \n",
      "2023-05-01 10:07:45   Epoch 6 | acc_train:  0.0000 | mae_train:  2.0080 | rmse_train:  5.6389 | mae_val:  2.6108 | rmse_val:  7.1173 | mae_test:  4.8339 | rmse_test:  9.7178 | mape_test:  0.7046 | Time(s)  0.1666 \n",
      "2023-05-01 10:07:45   Epoch 7 | acc_train:  0.0000 | mae_train:  1.9833 | rmse_train:  5.5703 | mae_val:  2.5895 | rmse_val:  7.0530 | mae_test:  4.7708 | rmse_test:  9.6119 | mape_test:  0.7001 | Time(s)  0.2145 \n",
      "2023-05-01 10:07:45   Epoch 8 | acc_train:  0.0000 | mae_train:  1.9580 | rmse_train:  5.5003 | mae_val:  2.5686 | rmse_val:  6.9885 | mae_test:  4.7094 | rmse_test:  9.5064 | mape_test:  0.6965 | Time(s)  0.1202 \n",
      "2023-05-01 10:07:45   Epoch 9 | acc_train:  0.0000 | mae_train:  1.9327 | rmse_train:  5.4295 | mae_val:  2.5485 | rmse_val:  6.9249 | mae_test:  4.6525 | rmse_test:  9.4052 | mape_test:  0.6937 | Time(s)  0.1250 \n",
      "2023-05-01 10:07:45   Epoch 10 | acc_train:  0.0000 | mae_train:  1.9085 | rmse_train:  5.3595 | mae_val:  2.5291 | rmse_val:  6.8628 | mae_test:  4.5978 | rmse_test:  9.3060 | mape_test:  0.6915 | Time(s)  0.1277 \n",
      "2023-05-01 10:07:46   Epoch 11 | acc_train:  0.0000 | mae_train:  1.8845 | rmse_train:  5.2902 | mae_val:  2.5104 | rmse_val:  6.8021 | mae_test:  4.5464 | rmse_test:  9.2109 | mape_test:  0.6899 | Time(s)  0.1236 \n",
      "2023-05-01 10:07:46   Epoch 12 | acc_train:  0.0000 | mae_train:  1.8609 | rmse_train:  5.2217 | mae_val:  2.4926 | rmse_val:  6.7431 | mae_test:  4.4978 | rmse_test:  9.1189 | mape_test:  0.6888 | Time(s)  0.1193 \n",
      "2023-05-01 10:07:46   Epoch 13 | acc_train:  0.0000 | mae_train:  1.8379 | rmse_train:  5.1542 | mae_val:  2.4756 | rmse_val:  6.6857 | mae_test:  4.4511 | rmse_test:  9.0294 | mape_test:  0.6883 | Time(s)  0.1223 \n",
      "2023-05-01 10:07:46   Epoch 14 | acc_train:  0.0000 | mae_train:  1.8152 | rmse_train:  5.0877 | mae_val:  2.4594 | rmse_val:  6.6298 | mae_test:  4.4071 | rmse_test:  8.9426 | mape_test:  0.6883 | Time(s)  0.1238 \n",
      "2023-05-01 10:07:46   Epoch 15 | acc_train:  0.0000 | mae_train:  1.7928 | rmse_train:  5.0219 | mae_val:  2.4438 | rmse_val:  6.5754 | mae_test:  4.3658 | rmse_test:  8.8590 | mape_test:  0.6887 | Time(s)  0.1227 \n",
      "2023-05-01 10:07:46   Epoch 16 | acc_train:  0.0000 | mae_train:  1.7706 | rmse_train:  4.9569 | mae_val:  2.4289 | rmse_val:  6.5224 | mae_test:  4.3264 | rmse_test:  8.7775 | mape_test:  0.6896 | Time(s)  0.1227 \n",
      "2023-05-01 10:07:46   Epoch 17 | acc_train:  0.0000 | mae_train:  1.7488 | rmse_train:  4.8927 | mae_val:  2.4148 | rmse_val:  6.4708 | mae_test:  4.2888 | rmse_test:  8.6986 | mape_test:  0.6910 | Time(s)  0.1252 \n",
      "2023-05-01 10:07:46   Epoch 18 | acc_train:  0.0000 | mae_train:  1.7271 | rmse_train:  4.8291 | mae_val:  2.4013 | rmse_val:  6.4206 | mae_test:  4.2537 | rmse_test:  8.6226 | mape_test:  0.6929 | Time(s)  0.1212 \n",
      "2023-05-01 10:07:47   Epoch 19 | acc_train:  0.0000 | mae_train:  1.7058 | rmse_train:  4.7663 | mae_val:  2.3883 | rmse_val:  6.3719 | mae_test:  4.2209 | rmse_test:  8.5489 | mape_test:  0.6951 | Time(s)  0.1333 \n",
      "2023-05-01 10:07:47   Epoch 20 | acc_train:  0.0000 | mae_train:  1.6847 | rmse_train:  4.7040 | mae_val:  2.3761 | rmse_val:  6.3249 | mae_test:  4.1902 | rmse_test:  8.4786 | mape_test:  0.6976 | Time(s)  0.1257 \n",
      "2023-05-01 10:07:47   Epoch 21 | acc_train:  0.0000 | mae_train:  1.6650 | rmse_train:  4.6434 | mae_val:  2.3645 | rmse_val:  6.2799 | mae_test:  4.1614 | rmse_test:  8.4113 | mape_test:  0.7004 | Time(s)  0.1327 \n",
      "2023-05-01 10:07:47   Epoch 22 | acc_train:  0.0000 | mae_train:  1.6456 | rmse_train:  4.5840 | mae_val:  2.3535 | rmse_val:  6.2365 | mae_test:  4.1342 | rmse_test:  8.3468 | mape_test:  0.7034 | Time(s)  0.1217 \n",
      "2023-05-01 10:07:47   Epoch 23 | acc_train:  0.0000 | mae_train:  1.6264 | rmse_train:  4.5255 | mae_val:  2.3432 | rmse_val:  6.1946 | mae_test:  4.1089 | rmse_test:  8.2850 | mape_test:  0.7067 | Time(s)  0.1237 \n",
      "2023-05-01 10:07:47   Epoch 24 | acc_train:  0.0000 | mae_train:  1.6079 | rmse_train:  4.4678 | mae_val:  2.3335 | rmse_val:  6.1544 | mae_test:  4.0855 | rmse_test:  8.2259 | mape_test:  0.7102 | Time(s)  0.1152 \n",
      "2023-05-01 10:07:47   Epoch 25 | acc_train:  0.0000 | mae_train:  1.5902 | rmse_train:  4.4118 | mae_val:  2.3244 | rmse_val:  6.1160 | mae_test:  4.0639 | rmse_test:  8.1699 | mape_test:  0.7139 | Time(s)  0.1287 \n",
      "2023-05-01 10:07:48   Epoch 26 | acc_train:  0.0000 | mae_train:  1.5730 | rmse_train:  4.3570 | mae_val:  2.3158 | rmse_val:  6.0791 | mae_test:  4.0435 | rmse_test:  8.1164 | mape_test:  0.7177 | Time(s)  0.1157 \n",
      "2023-05-01 10:07:48   Epoch 27 | acc_train:  0.0000 | mae_train:  1.5560 | rmse_train:  4.3033 | mae_val:  2.3077 | rmse_val:  6.0437 | mae_test:  4.0245 | rmse_test:  8.0653 | mape_test:  0.7217 | Time(s)  0.1226 \n",
      "2023-05-01 10:07:48   Epoch 28 | acc_train:  0.0000 | mae_train:  1.5392 | rmse_train:  4.2505 | mae_val:  2.3003 | rmse_val:  6.0095 | mae_test:  4.0068 | rmse_test:  8.0163 | mape_test:  0.7258 | Time(s)  0.1193 \n",
      "2023-05-01 10:07:48   Epoch 29 | acc_train:  0.0000 | mae_train:  1.5227 | rmse_train:  4.1984 | mae_val:  2.2932 | rmse_val:  5.9765 | mae_test:  3.9910 | rmse_test:  7.9706 | mape_test:  0.7300 | Time(s)  0.1446 \n",
      "2023-05-01 10:07:48   Epoch 30 | acc_train:  0.0000 | mae_train:  1.5064 | rmse_train:  4.1471 | mae_val:  2.2866 | rmse_val:  5.9449 | mae_test:  3.9758 | rmse_test:  7.9259 | mape_test:  0.7344 | Time(s)  0.1157 \n",
      "2023-05-01 10:07:48   Epoch 31 | acc_train:  0.0000 | mae_train:  1.4903 | rmse_train:  4.0966 | mae_val:  2.2804 | rmse_val:  5.9144 | mae_test:  3.9622 | rmse_test:  7.8831 | mape_test:  0.7390 | Time(s)  0.1258 \n",
      "2023-05-01 10:07:48   Epoch 32 | acc_train:  0.0000 | mae_train:  1.4743 | rmse_train:  4.0467 | mae_val:  2.2745 | rmse_val:  5.8850 | mae_test:  3.9504 | rmse_test:  7.8423 | mape_test:  0.7438 | Time(s)  0.1197 \n",
      "2023-05-01 10:07:49   Epoch 33 | acc_train:  0.0000 | mae_train:  1.4583 | rmse_train:  3.9974 | mae_val:  2.2690 | rmse_val:  5.8567 | mae_test:  3.9402 | rmse_test:  7.8033 | mape_test:  0.7488 | Time(s)  0.1326 \n",
      "2023-05-01 10:07:49   Epoch 34 | acc_train:  0.0000 | mae_train:  1.4424 | rmse_train:  3.9486 | mae_val:  2.2638 | rmse_val:  5.8294 | mae_test:  3.9311 | rmse_test:  7.7662 | mape_test:  0.7540 | Time(s)  0.1187 \n",
      "2023-05-01 10:07:49   Epoch 35 | acc_train:  0.0000 | mae_train:  1.4266 | rmse_train:  3.9003 | mae_val:  2.2590 | rmse_val:  5.8033 | mae_test:  3.9229 | rmse_test:  7.7309 | mape_test:  0.7592 | Time(s)  0.1282 \n",
      "2023-05-01 10:07:49   Epoch 36 | acc_train:  0.0000 | mae_train:  1.4109 | rmse_train:  3.8526 | mae_val:  2.2546 | rmse_val:  5.7783 | mae_test:  3.9159 | rmse_test:  7.6976 | mape_test:  0.7646 | Time(s)  0.1220 \n",
      "2023-05-01 10:07:49   Epoch 37 | acc_train:  0.0000 | mae_train:  1.3953 | rmse_train:  3.8055 | mae_val:  2.2504 | rmse_val:  5.7544 | mae_test:  3.9099 | rmse_test:  7.6660 | mape_test:  0.7702 | Time(s)  0.1219 \n",
      "2023-05-01 10:07:49   Epoch 38 | acc_train:  0.0000 | mae_train:  1.3797 | rmse_train:  3.7589 | mae_val:  2.2466 | rmse_val:  5.7315 | mae_test:  3.9047 | rmse_test:  7.6363 | mape_test:  0.7759 | Time(s)  0.1218 \n",
      "2023-05-01 10:07:49   Epoch 39 | acc_train:  0.0000 | mae_train:  1.3640 | rmse_train:  3.7128 | mae_val:  2.2431 | rmse_val:  5.7098 | mae_test:  3.9005 | rmse_test:  7.6085 | mape_test:  0.7817 | Time(s)  0.1297 \n",
      "2023-05-01 10:07:50   Epoch 40 | acc_train:  0.0000 | mae_train:  1.3485 | rmse_train:  3.6673 | mae_val:  2.2398 | rmse_val:  5.6891 | mae_test:  3.8972 | rmse_test:  7.5826 | mape_test:  0.7877 | Time(s)  0.1177 \n",
      "2023-05-01 10:07:50   Epoch 41 | acc_train:  0.0000 | mae_train:  1.3346 | rmse_train:  3.6224 | mae_val:  2.2369 | rmse_val:  5.6700 | mae_test:  3.8951 | rmse_test:  7.5591 | mape_test:  0.7936 | Time(s)  0.1292 \n",
      "2023-05-01 10:07:50   Epoch 42 | acc_train:  0.0000 | mae_train:  1.3213 | rmse_train:  3.5798 | mae_val:  2.2344 | rmse_val:  5.6526 | mae_test:  3.8940 | rmse_test:  7.5382 | mape_test:  0.7995 | Time(s)  0.1252 \n",
      "2023-05-01 10:07:50   Epoch 43 | acc_train:  0.0000 | mae_train:  1.3084 | rmse_train:  3.5389 | mae_val:  2.2322 | rmse_val:  5.6366 | mae_test:  3.8939 | rmse_test:  7.5193 | mape_test:  0.8054 | Time(s)  0.1258 \n",
      "2023-05-01 10:07:50   Epoch 44 | acc_train:  0.0000 | mae_train:  1.2966 | rmse_train:  3.4993 | mae_val:  2.2304 | rmse_val:  5.6223 | mae_test:  3.8969 | rmse_test:  7.5065 | mape_test:  0.8109 | Time(s)  0.1252 \n",
      "2023-05-01 10:07:50   Epoch 45 | acc_train:  0.0000 | mae_train:  1.2868 | rmse_train:  3.4631 | mae_val:  2.2288 | rmse_val:  5.6098 | mae_test:  3.8982 | rmse_test:  7.4925 | mape_test:  0.8164 | Time(s)  0.1277 \n",
      "2023-05-01 10:07:50   Epoch 46 | acc_train:  0.0000 | mae_train:  1.2777 | rmse_train:  3.4293 | mae_val:  2.2275 | rmse_val:  5.5986 | mae_test:  3.9000 | rmse_test:  7.4805 | mape_test:  0.8216 | Time(s)  0.1186 \n",
      "2023-05-01 10:07:51   Epoch 47 | acc_train:  0.0000 | mae_train:  1.2696 | rmse_train:  3.3980 | mae_val:  2.2265 | rmse_val:  5.5888 | mae_test:  3.9022 | rmse_test:  7.4701 | mape_test:  0.8267 | Time(s)  0.1286 \n",
      "2023-05-01 10:07:51   Epoch 48 | acc_train:  0.0000 | mae_train:  1.2619 | rmse_train:  3.3684 | mae_val:  2.2255 | rmse_val:  5.5798 | mae_test:  3.9049 | rmse_test:  7.4611 | mape_test:  0.8316 | Time(s)  0.1217 \n",
      "2023-05-01 10:07:51   Epoch 49 | acc_train:  0.0000 | mae_train:  1.2543 | rmse_train:  3.3401 | mae_val:  2.2248 | rmse_val:  5.5717 | mae_test:  3.9082 | rmse_test:  7.4533 | mape_test:  0.8364 | Time(s)  0.1206 \n",
      "2023-05-01 10:07:51   Epoch 50 | acc_train:  0.0000 | mae_train:  1.2469 | rmse_train:  3.3128 | mae_val:  2.2242 | rmse_val:  5.5642 | mae_test:  3.9119 | rmse_test:  7.4465 | mape_test:  0.8413 | Time(s)  0.1223 \n",
      "2023-05-01 10:07:51   Epoch 51 | acc_train:  0.0000 | mae_train:  1.2397 | rmse_train:  3.2861 | mae_val:  2.2237 | rmse_val:  5.5573 | mae_test:  3.9160 | rmse_test:  7.4407 | mape_test:  0.8461 | Time(s)  0.1232 \n",
      "2023-05-01 10:07:51   Epoch 52 | acc_train:  0.0000 | mae_train:  1.2325 | rmse_train:  3.2601 | mae_val:  2.2234 | rmse_val:  5.5509 | mae_test:  3.9204 | rmse_test:  7.4357 | mape_test:  0.8510 | Time(s)  0.1172 \n",
      "2023-05-01 10:07:51   Epoch 53 | acc_train:  0.0000 | mae_train:  1.2254 | rmse_train:  3.2347 | mae_val:  2.2232 | rmse_val:  5.5451 | mae_test:  3.9254 | rmse_test:  7.4319 | mape_test:  0.8558 | Time(s)  0.1266 \n",
      "2023-05-01 10:07:52   Epoch 54 | acc_train:  0.0000 | mae_train:  1.2184 | rmse_train:  3.2097 | mae_val:  2.2231 | rmse_val:  5.5399 | mae_test:  3.9303 | rmse_test:  7.4287 | mape_test:  0.8605 | Time(s)  0.1193 \n",
      "2023-05-01 10:07:52   Epoch 55 | acc_train:  0.0000 | mae_train:  1.2121 | rmse_train:  3.1861 | mae_val:  2.2231 | rmse_val:  5.5353 | mae_test:  3.9470 | rmse_test:  7.4429 | mape_test:  0.8644 | Time(s)  0.1346 \n",
      "2023-05-01 10:07:52   Epoch 56 | acc_train:  0.0000 | mae_train:  1.2060 | rmse_train:  3.1633 | mae_val:  2.2233 | rmse_val:  5.5312 | mae_test:  3.9524 | rmse_test:  7.4412 | mape_test:  0.8690 | Time(s)  0.1389 \n",
      "2023-05-01 10:07:52   Epoch 57 | acc_train:  0.0000 | mae_train:  1.2000 | rmse_train:  3.1413 | mae_val:  2.2235 | rmse_val:  5.5276 | mae_test:  3.9582 | rmse_test:  7.4401 | mape_test:  0.8736 | Time(s)  0.1626 \n",
      "2023-05-01 10:07:52   Epoch 58 | acc_train:  0.0000 | mae_train:  1.1940 | rmse_train:  3.1199 | mae_val:  2.2238 | rmse_val:  5.5243 | mae_test:  3.9641 | rmse_test:  7.4397 | mape_test:  0.8781 | Time(s)  0.1606 \n",
      "2023-05-01 10:07:52   Epoch 59 | acc_train:  0.0000 | mae_train:  1.1881 | rmse_train:  3.0990 | mae_val:  2.2241 | rmse_val:  5.5215 | mae_test:  3.9703 | rmse_test:  7.4399 | mape_test:  0.8826 | Time(s)  0.1227 \n",
      "2023-05-01 10:07:52   Epoch 60 | acc_train:  0.0000 | mae_train:  1.1823 | rmse_train:  3.0786 | mae_val:  2.2247 | rmse_val:  5.5190 | mae_test:  3.9767 | rmse_test:  7.4407 | mape_test:  0.8871 | Time(s)  0.1267 \n",
      "2023-05-01 10:07:53   Epoch 61 | acc_train:  0.0000 | mae_train:  1.1765 | rmse_train:  3.0587 | mae_val:  2.2253 | rmse_val:  5.5169 | mae_test:  3.9834 | rmse_test:  7.4422 | mape_test:  0.8916 | Time(s)  0.1316 \n",
      "2023-05-01 10:07:53   Epoch 62 | acc_train:  0.0000 | mae_train:  1.1707 | rmse_train:  3.0392 | mae_val:  2.2261 | rmse_val:  5.5153 | mae_test:  3.9903 | rmse_test:  7.4443 | mape_test:  0.8961 | Time(s)  0.1187 \n",
      "2023-05-01 10:07:53   Epoch 63 | acc_train:  0.0000 | mae_train:  1.1651 | rmse_train:  3.0200 | mae_val:  2.2268 | rmse_val:  5.5139 | mae_test:  3.9973 | rmse_test:  7.4469 | mape_test:  0.9006 | Time(s)  0.1277 \n",
      "2023-05-01 10:07:53   Epoch 64 | acc_train:  0.0000 | mae_train:  1.1595 | rmse_train:  3.0015 | mae_val:  2.2275 | rmse_val:  5.5128 | mae_test:  4.2214 | rmse_test:  7.7489 | mape_test:  0.8968 | Time(s)  0.1182 \n",
      "2023-05-01 10:07:53   Epoch 65 | acc_train:  0.0000 | mae_train:  1.1540 | rmse_train:  2.9835 | mae_val:  2.2283 | rmse_val:  5.5121 | mae_test:  4.2290 | rmse_test:  7.7525 | mape_test:  0.9014 | Time(s)  0.1230 \n",
      "2023-05-01 10:07:53   Epoch 66 | acc_train:  0.0000 | mae_train:  1.1485 | rmse_train:  2.9659 | mae_val:  2.2291 | rmse_val:  5.5116 | mae_test:  4.2369 | rmse_test:  7.7567 | mape_test:  0.9060 | Time(s)  0.1486 \n",
      "2023-05-01 10:07:53   Epoch 67 | acc_train:  0.0000 | mae_train:  1.1430 | rmse_train:  2.9487 | mae_val:  2.2301 | rmse_val:  5.5115 | mae_test:  4.2463 | rmse_test:  7.7633 | mape_test:  0.9106 | Time(s)  0.1206 \n",
      "2023-05-01 10:07:53   Epoch 68 | acc_train:  0.0000 | mae_train:  1.1375 | rmse_train:  2.9319 | mae_val:  2.2318 | rmse_val:  5.5117 | mae_test:  4.2546 | rmse_test:  7.7687 | mape_test:  0.9152 | Time(s)  0.1247 \n",
      "2023-05-01 10:07:54   Epoch 69 | acc_train:  0.0000 | mae_train:  1.1334 | rmse_train:  2.9158 | mae_val:  2.2337 | rmse_val:  5.5117 | mae_test:  4.2621 | rmse_test:  7.7736 | mape_test:  0.9195 | Time(s)  0.1233 \n",
      "2023-05-01 10:07:54   Epoch 70 | acc_train:  0.0000 | mae_train:  1.1298 | rmse_train:  2.9005 | mae_val:  2.2353 | rmse_val:  5.5116 | mae_test:  4.2691 | rmse_test:  7.7784 | mape_test:  0.9234 | Time(s)  0.1223 \n",
      "2023-05-01 10:07:54   Epoch 71 | acc_train:  0.0000 | mae_train:  1.1258 | rmse_train:  2.8858 | mae_val:  2.2367 | rmse_val:  5.5116 | mae_test:  4.2757 | rmse_test:  7.7832 | mape_test:  0.9272 | Time(s)  0.1282 \n",
      "2023-05-01 10:07:54   Epoch 72 | acc_train:  0.0000 | mae_train:  1.1226 | rmse_train:  2.8717 | mae_val:  2.2377 | rmse_val:  5.5113 | mae_test:  4.2815 | rmse_test:  7.7873 | mape_test:  0.9305 | Time(s)  0.1472 \n",
      "2023-05-01 10:07:54   Epoch 73 | acc_train:  0.0000 | mae_train:  1.1199 | rmse_train:  2.8595 | mae_val:  2.2383 | rmse_val:  5.5108 | mae_test:  4.2861 | rmse_test:  7.7904 | mape_test:  0.9333 | Time(s)  0.1386 \n",
      "2023-05-01 10:07:54   Epoch 74 | acc_train:  0.0000 | mae_train:  1.1172 | rmse_train:  2.8486 | mae_val:  2.2389 | rmse_val:  5.5101 | mae_test:  4.2886 | rmse_test:  7.7909 | mape_test:  0.9357 | Time(s)  0.1336 \n",
      "2023-05-01 10:07:54   Epoch 75 | acc_train:  0.0000 | mae_train:  1.1149 | rmse_train:  2.8385 | mae_val:  2.2398 | rmse_val:  5.5098 | mae_test:  4.2929 | rmse_test:  7.7940 | mape_test:  0.9382 | Time(s)  0.1297 \n",
      "2023-05-01 10:07:55   Epoch 76 | acc_train:  0.0000 | mae_train:  1.1127 | rmse_train:  2.8286 | mae_val:  2.2407 | rmse_val:  5.5099 | mae_test:  4.2977 | rmse_test:  7.7978 | mape_test:  0.9409 | Time(s)  0.1216 \n",
      "2023-05-01 10:07:55   Epoch 77 | acc_train:  0.0000 | mae_train:  1.1109 | rmse_train:  2.8191 | mae_val:  2.2414 | rmse_val:  5.5097 | mae_test:  4.3029 | rmse_test:  7.8026 | mape_test:  0.9431 | Time(s)  0.1197 \n",
      "2023-05-01 10:07:55   Epoch 78 | acc_train:  0.0000 | mae_train:  1.1096 | rmse_train:  2.8112 | mae_val:  2.2419 | rmse_val:  5.5091 | mae_test:  4.3042 | rmse_test:  7.8024 | mape_test:  0.9448 | Time(s)  0.1165 \n",
      "2023-05-01 10:07:55   Epoch 79 | acc_train:  0.0000 | mae_train:  1.1083 | rmse_train:  2.8041 | mae_val:  2.2423 | rmse_val:  5.5088 | mae_test:  4.3084 | rmse_test:  7.8063 | mape_test:  0.9465 | Time(s)  0.1235 \n",
      "2023-05-01 10:07:55   Epoch 80 | acc_train:  0.0000 | mae_train:  1.1073 | rmse_train:  2.7976 | mae_val:  2.2427 | rmse_val:  5.5083 | mae_test:  4.3105 | rmse_test:  7.8076 | mape_test:  0.9479 | Time(s)  0.1202 \n",
      "2023-05-01 10:07:55   Epoch 81 | acc_train:  0.0000 | mae_train:  1.1063 | rmse_train:  2.7916 | mae_val:  2.2430 | rmse_val:  5.5079 | mae_test:  4.3127 | rmse_test:  7.8091 | mape_test:  0.9493 | Time(s)  0.1173 \n",
      "2023-05-01 10:07:55   Epoch 82 | acc_train:  0.0000 | mae_train:  1.1053 | rmse_train:  2.7859 | mae_val:  2.2433 | rmse_val:  5.5072 | mae_test:  4.3146 | rmse_test:  7.8103 | mape_test:  0.9505 | Time(s)  0.1312 \n",
      "2023-05-01 10:07:55   Epoch 83 | acc_train:  0.0000 | mae_train:  1.1043 | rmse_train:  2.7803 | mae_val:  2.2437 | rmse_val:  5.5070 | mae_test:  4.3169 | rmse_test:  7.8119 | mape_test:  0.9518 | Time(s)  0.1251 \n",
      "2023-05-01 10:07:55   Epoch 84 | acc_train:  0.0000 | mae_train:  1.1035 | rmse_train:  2.7750 | mae_val:  2.2438 | rmse_val:  5.5063 | mae_test:  4.3184 | rmse_test:  7.8127 | mape_test:  0.9529 | Time(s)  0.1207 \n",
      "2023-05-01 10:07:56   Epoch 85 | acc_train:  0.0000 | mae_train:  1.1025 | rmse_train:  2.7700 | mae_val:  2.2441 | rmse_val:  5.5055 | mae_test:  4.3197 | rmse_test:  7.8133 | mape_test:  0.9539 | Time(s)  0.1287 \n",
      "2023-05-01 10:07:56   Epoch 86 | acc_train:  0.0000 | mae_train:  1.1017 | rmse_train:  2.7650 | mae_val:  2.2443 | rmse_val:  5.5052 | mae_test:  4.3219 | rmse_test:  7.8149 | mape_test:  0.9552 | Time(s)  0.1247 \n",
      "2023-05-01 10:07:56   Epoch 87 | acc_train:  0.0000 | mae_train:  1.1006 | rmse_train:  2.7600 | mae_val:  2.2445 | rmse_val:  5.5047 | mae_test:  4.3236 | rmse_test:  7.8161 | mape_test:  0.9563 | Time(s)  0.1231 \n",
      "2023-05-01 10:07:56   Epoch 88 | acc_train:  0.0000 | mae_train:  1.0997 | rmse_train:  2.7551 | mae_val:  2.2449 | rmse_val:  5.5044 | mae_test:  4.3256 | rmse_test:  7.8175 | mape_test:  0.9575 | Time(s)  0.1162 \n",
      "2023-05-01 10:07:56   Epoch 89 | acc_train:  0.0000 | mae_train:  1.0989 | rmse_train:  2.7505 | mae_val:  2.2450 | rmse_val:  5.5037 | mae_test:  4.3270 | rmse_test:  7.8183 | mape_test:  0.9585 | Time(s)  0.1242 \n",
      "2023-05-01 10:07:56   Epoch 90 | acc_train:  0.0000 | mae_train:  1.0979 | rmse_train:  2.7459 | mae_val:  2.2454 | rmse_val:  5.5035 | mae_test:  4.3291 | rmse_test:  7.8199 | mape_test:  0.9597 | Time(s)  0.1202 \n",
      "2023-05-01 10:07:56   Epoch 91 | acc_train:  0.0000 | mae_train:  1.0971 | rmse_train:  2.7413 | mae_val:  2.2455 | rmse_val:  5.5031 | mae_test:  4.3307 | rmse_test:  7.8210 | mape_test:  0.9608 | Time(s)  0.1202 \n",
      "2023-05-01 10:07:56   Epoch 92 | acc_train:  0.0000 | mae_train:  1.0962 | rmse_train:  2.7370 | mae_val:  2.2458 | rmse_val:  5.5025 | mae_test:  4.3322 | rmse_test:  7.8220 | mape_test:  0.9618 | Time(s)  0.1207 \n",
      "2023-05-01 10:07:57   Epoch 93 | acc_train:  0.0000 | mae_train:  1.0953 | rmse_train:  2.7326 | mae_val:  2.2462 | rmse_val:  5.5024 | mae_test:  4.3345 | rmse_test:  7.8238 | mape_test:  0.9631 | Time(s)  0.1157 \n",
      "2023-05-01 10:07:57   Epoch 94 | acc_train:  0.0000 | mae_train:  1.0944 | rmse_train:  2.7283 | mae_val:  2.2464 | rmse_val:  5.5021 | mae_test:  4.3363 | rmse_test:  7.8252 | mape_test:  0.9642 | Time(s)  0.1197 \n",
      "2023-05-01 10:07:57   Epoch 95 | acc_train:  0.0000 | mae_train:  1.0935 | rmse_train:  2.7242 | mae_val:  2.2466 | rmse_val:  5.5016 | mae_test:  4.3379 | rmse_test:  7.8263 | mape_test:  0.9652 | Time(s)  0.1346 \n",
      "2023-05-01 10:07:57   Epoch 96 | acc_train:  0.0000 | mae_train:  1.0926 | rmse_train:  2.7201 | mae_val:  2.2470 | rmse_val:  5.5016 | mae_test:  4.3401 | rmse_test:  7.8281 | mape_test:  0.9664 | Time(s)  0.1287 \n",
      "2023-05-01 10:07:57   Epoch 97 | acc_train:  0.0000 | mae_train:  1.0918 | rmse_train:  2.7162 | mae_val:  2.2472 | rmse_val:  5.5011 | mae_test:  4.3417 | rmse_test:  7.8293 | mape_test:  0.9674 | Time(s)  0.1263 \n",
      "2023-05-01 10:07:57   Epoch 98 | acc_train:  0.0000 | mae_train:  1.0908 | rmse_train:  2.7123 | mae_val:  2.2476 | rmse_val:  5.5011 | mae_test:  4.3439 | rmse_test:  7.8312 | mape_test:  0.9687 | Time(s)  0.1212 \n",
      "2023-05-01 10:07:57   Epoch 99 | acc_train:  0.0000 | mae_train:  1.0900 | rmse_train:  2.7085 | mae_val:  2.2478 | rmse_val:  5.5009 | mae_test:  4.3458 | rmse_test:  7.8327 | mape_test:  0.9698 | Time(s)  0.1212 \n",
      "2023-05-01 10:07:57   Epoch 100 | acc_train:  0.0000 | mae_train:  1.0891 | rmse_train:  2.7049 | mae_val:  2.2481 | rmse_val:  5.5005 | mae_test:  4.3473 | rmse_test:  7.8339 | mape_test:  0.9707 | Time(s)  0.1167 \n",
      "2023-05-01 10:07:58   Epoch 101 | acc_train:  0.0000 | mae_train:  1.0883 | rmse_train:  2.7012 | mae_val:  2.2485 | rmse_val:  5.5006 | mae_test:  4.3498 | rmse_test:  7.8361 | mape_test:  0.9720 | Time(s)  0.1177 \n",
      "2023-05-01 10:07:58   Epoch 102 | acc_train:  0.0000 | mae_train:  1.0874 | rmse_train:  2.6977 | mae_val:  2.2488 | rmse_val:  5.5005 | mae_test:  4.3517 | rmse_test:  7.8378 | mape_test:  0.9731 | Time(s)  0.1150 \n",
      "2023-05-01 10:07:58   Epoch 103 | acc_train:  0.0000 | mae_train:  1.0865 | rmse_train:  2.6944 | mae_val:  2.2490 | rmse_val:  5.5000 | mae_test:  4.3531 | rmse_test:  7.8388 | mape_test:  0.9740 | Time(s)  0.1208 \n",
      "2023-05-01 10:07:58   Epoch 104 | acc_train:  0.0000 | mae_train:  1.0858 | rmse_train:  2.6910 | mae_val:  2.2492 | rmse_val:  5.4999 | mae_test:  4.3551 | rmse_test:  7.8406 | mape_test:  0.9751 | Time(s)  0.1192 \n",
      "2023-05-01 10:07:58   Epoch 105 | acc_train:  0.0000 | mae_train:  1.0849 | rmse_train:  2.6878 | mae_val:  2.2497 | rmse_val:  5.5001 | mae_test:  4.3573 | rmse_test:  7.8427 | mape_test:  0.9763 | Time(s)  0.1253 \n",
      "2023-05-01 10:07:58   Epoch 106 | acc_train:  0.0000 | mae_train:  1.0842 | rmse_train:  2.6847 | mae_val:  2.2498 | rmse_val:  5.4996 | mae_test:  4.3587 | rmse_test:  7.8438 | mape_test:  0.9771 | Time(s)  0.1247 \n",
      "2023-05-01 10:07:58   Epoch 107 | acc_train:  0.0000 | mae_train:  1.0833 | rmse_train:  2.6819 | mae_val:  2.2497 | rmse_val:  5.4989 | mae_test:  4.3596 | rmse_test:  7.8443 | mape_test:  0.9778 | Time(s)  0.1176 \n",
      "2023-05-01 10:07:58   Epoch 108 | acc_train:  0.0000 | mae_train:  1.0825 | rmse_train:  2.6790 | mae_val:  2.2498 | rmse_val:  5.4986 | mae_test:  4.3613 | rmse_test:  7.8456 | mape_test:  0.9787 | Time(s)  0.1257 \n",
      "2023-05-01 10:07:59   Epoch 109 | acc_train:  0.0000 | mae_train:  1.0816 | rmse_train:  2.6761 | mae_val:  2.2502 | rmse_val:  5.4987 | mae_test:  4.3633 | rmse_test:  7.8475 | mape_test:  0.9798 | Time(s)  0.1277 \n",
      "2023-05-01 10:07:59   Epoch 110 | acc_train:  0.0000 | mae_train:  1.0810 | rmse_train:  2.6735 | mae_val:  2.2502 | rmse_val:  5.4982 | mae_test:  4.3645 | rmse_test:  7.8485 | mape_test:  0.9806 | Time(s)  0.1267 \n",
      "2023-05-01 10:07:59   Epoch 111 | acc_train:  0.0000 | mae_train:  1.0801 | rmse_train:  2.6709 | mae_val:  2.2501 | rmse_val:  5.4974 | mae_test:  4.3653 | rmse_test:  7.8489 | mape_test:  0.9812 | Time(s)  0.1197 \n",
      "2023-05-01 10:07:59   Epoch 112 | acc_train:  0.0000 | mae_train:  1.0793 | rmse_train:  2.6684 | mae_val:  2.2502 | rmse_val:  5.4972 | mae_test:  4.3669 | rmse_test:  7.8503 | mape_test:  0.9821 | Time(s)  0.1342 \n",
      "2023-05-01 10:07:59   Epoch 113 | acc_train:  0.0000 | mae_train:  1.0784 | rmse_train:  2.6659 | mae_val:  2.2506 | rmse_val:  5.4972 | mae_test:  4.3689 | rmse_test:  7.8522 | mape_test:  0.9831 | Time(s)  0.1287 \n",
      "2023-05-01 10:07:59   Epoch 114 | acc_train:  0.0000 | mae_train:  1.0778 | rmse_train:  2.6635 | mae_val:  2.2506 | rmse_val:  5.4968 | mae_test:  4.3701 | rmse_test:  7.8533 | mape_test:  0.9839 | Time(s)  0.1208 \n",
      "2023-05-01 10:07:59   Epoch 115 | acc_train:  0.0000 | mae_train:  1.0769 | rmse_train:  2.6613 | mae_val:  2.2505 | rmse_val:  5.4961 | mae_test:  4.3709 | rmse_test:  7.8538 | mape_test:  0.9845 | Time(s)  0.1166 \n",
      "2023-05-01 10:07:59   Epoch 116 | acc_train:  0.0000 | mae_train:  1.0761 | rmse_train:  2.6591 | mae_val:  2.2506 | rmse_val:  5.4959 | mae_test:  4.3725 | rmse_test:  7.8553 | mape_test:  0.9854 | Time(s)  0.1157 \n",
      "2023-05-01 10:08:00   Epoch 117 | acc_train:  0.0000 | mae_train:  1.0753 | rmse_train:  2.6569 | mae_val:  2.2510 | rmse_val:  5.4961 | mae_test:  4.3745 | rmse_test:  7.8573 | mape_test:  0.9864 | Time(s)  0.1203 \n",
      "2023-05-01 10:08:00   Epoch 118 | acc_train:  0.0000 | mae_train:  1.0746 | rmse_train:  2.6549 | mae_val:  2.2510 | rmse_val:  5.4957 | mae_test:  4.3758 | rmse_test:  7.8585 | mape_test:  0.9872 | Time(s)  0.1202 \n",
      "2023-05-01 10:08:00   Epoch 119 | acc_train:  0.0000 | mae_train:  1.0738 | rmse_train:  2.6530 | mae_val:  2.2509 | rmse_val:  5.4951 | mae_test:  4.3766 | rmse_test:  7.8591 | mape_test:  0.9878 | Time(s)  0.1185 \n",
      "2023-05-01 10:08:00   Epoch 120 | acc_train:  0.0000 | mae_train:  1.0730 | rmse_train:  2.6511 | mae_val:  2.2510 | rmse_val:  5.4950 | mae_test:  4.3782 | rmse_test:  7.8608 | mape_test:  0.9886 | Time(s)  0.1211 \n",
      "2023-05-01 10:08:00   Epoch 121 | acc_train:  0.0000 | mae_train:  1.0721 | rmse_train:  2.6492 | mae_val:  2.2515 | rmse_val:  5.4952 | mae_test:  4.3806 | rmse_test:  7.8633 | mape_test:  0.9896 | Time(s)  0.1263 \n",
      "2023-05-01 10:08:00   Epoch 122 | acc_train:  0.0000 | mae_train:  1.0715 | rmse_train:  2.6475 | mae_val:  2.2515 | rmse_val:  5.4949 | mae_test:  4.3820 | rmse_test:  7.8646 | mape_test:  0.9904 | Time(s)  0.1207 \n",
      "2023-05-01 10:08:00   Epoch 123 | acc_train:  0.0000 | mae_train:  1.0706 | rmse_train:  2.6459 | mae_val:  2.2515 | rmse_val:  5.4944 | mae_test:  4.3829 | rmse_test:  7.8654 | mape_test:  0.9910 | Time(s)  0.1167 \n",
      "2023-05-01 10:08:00   Epoch 124 | acc_train:  0.0000 | mae_train:  1.0699 | rmse_train:  2.6443 | mae_val:  2.2516 | rmse_val:  5.4943 | mae_test:  4.3845 | rmse_test:  7.8671 | mape_test:  0.9918 | Time(s)  0.1227 \n",
      "2023-05-01 10:08:01   Epoch 125 | acc_train:  0.0000 | mae_train:  1.0690 | rmse_train:  2.6428 | mae_val:  2.2520 | rmse_val:  5.4946 | mae_test:  4.3869 | rmse_test:  7.8697 | mape_test:  0.9928 | Time(s)  0.1247 \n",
      "2023-05-01 10:08:01   Epoch 126 | acc_train:  0.0000 | mae_train:  1.0684 | rmse_train:  2.6415 | mae_val:  2.2520 | rmse_val:  5.4943 | mae_test:  4.3882 | rmse_test:  7.8710 | mape_test:  0.9935 | Time(s)  0.1176 \n",
      "2023-05-01 10:08:01   Epoch 127 | acc_train:  0.0000 | mae_train:  1.0675 | rmse_train:  2.6402 | mae_val:  2.2520 | rmse_val:  5.4937 | mae_test:  4.3890 | rmse_test:  7.8718 | mape_test:  0.9941 | Time(s)  0.1207 \n",
      "2023-05-01 10:08:01   Epoch 128 | acc_train:  0.0000 | mae_train:  1.0668 | rmse_train:  2.6389 | mae_val:  2.2521 | rmse_val:  5.4937 | mae_test:  4.3906 | rmse_test:  7.8735 | mape_test:  0.9949 | Time(s)  0.1277 \n",
      "2023-05-01 10:08:01   Epoch 129 | acc_train:  0.0000 | mae_train:  1.0659 | rmse_train:  2.6377 | mae_val:  2.2524 | rmse_val:  5.4940 | mae_test:  4.3934 | rmse_test:  7.8767 | mape_test:  0.9959 | Time(s)  0.1170 \n",
      "2023-05-01 10:08:01   Epoch 130 | acc_train:  0.0000 | mae_train:  1.0653 | rmse_train:  2.6366 | mae_val:  2.2525 | rmse_val:  5.4938 | mae_test:  4.3947 | rmse_test:  7.8781 | mape_test:  0.9966 | Time(s)  0.1217 \n",
      "2023-05-01 10:08:01   Epoch 131 | acc_train:  0.0000 | mae_train:  1.0645 | rmse_train:  2.6356 | mae_val:  2.2524 | rmse_val:  5.4934 | mae_test:  4.3957 | rmse_test:  7.8792 | mape_test:  0.9972 | Time(s)  0.1287 \n",
      "2023-05-01 10:08:01   Epoch 132 | acc_train:  0.0000 | mae_train:  1.0637 | rmse_train:  2.6347 | mae_val:  2.2526 | rmse_val:  5.4935 | mae_test:  4.3973 | rmse_test:  7.8809 | mape_test:  0.9980 | Time(s)  0.1312 \n",
      "2023-05-01 10:08:02   Epoch 133 | acc_train:  0.0000 | mae_train:  1.0631 | rmse_train:  2.6339 | mae_val:  2.2526 | rmse_val:  5.4931 | mae_test:  4.3982 | rmse_test:  7.8819 | mape_test:  0.9986 | Time(s)  0.1273 \n",
      "2023-05-01 10:08:02   Epoch 134 | acc_train:  0.0000 | mae_train:  1.0624 | rmse_train:  2.6331 | mae_val:  2.2527 | rmse_val:  5.4932 | mae_test:  4.3998 | rmse_test:  7.8837 | mape_test:  0.9994 | Time(s)  0.1220 \n",
      "2023-05-01 10:08:02   Epoch 135 | acc_train:  0.0000 | mae_train:  1.0617 | rmse_train:  2.6324 | mae_val:  2.2527 | rmse_val:  5.4930 | mae_test:  4.4009 | rmse_test:  7.8850 | mape_test:  1.0000 | Time(s)  0.1202 \n",
      "2023-05-01 10:08:02   Epoch 136 | acc_train:  0.0000 | mae_train:  1.0611 | rmse_train:  2.6318 | mae_val:  2.2528 | rmse_val:  5.4926 | mae_test:  4.4018 | rmse_test:  7.8859 | mape_test:  1.0005 | Time(s)  0.1386 \n",
      "2023-05-01 10:08:02   Epoch 137 | acc_train:  0.0000 | mae_train:  1.0605 | rmse_train:  2.6312 | mae_val:  2.2530 | rmse_val:  5.4929 | mae_test:  4.4037 | rmse_test:  7.8880 | mape_test:  1.0013 | Time(s)  0.1203 \n",
      "2023-05-01 10:08:02   Epoch 138 | acc_train:  0.0000 | mae_train:  1.0598 | rmse_train:  2.6308 | mae_val:  2.2531 | rmse_val:  5.4928 | mae_test:  4.4049 | rmse_test:  7.8894 | mape_test:  1.0020 | Time(s)  0.1167 \n",
      "2023-05-01 10:08:02   Epoch 139 | acc_train:  0.0000 | mae_train:  1.0591 | rmse_train:  2.6303 | mae_val:  2.2530 | rmse_val:  5.4925 | mae_test:  4.4059 | rmse_test:  7.8905 | mape_test:  1.0025 | Time(s)  0.1177 \n",
      "2023-05-01 10:08:02   Epoch 140 | acc_train:  0.0000 | mae_train:  1.0585 | rmse_train:  2.6300 | mae_val:  2.2533 | rmse_val:  5.4927 | mae_test:  4.4075 | rmse_test:  7.8925 | mape_test:  1.0033 | Time(s)  0.1217 \n",
      "2023-05-01 10:08:03   Epoch 141 | acc_train:  0.0000 | mae_train:  1.0579 | rmse_train:  2.6297 | mae_val:  2.2532 | rmse_val:  5.4924 | mae_test:  4.4085 | rmse_test:  7.8935 | mape_test:  1.0038 | Time(s)  0.1216 \n",
      "2023-05-01 10:08:03   Epoch 142 | acc_train:  0.0000 | mae_train:  1.0572 | rmse_train:  2.6294 | mae_val:  2.2533 | rmse_val:  5.4925 | mae_test:  4.4099 | rmse_test:  7.8952 | mape_test:  1.0045 | Time(s)  0.1333 \n",
      "2023-05-01 10:08:03   Epoch 143 | acc_train:  0.0000 | mae_train:  1.0566 | rmse_train:  2.6293 | mae_val:  2.2534 | rmse_val:  5.4923 | mae_test:  4.4110 | rmse_test:  7.8965 | mape_test:  1.0051 | Time(s)  0.1286 \n",
      "2023-05-01 10:08:03   Epoch 144 | acc_train:  0.0000 | mae_train:  1.0559 | rmse_train:  2.6292 | mae_val:  2.2536 | rmse_val:  5.4926 | mae_test:  4.4128 | rmse_test:  7.8987 | mape_test:  1.0059 | Time(s)  0.1267 \n",
      "2023-05-01 10:08:03   Epoch 145 | acc_train:  0.0000 | mae_train:  1.0553 | rmse_train:  2.6292 | mae_val:  2.2535 | rmse_val:  5.4923 | mae_test:  4.4139 | rmse_test:  7.9001 | mape_test:  1.0064 | Time(s)  0.1233 \n",
      "2023-05-01 10:08:03   Epoch 146 | acc_train:  0.0000 | mae_train:  1.0546 | rmse_train:  2.6292 | mae_val:  2.2536 | rmse_val:  5.4925 | mae_test:  4.4154 | rmse_test:  7.9020 | mape_test:  1.0071 | Time(s)  0.1258 \n",
      "2023-05-01 10:08:03   Epoch 147 | acc_train:  0.0000 | mae_train:  1.0540 | rmse_train:  2.6293 | mae_val:  2.2537 | rmse_val:  5.4924 | mae_test:  4.4166 | rmse_test:  7.9034 | mape_test:  1.0077 | Time(s)  0.1202 \n",
      "2023-05-01 10:08:03   Epoch 148 | acc_train:  0.0000 | mae_train:  1.0533 | rmse_train:  2.6294 | mae_val:  2.2539 | rmse_val:  5.4927 | mae_test:  4.4186 | rmse_test:  7.9058 | mape_test:  1.0085 | Time(s)  0.1251 \n",
      "2023-05-01 10:08:04   Epoch 149 | acc_train:  0.0000 | mae_train:  1.0527 | rmse_train:  2.6297 | mae_val:  2.2539 | rmse_val:  5.4926 | mae_test:  4.4197 | rmse_test:  7.9072 | mape_test:  1.0090 | Time(s)  0.1152 \n",
      "2023-05-01 10:08:04   Epoch 150 | acc_train:  0.0000 | mae_train:  1.0520 | rmse_train:  2.6299 | mae_val:  2.2541 | rmse_val:  5.4928 | mae_test:  4.4213 | rmse_test:  7.9093 | mape_test:  1.0097 | Time(s)  0.1202 \n",
      "2023-05-01 10:08:04   Epoch 151 | acc_train:  0.0000 | mae_train:  1.0514 | rmse_train:  2.6303 | mae_val:  2.2541 | rmse_val:  5.4927 | mae_test:  4.4226 | rmse_test:  7.9108 | mape_test:  1.0103 | Time(s)  0.1376 \n",
      "2023-05-01 10:08:04   Epoch 152 | acc_train:  0.0000 | mae_train:  1.0508 | rmse_train:  2.6307 | mae_val:  2.2544 | rmse_val:  5.4931 | mae_test:  4.4244 | rmse_test:  7.9132 | mape_test:  1.0111 | Time(s)  0.1506 \n",
      "2023-05-01 10:08:04   Epoch 153 | acc_train:  0.0000 | mae_train:  1.0501 | rmse_train:  2.6312 | mae_val:  2.2543 | rmse_val:  5.4931 | mae_test:  4.4255 | rmse_test:  7.9147 | mape_test:  1.0116 | Time(s)  0.1522 \n",
      "2023-05-01 10:08:04   Epoch 154 | acc_train:  0.0000 | mae_train:  1.0494 | rmse_train:  2.6317 | mae_val:  2.2545 | rmse_val:  5.4933 | mae_test:  4.4271 | rmse_test:  7.9168 | mape_test:  1.0123 | Time(s)  0.1316 \n",
      "2023-05-01 10:08:04   Epoch 155 | acc_train:  0.0000 | mae_train:  1.0488 | rmse_train:  2.6323 | mae_val:  2.2546 | rmse_val:  5.4934 | mae_test:  4.4284 | rmse_test:  7.9185 | mape_test:  1.0129 | Time(s)  0.1286 \n",
      "2023-05-01 10:08:04   Epoch 156 | acc_train:  0.0000 | mae_train:  1.0482 | rmse_train:  2.6330 | mae_val:  2.2549 | rmse_val:  5.4939 | mae_test:  4.4303 | rmse_test:  7.9210 | mape_test:  1.0137 | Time(s)  0.1197 \n",
      "2023-05-01 10:08:05   Epoch 157 | acc_train:  0.0000 | mae_train:  1.0476 | rmse_train:  2.6338 | mae_val:  2.2548 | rmse_val:  5.4938 | mae_test:  4.4315 | rmse_test:  7.9226 | mape_test:  1.0143 | Time(s)  0.1297 \n",
      "2023-05-01 10:08:05   Epoch 158 | acc_train:  0.0000 | mae_train:  1.0469 | rmse_train:  2.6345 | mae_val:  2.2550 | rmse_val:  5.4937 | mae_test:  4.4325 | rmse_test:  7.9240 | mape_test:  1.0148 | Time(s)  0.1307 \n",
      "2023-05-01 10:08:05   Epoch 159 | acc_train:  0.0000 | mae_train:  1.0464 | rmse_train:  2.6353 | mae_val:  2.2551 | rmse_val:  5.4943 | mae_test:  4.4346 | rmse_test:  7.9269 | mape_test:  1.0156 | Time(s)  0.1212 \n",
      "2023-05-01 10:08:05   Epoch 160 | acc_train:  0.0000 | mae_train:  1.0455 | rmse_train:  2.6363 | mae_val:  2.2552 | rmse_val:  5.4946 | mae_test:  4.4361 | rmse_test:  7.9289 | mape_test:  1.0163 | Time(s)  0.1316 \n",
      "2023-05-01 10:08:05   Epoch 161 | acc_train:  0.0000 | mae_train:  1.0449 | rmse_train:  2.6373 | mae_val:  2.2554 | rmse_val:  5.4948 | mae_test:  4.4375 | rmse_test:  7.9309 | mape_test:  1.0169 | Time(s)  0.1218 \n",
      "2023-05-01 10:08:05   Epoch 162 | acc_train:  0.0000 | mae_train:  1.0445 | rmse_train:  2.6382 | mae_val:  2.2551 | rmse_val:  5.4942 | mae_test:  4.4378 | rmse_test:  7.9313 | mape_test:  1.0172 | Time(s)  0.1173 \n",
      "2023-05-01 10:08:05   Epoch 163 | acc_train:  0.0000 | mae_train:  1.0440 | rmse_train:  2.6390 | mae_val:  2.2549 | rmse_val:  5.4937 | mae_test:  4.4381 | rmse_test:  7.9316 | mape_test:  1.0174 | Time(s)  0.1279 \n",
      "2023-05-01 10:08:05   Epoch 164 | acc_train:  0.0000 | mae_train:  1.0436 | rmse_train:  2.6397 | mae_val:  2.2548 | rmse_val:  5.4932 | mae_test:  4.4425 | rmse_test:  7.9372 | mape_test:  1.0177 | Time(s)  0.1267 \n",
      "2023-05-01 10:08:06   Epoch 165 | acc_train:  0.0000 | mae_train:  1.0435 | rmse_train:  2.6405 | mae_val:  2.2535 | rmse_val:  5.4905 | mae_test:  4.4396 | rmse_test:  7.9327 | mape_test:  1.0169 | Time(s)  0.1277 \n",
      "2023-05-01 10:08:06   Epoch 166 | acc_train:  0.0000 | mae_train:  1.0432 | rmse_train:  2.6398 | mae_val:  2.2515 | rmse_val:  5.4857 | mae_test:  4.4333 | rmse_test:  7.9234 | mape_test:  1.0149 | Time(s)  0.1192 \n",
      "2023-05-01 10:08:06   Epoch 167 | acc_train:  0.0000 | mae_train:  1.0431 | rmse_train:  2.6382 | mae_val:  2.2495 | rmse_val:  5.4812 | mae_test:  4.4276 | rmse_test:  7.9147 | mape_test:  1.0130 | Time(s)  0.1217 \n",
      "2023-05-01 10:08:06   Epoch 168 | acc_train:  0.0000 | mae_train:  1.0429 | rmse_train:  2.6372 | mae_val:  2.2480 | rmse_val:  5.4778 | mae_test:  4.4242 | rmse_test:  7.9095 | mape_test:  1.0117 | Time(s)  0.1287 \n",
      "2023-05-01 10:08:06   Epoch 169 | acc_train:  0.0000 | mae_train:  1.0426 | rmse_train:  2.6367 | mae_val:  2.2470 | rmse_val:  5.4752 | mae_test:  4.4213 | rmse_test:  7.9052 | mape_test:  1.0109 | Time(s)  0.1162 \n",
      "2023-05-01 10:08:06   Epoch 170 | acc_train:  0.0000 | mae_train:  1.0423 | rmse_train:  2.6365 | mae_val:  2.2463 | rmse_val:  5.4736 | mae_test:  4.4199 | rmse_test:  7.9029 | mape_test:  1.0106 | Time(s)  0.1182 \n",
      "2023-05-01 10:08:06   Epoch 171 | acc_train:  0.0000 | mae_train:  1.0423 | rmse_train:  2.6367 | mae_val:  2.2448 | rmse_val:  5.4702 | mae_test:  4.4159 | rmse_test:  7.8969 | mape_test:  1.0093 | Time(s)  0.1227 \n",
      "2023-05-01 10:08:06   Epoch 172 | acc_train:  0.0000 | mae_train:  1.0420 | rmse_train:  2.6358 | mae_val:  2.2426 | rmse_val:  5.4652 | mae_test:  4.4093 | rmse_test:  7.8870 | mape_test:  1.0072 | Time(s)  0.1277 \n",
      "2023-05-01 10:08:07   Epoch 173 | acc_train:  0.0000 | mae_train:  1.0420 | rmse_train:  2.6341 | mae_val:  2.2405 | rmse_val:  5.4604 | mae_test:  4.4031 | rmse_test:  7.8777 | mape_test:  1.0051 | Time(s)  0.1132 \n",
      "2023-05-01 10:08:07   Epoch 174 | acc_train:  0.0000 | mae_train:  1.0418 | rmse_train:  2.6329 | mae_val:  2.2390 | rmse_val:  5.4569 | mae_test:  4.3989 | rmse_test:  7.8715 | mape_test:  1.0038 | Time(s)  0.1187 \n",
      "2023-05-01 10:08:07   Epoch 175 | acc_train:  0.0000 | mae_train:  1.0415 | rmse_train:  2.6323 | mae_val:  2.2381 | rmse_val:  5.4548 | mae_test:  4.3971 | rmse_test:  7.8685 | mape_test:  1.0031 | Time(s)  0.1176 \n",
      "2023-05-01 10:08:07   Epoch 176 | acc_train:  0.0000 | mae_train:  1.0413 | rmse_train:  2.6322 | mae_val:  2.2371 | rmse_val:  5.4526 | mae_test:  4.3950 | rmse_test:  7.8653 | mape_test:  1.0026 | Time(s)  0.1197 \n",
      "2023-05-01 10:08:07   Epoch 177 | acc_train:  0.0000 | mae_train:  1.0409 | rmse_train:  2.6323 | mae_val:  2.2357 | rmse_val:  5.4492 | mae_test:  4.3908 | rmse_test:  7.8591 | mape_test:  1.0013 | Time(s)  0.1218 \n",
      "2023-05-01 10:08:07   Epoch 178 | acc_train:  0.0000 | mae_train:  1.0409 | rmse_train:  2.6314 | mae_val:  2.2342 | rmse_val:  5.4460 | mae_test:  4.3868 | rmse_test:  7.8533 | mape_test:  1.0000 | Time(s)  0.1203 \n",
      "2023-05-01 10:08:07   Epoch 179 | acc_train:  0.0000 | mae_train:  1.0405 | rmse_train:  2.6309 | mae_val:  2.2335 | rmse_val:  5.4440 | mae_test:  4.3849 | rmse_test:  7.8502 | mape_test:  0.9994 | Time(s)  0.1272 \n",
      "2023-05-01 10:08:07   Epoch 180 | acc_train:  0.0000 | mae_train:  1.0406 | rmse_train:  2.6308 | mae_val:  2.2319 | rmse_val:  5.4404 | mae_test:  4.3806 | rmse_test:  7.8438 | mape_test:  0.9980 | Time(s)  0.1182 \n",
      "2023-05-01 10:08:08   Epoch 181 | acc_train:  0.0000 | mae_train:  1.0403 | rmse_train:  2.6297 | mae_val:  2.2300 | rmse_val:  5.4362 | mae_test:  4.3753 | rmse_test:  7.8359 | mape_test:  0.9963 | Time(s)  0.1212 \n",
      "2023-05-01 10:08:08   Epoch 182 | acc_train:  0.0000 | mae_train:  1.0400 | rmse_train:  2.6289 | mae_val:  2.2288 | rmse_val:  5.4336 | mae_test:  4.3723 | rmse_test:  7.8314 | mape_test:  0.9954 | Time(s)  0.1236 \n",
      "2023-05-01 10:08:08   Epoch 183 | acc_train:  0.0000 | mae_train:  1.0396 | rmse_train:  2.6286 | mae_val:  2.2272 | rmse_val:  5.4300 | mae_test:  4.3678 | rmse_test:  7.8248 | mape_test:  0.9940 | Time(s)  0.1177 \n",
      "2023-05-01 10:08:08   Epoch 184 | acc_train:  0.0000 | mae_train:  1.0396 | rmse_train:  2.6276 | mae_val:  2.2258 | rmse_val:  5.4266 | mae_test:  4.3649 | rmse_test:  7.8201 | mape_test:  0.9926 | Time(s)  0.1306 \n",
      "2023-05-01 10:08:08   Epoch 185 | acc_train:  0.0000 | mae_train:  1.0395 | rmse_train:  2.6269 | mae_val:  2.2245 | rmse_val:  5.4237 | mae_test:  4.3615 | rmse_test:  7.8151 | mape_test:  0.9916 | Time(s)  0.1268 \n",
      "2023-05-01 10:08:08   Epoch 186 | acc_train:  0.0000 | mae_train:  1.0391 | rmse_train:  2.6266 | mae_val:  2.2236 | rmse_val:  5.4213 | mae_test:  4.3593 | rmse_test:  7.8117 | mape_test:  0.9909 | Time(s)  0.1227 \n",
      "2023-05-01 10:08:08   Epoch 187 | acc_train:  0.0000 | mae_train:  1.0391 | rmse_train:  2.6265 | mae_val:  2.2222 | rmse_val:  5.4185 | mae_test:  4.3559 | rmse_test:  7.8067 | mape_test:  0.9898 | Time(s)  0.1127 \n",
      "2023-05-01 10:08:08   Epoch 188 | acc_train:  0.0000 | mae_train:  1.0388 | rmse_train:  2.6258 | mae_val:  2.2204 | rmse_val:  5.4141 | mae_test:  4.3502 | rmse_test:  7.7981 | mape_test:  0.9878 | Time(s)  0.1257 \n",
      "2023-05-01 10:08:09   Epoch 189 | acc_train:  0.0000 | mae_train:  1.0390 | rmse_train:  2.6242 | mae_val:  2.2182 | rmse_val:  5.4094 | mae_test:  4.3439 | rmse_test:  7.7889 | mape_test:  0.9858 | Time(s)  0.1252 \n",
      "2023-05-01 10:08:09   Epoch 190 | acc_train:  0.0000 | mae_train:  1.0387 | rmse_train:  2.6230 | mae_val:  2.2167 | rmse_val:  5.4059 | mae_test:  4.3396 | rmse_test:  7.7827 | mape_test:  0.9844 | Time(s)  0.1177 \n",
      "2023-05-01 10:08:09   Epoch 191 | acc_train:  0.0000 | mae_train:  1.0384 | rmse_train:  2.6225 | mae_val:  2.2159 | rmse_val:  5.4042 | mae_test:  4.3383 | rmse_test:  7.7806 | mape_test:  0.9840 | Time(s)  0.1227 \n",
      "2023-05-01 10:08:09   Epoch 192 | acc_train:  0.0000 | mae_train:  1.0379 | rmse_train:  2.6228 | mae_val:  2.2157 | rmse_val:  5.4034 | mae_test:  4.3380 | rmse_test:  7.7799 | mape_test:  0.9840 | Time(s)  0.1282 \n",
      "2023-05-01 10:08:09   Epoch 193 | acc_train:  0.0000 | mae_train:  1.0381 | rmse_train:  2.6232 | mae_val:  2.2144 | rmse_val:  5.4007 | mae_test:  4.3350 | rmse_test:  7.7753 | mape_test:  0.9831 | Time(s)  0.1376 \n",
      "2023-05-01 10:08:09   Epoch 194 | acc_train:  0.0000 | mae_train:  1.0377 | rmse_train:  2.6224 | mae_val:  2.2122 | rmse_val:  5.3958 | mae_test:  4.3283 | rmse_test:  7.7657 | mape_test:  0.9808 | Time(s)  0.1258 \n",
      "2023-05-01 10:08:09   Epoch 195 | acc_train:  0.0000 | mae_train:  1.0377 | rmse_train:  2.6208 | mae_val:  2.2105 | rmse_val:  5.3920 | mae_test:  4.3232 | rmse_test:  7.7583 | mape_test:  0.9792 | Time(s)  0.1267 \n",
      "2023-05-01 10:08:10   Epoch 196 | acc_train:  0.0000 | mae_train:  1.0374 | rmse_train:  2.6199 | mae_val:  2.2093 | rmse_val:  5.3894 | mae_test:  4.3202 | rmse_test:  7.7538 | mape_test:  0.9782 | Time(s)  0.1177 \n",
      "2023-05-01 10:08:10   Epoch 197 | acc_train:  0.0000 | mae_train:  1.0371 | rmse_train:  2.6197 | mae_val:  2.2087 | rmse_val:  5.3877 | mae_test:  4.3185 | rmse_test:  7.7514 | mape_test:  0.9778 | Time(s)  0.1197 \n",
      "2023-05-01 10:08:10   Epoch 198 | acc_train:  0.0000 | mae_train:  1.0369 | rmse_train:  2.6199 | mae_val:  2.2076 | rmse_val:  5.3856 | mae_test:  4.3161 | rmse_test:  7.7478 | mape_test:  0.9770 | Time(s)  0.1187 \n",
      "2023-05-01 10:08:10   Epoch 199 | acc_train:  0.0000 | mae_train:  1.0367 | rmse_train:  2.6193 | mae_val:  2.2063 | rmse_val:  5.3828 | mae_test:  4.3128 | rmse_test:  7.7429 | mape_test:  0.9759 | Time(s)  0.1217 \n",
      "2023-05-01 10:08:10   Epoch 200 | acc_train:  0.0000 | mae_train:  1.0365 | rmse_train:  2.6189 | mae_val:  2.2050 | rmse_val:  5.3795 | mae_test:  4.3085 | rmse_test:  7.7368 | mape_test:  0.9746 | Time(s)  0.1257 \n",
      "2023-05-01 10:08:10   Epoch 201 | acc_train:  0.0000 | mae_train:  1.0366 | rmse_train:  2.6180 | mae_val:  2.2037 | rmse_val:  5.3769 | mae_test:  4.3055 | rmse_test:  7.7322 | mape_test:  0.9735 | Time(s)  0.1242 \n",
      "2023-05-01 10:08:10   Epoch 202 | acc_train:  0.0000 | mae_train:  1.0362 | rmse_train:  2.6177 | mae_val:  2.2029 | rmse_val:  5.3751 | mae_test:  4.3040 | rmse_test:  7.7300 | mape_test:  0.9730 | Time(s)  0.1257 \n",
      "2023-05-01 10:08:11   Epoch 203 | acc_train:  0.0000 | mae_train:  1.0361 | rmse_train:  2.6178 | mae_val:  2.2017 | rmse_val:  5.3723 | mae_test:  4.3004 | rmse_test:  7.7250 | mape_test:  0.9719 | Time(s)  0.1256 \n",
      "2023-05-01 10:08:11   Epoch 204 | acc_train:  0.0000 | mae_train:  1.0360 | rmse_train:  2.6170 | mae_val:  2.2005 | rmse_val:  5.3698 | mae_test:  4.2974 | rmse_test:  7.7205 | mape_test:  0.9709 | Time(s)  0.1247 \n",
      "2023-05-01 10:08:11   Epoch 205 | acc_train:  0.0000 | mae_train:  1.0358 | rmse_train:  2.6167 | mae_val:  2.1990 | rmse_val:  5.3667 | mae_test:  4.2935 | rmse_test:  7.7149 | mape_test:  0.9696 | Time(s)  0.1262 \n",
      "2023-05-01 10:08:11   Epoch 206 | acc_train:  0.0000 | mae_train:  1.0357 | rmse_train:  2.6157 | mae_val:  2.1977 | rmse_val:  5.3635 | mae_test:  4.2894 | rmse_test:  7.7091 | mape_test:  0.9683 | Time(s)  0.1162 \n",
      "2023-05-01 10:08:11   Epoch 207 | acc_train:  0.0000 | mae_train:  1.0355 | rmse_train:  2.6153 | mae_val:  2.1970 | rmse_val:  5.3622 | mae_test:  4.2881 | rmse_test:  7.7071 | mape_test:  0.9680 | Time(s)  0.1216 \n",
      "2023-05-01 10:08:11   Epoch 208 | acc_train:  0.0000 | mae_train:  1.0354 | rmse_train:  2.6154 | mae_val:  2.1959 | rmse_val:  5.3598 | mae_test:  4.2906 | rmse_test:  7.7095 | mape_test:  0.9673 | Time(s)  0.1176 \n",
      "2023-05-01 10:08:11   Epoch 209 | acc_train:  0.0000 | mae_train:  1.0351 | rmse_train:  2.6148 | mae_val:  2.1941 | rmse_val:  5.3558 | mae_test:  4.2852 | rmse_test:  7.7019 | mape_test:  0.9654 | Time(s)  0.1197 \n",
      "2023-05-01 10:08:12   Epoch 210 | acc_train:  0.0000 | mae_train:  1.0353 | rmse_train:  2.6135 | mae_val:  2.1926 | rmse_val:  5.3528 | mae_test:  4.2813 | rmse_test:  7.6962 | mape_test:  0.9640 | Time(s)  0.1226 \n",
      "2023-05-01 10:08:12   Epoch 211 | acc_train:  0.0000 | mae_train:  1.0350 | rmse_train:  2.6130 | mae_val:  2.1917 | rmse_val:  5.3508 | mae_test:  4.2791 | rmse_test:  7.6931 | mape_test:  0.9633 | Time(s)  0.1287 \n",
      "2023-05-01 10:08:12   Epoch 212 | acc_train:  0.0000 | mae_train:  1.0347 | rmse_train:  2.6129 | mae_val:  2.1912 | rmse_val:  5.3494 | mae_test:  4.2780 | rmse_test:  7.6914 | mape_test:  0.9631 | Time(s)  0.1167 \n",
      "2023-05-01 10:08:12   Epoch 213 | acc_train:  0.0000 | mae_train:  1.0346 | rmse_train:  2.6132 | mae_val:  2.1903 | rmse_val:  5.3477 | mae_test:  4.2761 | rmse_test:  7.6887 | mape_test:  0.9625 | Time(s)  0.1296 \n",
      "2023-05-01 10:08:12   Epoch 214 | acc_train:  0.0000 | mae_train:  1.0345 | rmse_train:  2.6128 | mae_val:  2.1887 | rmse_val:  5.3441 | mae_test:  4.2712 | rmse_test:  7.6818 | mape_test:  0.9609 | Time(s)  0.1222 \n",
      "2023-05-01 10:08:12   Epoch 215 | acc_train:  0.0000 | mae_train:  1.0343 | rmse_train:  2.6117 | mae_val:  2.1873 | rmse_val:  5.3413 | mae_test:  4.2675 | rmse_test:  7.6765 | mape_test:  0.9596 | Time(s)  0.1257 \n",
      "2023-05-01 10:08:12   Epoch 216 | acc_train:  0.0000 | mae_train:  1.0341 | rmse_train:  2.6112 | mae_val:  2.1864 | rmse_val:  5.3394 | mae_test:  4.2654 | rmse_test:  7.6735 | mape_test:  0.9590 | Time(s)  0.1237 \n",
      "2023-05-01 10:08:13   Epoch 217 | acc_train:  0.0000 | mae_train:  1.0339 | rmse_train:  2.6112 | mae_val:  2.1853 | rmse_val:  5.3369 | mae_test:  4.2624 | rmse_test:  7.6693 | mape_test:  0.9580 | Time(s)  0.1292 \n",
      "2023-05-01 10:08:13   Epoch 218 | acc_train:  0.0000 | mae_train:  1.0338 | rmse_train:  2.6105 | mae_val:  2.1843 | rmse_val:  5.3348 | mae_test:  4.2599 | rmse_test:  7.6655 | mape_test:  0.9572 | Time(s)  0.1210 \n",
      "2023-05-01 10:08:13   Epoch 219 | acc_train:  0.0000 | mae_train:  1.0337 | rmse_train:  2.6103 | mae_val:  2.1830 | rmse_val:  5.3320 | mae_test:  4.2561 | rmse_test:  7.6603 | mape_test:  0.9559 | Time(s)  0.1332 \n",
      "2023-05-01 10:08:13   Epoch 220 | acc_train:  0.0000 | mae_train:  1.0336 | rmse_train:  2.6095 | mae_val:  2.1819 | rmse_val:  5.3296 | mae_test:  4.2532 | rmse_test:  7.6561 | mape_test:  0.9550 | Time(s)  0.1257 \n",
      "2023-05-01 10:08:13   Epoch 221 | acc_train:  0.0000 | mae_train:  1.0333 | rmse_train:  2.6092 | mae_val:  2.1812 | rmse_val:  5.3281 | mae_test:  4.2516 | rmse_test:  7.6539 | mape_test:  0.9545 | Time(s)  0.1226 \n",
      "2023-05-01 10:08:13   Epoch 222 | acc_train:  0.0000 | mae_train:  1.0333 | rmse_train:  2.6094 | mae_val:  2.1803 | rmse_val:  5.3262 | mae_test:  4.2494 | rmse_test:  7.6506 | mape_test:  0.9538 | Time(s)  0.1157 \n",
      "2023-05-01 10:08:13   Epoch 223 | acc_train:  0.0000 | mae_train:  1.0332 | rmse_train:  2.6089 | mae_val:  2.1787 | rmse_val:  5.3226 | mae_test:  4.2443 | rmse_test:  7.6437 | mape_test:  0.9521 | Time(s)  0.1257 \n",
      "2023-05-01 10:08:14   Epoch 224 | acc_train:  0.0000 | mae_train:  1.0331 | rmse_train:  2.6078 | mae_val:  2.1774 | rmse_val:  5.3200 | mae_test:  4.2409 | rmse_test:  7.6387 | mape_test:  0.9509 | Time(s)  0.1186 \n",
      "2023-05-01 10:08:14   Epoch 225 | acc_train:  0.0000 | mae_train:  1.0329 | rmse_train:  2.6073 | mae_val:  2.1766 | rmse_val:  5.3182 | mae_test:  4.2391 | rmse_test:  7.6363 | mape_test:  0.9504 | Time(s)  0.1237 \n",
      "2023-05-01 10:08:14   Epoch 226 | acc_train:  0.0000 | mae_train:  1.0327 | rmse_train:  2.6073 | mae_val:  2.1754 | rmse_val:  5.3157 | mae_test:  4.2360 | rmse_test:  7.6320 | mape_test:  0.9493 | Time(s)  0.1157 \n",
      "2023-05-01 10:08:14   Epoch 227 | acc_train:  0.0000 | mae_train:  1.0327 | rmse_train:  2.6067 | mae_val:  2.1744 | rmse_val:  5.3136 | mae_test:  4.2335 | rmse_test:  7.6284 | mape_test:  0.9485 | Time(s)  0.1256 \n",
      "2023-05-01 10:08:14   Epoch 228 | acc_train:  0.0000 | mae_train:  1.0324 | rmse_train:  2.6065 | mae_val:  2.1734 | rmse_val:  5.3115 | mae_test:  4.2309 | rmse_test:  7.6247 | mape_test:  0.9476 | Time(s)  0.1162 \n",
      "2023-05-01 10:08:14   Epoch 229 | acc_train:  0.0000 | mae_train:  1.0324 | rmse_train:  2.6059 | mae_val:  2.1722 | rmse_val:  5.3090 | mae_test:  4.2279 | rmse_test:  7.6204 | mape_test:  0.9466 | Time(s)  0.1372 \n",
      "2023-05-01 10:08:14   Epoch 230 | acc_train:  0.0000 | mae_train:  1.0321 | rmse_train:  2.6055 | mae_val:  2.1715 | rmse_val:  5.3074 | mae_test:  4.2262 | rmse_test:  7.6181 | mape_test:  0.9461 | Time(s)  0.1191 \n",
      "2023-05-01 10:08:14   Epoch 231 | acc_train:  0.0000 | mae_train:  1.0322 | rmse_train:  2.6057 | mae_val:  2.1707 | rmse_val:  5.3057 | mae_test:  4.2247 | rmse_test:  7.6157 | mape_test:  0.9455 | Time(s)  0.1221 \n",
      "2023-05-01 10:08:15   Epoch 232 | acc_train:  0.0000 | mae_train:  1.0320 | rmse_train:  2.6053 | mae_val:  2.1691 | rmse_val:  5.3024 | mae_test:  4.2201 | rmse_test:  7.6094 | mape_test:  0.9439 | Time(s)  0.1217 \n",
      "2023-05-01 10:08:15   Epoch 233 | acc_train:  0.0000 | mae_train:  1.0318 | rmse_train:  2.6042 | mae_val:  2.1678 | rmse_val:  5.2997 | mae_test:  4.2164 | rmse_test:  7.6042 | mape_test:  0.9427 | Time(s)  0.1247 \n",
      "2023-05-01 10:08:15   Epoch 234 | acc_train:  0.0000 | mae_train:  1.0317 | rmse_train:  2.6037 | mae_val:  2.1669 | rmse_val:  5.2980 | mae_test:  4.2145 | rmse_test:  7.6014 | mape_test:  0.9421 | Time(s)  0.1356 \n",
      "2023-05-01 10:08:15   Epoch 235 | acc_train:  0.0000 | mae_train:  1.0314 | rmse_train:  2.6037 | mae_val:  2.1661 | rmse_val:  5.2961 | mae_test:  4.2123 | rmse_test:  7.5982 | mape_test:  0.9414 | Time(s)  0.1542 \n",
      "2023-05-01 10:08:15   Epoch 236 | acc_train:  0.0000 | mae_train:  1.0314 | rmse_train:  2.6032 | mae_val:  2.1650 | rmse_val:  5.2938 | mae_test:  4.2094 | rmse_test:  7.5942 | mape_test:  0.9404 | Time(s)  0.1516 \n",
      "2023-05-01 10:08:15   Epoch 237 | acc_train:  0.0000 | mae_train:  1.0312 | rmse_train:  2.6030 | mae_val:  2.1640 | rmse_val:  5.2917 | mae_test:  4.2072 | rmse_test:  7.5911 | mape_test:  0.9395 | Time(s)  0.1247 \n",
      "2023-05-01 10:08:16   Epoch 238 | acc_train:  0.0000 | mae_train:  1.0311 | rmse_train:  2.6024 | mae_val:  2.1628 | rmse_val:  5.2893 | mae_test:  4.2047 | rmse_test:  7.5876 | mape_test:  0.9385 | Time(s)  0.1196 \n",
      "2023-05-01 10:08:16   Epoch 239 | acc_train:  0.0000 | mae_train:  1.0309 | rmse_train:  2.6021 | mae_val:  2.1623 | rmse_val:  5.2882 | mae_test:  4.2040 | rmse_test:  7.5864 | mape_test:  0.9382 | Time(s)  0.1616 \n",
      "2023-05-01 10:08:16   Epoch 240 | acc_train:  0.0000 | mae_train:  1.0310 | rmse_train:  2.6023 | mae_val:  2.1614 | rmse_val:  5.2863 | mae_test:  4.2018 | rmse_test:  7.5833 | mape_test:  0.9375 | Time(s)  0.1197 \n",
      "2023-05-01 10:08:16   Epoch 241 | acc_train:  0.0000 | mae_train:  1.0308 | rmse_train:  2.6019 | mae_val:  2.1601 | rmse_val:  5.2835 | mae_test:  4.1978 | rmse_test:  7.5777 | mape_test:  0.9362 | Time(s)  0.1351 \n",
      "2023-05-01 10:08:16   Epoch 242 | acc_train:  0.0000 | mae_train:  1.0307 | rmse_train:  2.6009 | mae_val:  2.1587 | rmse_val:  5.2808 | mae_test:  4.1941 | rmse_test:  7.5726 | mape_test:  0.9349 | Time(s)  0.1192 \n",
      "2023-05-01 10:08:16   Epoch 243 | acc_train:  0.0000 | mae_train:  1.0304 | rmse_train:  2.6004 | mae_val:  2.1582 | rmse_val:  5.2795 | mae_test:  4.1929 | rmse_test:  7.5708 | mape_test:  0.9345 | Time(s)  0.1213 \n",
      "2023-05-01 10:08:17   Epoch 244 | acc_train:  0.0000 | mae_train:  1.0304 | rmse_train:  2.6005 | mae_val:  2.1572 | rmse_val:  5.2774 | mae_test:  4.1903 | rmse_test:  7.5671 | mape_test:  0.9337 | Time(s)  0.1247 \n",
      "2023-05-01 10:08:17   Epoch 245 | acc_train:  0.0000 | mae_train:  1.0302 | rmse_train:  2.5999 | mae_val:  2.1563 | rmse_val:  5.2751 | mae_test:  4.1874 | rmse_test:  7.5632 | mape_test:  0.9327 | Time(s)  0.1197 \n",
      "2023-05-01 10:08:17   Epoch 246 | acc_train:  0.0000 | mae_train:  1.0303 | rmse_train:  2.5997 | mae_val:  2.1552 | rmse_val:  5.2732 | mae_test:  4.1853 | rmse_test:  7.5601 | mape_test:  0.9319 | Time(s)  0.1337 \n",
      "2023-05-01 10:08:17   Epoch 247 | acc_train:  0.0000 | mae_train:  1.0300 | rmse_train:  2.5992 | mae_val:  2.1545 | rmse_val:  5.2715 | mae_test:  4.1833 | rmse_test:  7.5571 | mape_test:  0.9312 | Time(s)  0.1227 \n",
      "2023-05-01 10:08:17   Epoch 248 | acc_train:  0.0000 | mae_train:  1.0300 | rmse_train:  2.5990 | mae_val:  2.1533 | rmse_val:  5.2692 | mae_test:  4.1802 | rmse_test:  7.5529 | mape_test:  0.9302 | Time(s)  0.1227 \n",
      "2023-05-01 10:08:17   Epoch 249 | acc_train:  0.0000 | mae_train:  1.0299 | rmse_train:  2.5983 | mae_val:  2.1521 | rmse_val:  5.2667 | mae_test:  4.1768 | rmse_test:  7.5483 | mape_test:  0.9291 | Time(s)  0.1267 \n",
      "2023-05-01 10:08:17   Epoch 250 | acc_train:  0.0000 | mae_train:  1.0296 | rmse_train:  2.5980 | mae_val:  2.1516 | rmse_val:  5.2657 | mae_test:  4.1760 | rmse_test:  7.5471 | mape_test:  0.9289 | Time(s)  0.1228 \n",
      "2023-05-01 10:08:17   Epoch 251 | acc_train:  0.0000 | mae_train:  1.0296 | rmse_train:  2.5983 | mae_val:  2.1511 | rmse_val:  5.2644 | mae_test:  4.1747 | rmse_test:  7.5451 | mape_test:  0.9285 | Time(s)  0.1227 \n",
      "2023-05-01 10:08:18   Epoch 252 | acc_train:  0.0000 | mae_train:  1.0296 | rmse_train:  2.5980 | mae_val:  2.1496 | rmse_val:  5.2615 | mae_test:  4.1707 | rmse_test:  7.5398 | mape_test:  0.9270 | Time(s)  0.1188 \n",
      "2023-05-01 10:08:18   Epoch 253 | acc_train:  0.0000 | mae_train:  1.0294 | rmse_train:  2.5969 | mae_val:  2.1484 | rmse_val:  5.2588 | mae_test:  4.1668 | rmse_test:  7.5346 | mape_test:  0.9257 | Time(s)  0.1231 \n",
      "2023-05-01 10:08:18   Epoch 254 | acc_train:  0.0000 | mae_train:  1.0293 | rmse_train:  2.5965 | mae_val:  2.1477 | rmse_val:  5.2577 | mae_test:  4.1660 | rmse_test:  7.5333 | mape_test:  0.9254 | Time(s)  0.1222 \n",
      "2023-05-01 10:08:18   Epoch 255 | acc_train:  0.0000 | mae_train:  1.0290 | rmse_train:  2.5966 | mae_val:  2.1469 | rmse_val:  5.2559 | mae_test:  4.1639 | rmse_test:  7.5304 | mape_test:  0.9247 | Time(s)  0.1223 \n",
      "2023-05-01 10:08:18   Epoch 256 | acc_train:  0.0000 | mae_train:  1.0289 | rmse_train:  2.5962 | mae_val:  2.1456 | rmse_val:  5.2533 | mae_test:  4.1599 | rmse_test:  7.5250 | mape_test:  0.9233 | Time(s)  0.1227 \n",
      "2023-05-01 10:08:18   Epoch 257 | acc_train:  0.0000 | mae_train:  1.0291 | rmse_train:  2.5952 | mae_val:  2.1444 | rmse_val:  5.2508 | mae_test:  4.1564 | rmse_test:  7.5202 | mape_test:  0.9221 | Time(s)  0.1217 \n",
      "2023-05-01 10:08:18   Epoch 258 | acc_train:  0.0000 | mae_train:  1.0289 | rmse_train:  2.5948 | mae_val:  2.1440 | rmse_val:  5.2499 | mae_test:  4.1570 | rmse_test:  7.5207 | mape_test:  0.9219 | Time(s)  0.1247 \n",
      "2023-05-01 10:08:19   Epoch 259 | acc_train:  0.0000 | mae_train:  1.0285 | rmse_train:  2.5949 | mae_val:  2.1438 | rmse_val:  5.2493 | mae_test:  4.1571 | rmse_test:  7.5207 | mape_test:  0.9221 | Time(s)  0.1247 \n",
      "2023-05-01 10:08:19   Epoch 260 | acc_train:  0.0000 | mae_train:  1.0287 | rmse_train:  2.5954 | mae_val:  2.1435 | rmse_val:  5.2486 | mae_test:  4.1568 | rmse_test:  7.5199 | mape_test:  0.9220 | Time(s)  0.1181 \n",
      "2023-05-01 10:08:19   Epoch 261 | acc_train:  0.0000 | mae_train:  1.0287 | rmse_train:  2.5954 | mae_val:  2.1424 | rmse_val:  5.2464 | mae_test:  4.1536 | rmse_test:  7.5156 | mape_test:  0.9209 | Time(s)  0.1237 \n",
      "2023-05-01 10:08:19   Epoch 262 | acc_train:  0.0000 | mae_train:  1.0284 | rmse_train:  2.5946 | mae_val:  2.1411 | rmse_val:  5.2437 | mae_test:  4.1496 | rmse_test:  7.5101 | mape_test:  0.9195 | Time(s)  0.1335 \n",
      "2023-05-01 10:08:19   Epoch 263 | acc_train:  0.0000 | mae_train:  1.0285 | rmse_train:  2.5935 | mae_val:  2.1398 | rmse_val:  5.2414 | mae_test:  4.1463 | rmse_test:  7.5057 | mape_test:  0.9182 | Time(s)  0.1222 \n",
      "2023-05-01 10:08:19   Epoch 264 | acc_train:  0.0000 | mae_train:  1.0283 | rmse_train:  2.5930 | mae_val:  2.1394 | rmse_val:  5.2404 | mae_test:  4.1454 | rmse_test:  7.5043 | mape_test:  0.9180 | Time(s)  0.1207 \n",
      "2023-05-01 10:08:19   Epoch 265 | acc_train:  0.0000 | mae_train:  1.0280 | rmse_train:  2.5931 | mae_val:  2.1393 | rmse_val:  5.2400 | mae_test:  4.1457 | rmse_test:  7.5044 | mape_test:  0.9182 | Time(s)  0.1309 \n",
      "2023-05-01 10:08:20   Epoch 266 | acc_train:  0.0000 | mae_train:  1.0281 | rmse_train:  2.5936 | mae_val:  2.1389 | rmse_val:  5.2389 | mae_test:  4.1448 | rmse_test:  7.5031 | mape_test:  0.9180 | Time(s)  0.1193 \n",
      "2023-05-01 10:08:20   Epoch 267 | acc_train:  0.0000 | mae_train:  1.0281 | rmse_train:  2.5934 | mae_val:  2.1380 | rmse_val:  5.2372 | mae_test:  4.1423 | rmse_test:  7.4996 | mape_test:  0.9171 | Time(s)  0.1220 \n",
      "2023-05-01 10:08:20   Epoch 268 | acc_train:  0.0000 | mae_train:  1.0279 | rmse_train:  2.5928 | mae_val:  2.1365 | rmse_val:  5.2344 | mae_test:  4.1379 | rmse_test:  7.4937 | mape_test:  0.9155 | Time(s)  0.1222 \n",
      "2023-05-01 10:08:20   Epoch 269 | acc_train:  0.0000 | mae_train:  1.0280 | rmse_train:  2.5917 | mae_val:  2.1354 | rmse_val:  5.2319 | mae_test:  4.1343 | rmse_test:  7.4888 | mape_test:  0.9142 | Time(s)  0.1213 \n",
      "2023-05-01 10:08:20   Epoch 270 | acc_train:  0.0000 | mae_train:  1.0279 | rmse_train:  2.5911 | mae_val:  2.1350 | rmse_val:  5.2312 | mae_test:  4.1338 | rmse_test:  7.4879 | mape_test:  0.9141 | Time(s)  0.1227 \n",
      "2023-05-01 10:08:20   Epoch 271 | acc_train:  0.0000 | mae_train:  1.0275 | rmse_train:  2.5913 | mae_val:  2.1350 | rmse_val:  5.2309 | mae_test:  4.1342 | rmse_test:  7.4883 | mape_test:  0.9144 | Time(s)  0.1418 \n",
      "2023-05-01 10:08:20   Epoch 272 | acc_train:  0.0000 | mae_train:  1.0276 | rmse_train:  2.5918 | mae_val:  2.1345 | rmse_val:  5.2299 | mae_test:  4.1335 | rmse_test:  7.4872 | mape_test:  0.9142 | Time(s)  0.1207 \n",
      "2023-05-01 10:08:21   Epoch 273 | acc_train:  0.0000 | mae_train:  1.0276 | rmse_train:  2.5917 | mae_val:  2.1336 | rmse_val:  5.2281 | mae_test:  4.1309 | rmse_test:  7.4836 | mape_test:  0.9133 | Time(s)  0.1277 \n",
      "2023-05-01 10:08:21   Epoch 274 | acc_train:  0.0000 | mae_train:  1.0273 | rmse_train:  2.5910 | mae_val:  2.1323 | rmse_val:  5.2254 | mae_test:  4.1267 | rmse_test:  7.4781 | mape_test:  0.9117 | Time(s)  0.1167 \n",
      "2023-05-01 10:08:21   Epoch 275 | acc_train:  0.0000 | mae_train:  1.0275 | rmse_train:  2.5899 | mae_val:  2.1313 | rmse_val:  5.2236 | mae_test:  4.1241 | rmse_test:  7.4745 | mape_test:  0.9107 | Time(s)  0.1266 \n",
      "2023-05-01 10:08:21   Epoch 276 | acc_train:  0.0000 | mae_train:  1.0274 | rmse_train:  2.5895 | mae_val:  2.1309 | rmse_val:  5.2227 | mae_test:  4.1233 | rmse_test:  7.4732 | mape_test:  0.9105 | Time(s)  0.1223 \n",
      "2023-05-01 10:08:21   Epoch 277 | acc_train:  0.0000 | mae_train:  1.0270 | rmse_train:  2.5896 | mae_val:  2.1308 | rmse_val:  5.2222 | mae_test:  4.1235 | rmse_test:  7.4733 | mape_test:  0.9107 | Time(s)  0.1296 \n",
      "2023-05-01 10:08:21   Epoch 278 | acc_train:  0.0000 | mae_train:  1.0271 | rmse_train:  2.5901 | mae_val:  2.1305 | rmse_val:  5.2216 | mae_test:  4.1233 | rmse_test:  7.4728 | mape_test:  0.9107 | Time(s)  0.1187 \n",
      "2023-05-01 10:08:21   Epoch 279 | acc_train:  0.0000 | mae_train:  1.0271 | rmse_train:  2.5900 | mae_val:  2.1298 | rmse_val:  5.2201 | mae_test:  4.1211 | rmse_test:  7.4697 | mape_test:  0.9099 | Time(s)  0.1377 \n",
      "2023-05-01 10:08:22   Epoch 280 | acc_train:  0.0000 | mae_train:  1.0270 | rmse_train:  2.5894 | mae_val:  2.1283 | rmse_val:  5.2174 | mae_test:  4.1169 | rmse_test:  7.4641 | mape_test:  0.9084 | Time(s)  0.1212 \n",
      "2023-05-01 10:08:22   Epoch 281 | acc_train:  0.0000 | mae_train:  1.0271 | rmse_train:  2.5884 | mae_val:  2.1273 | rmse_val:  5.2152 | mae_test:  4.1135 | rmse_test:  7.4597 | mape_test:  0.9072 | Time(s)  0.1257 \n",
      "2023-05-01 10:08:22   Epoch 282 | acc_train:  0.0000 | mae_train:  1.0270 | rmse_train:  2.5879 | mae_val:  2.1269 | rmse_val:  5.2146 | mae_test:  4.1132 | rmse_test:  7.4590 | mape_test:  0.9071 | Time(s)  0.1190 \n",
      "2023-05-01 10:08:22   Epoch 283 | acc_train:  0.0000 | mae_train:  1.0265 | rmse_train:  2.5881 | mae_val:  2.1273 | rmse_val:  5.2149 | mae_test:  4.1146 | rmse_test:  7.4604 | mape_test:  0.9077 | Time(s)  0.1223 \n",
      "2023-05-01 10:08:22   Epoch 284 | acc_train:  0.0000 | mae_train:  1.0270 | rmse_train:  2.5887 | mae_val:  2.1270 | rmse_val:  5.2142 | mae_test:  4.1142 | rmse_test:  7.4597 | mape_test:  0.9077 | Time(s)  0.1267 \n",
      "2023-05-01 10:08:22   Epoch 285 | acc_train:  0.0000 | mae_train:  1.0269 | rmse_train:  2.5886 | mae_val:  2.1258 | rmse_val:  5.2120 | mae_test:  4.1110 | rmse_test:  7.4556 | mape_test:  0.9066 | Time(s)  0.1336 \n",
      "2023-05-01 10:08:22   Epoch 286 | acc_train:  0.0000 | mae_train:  1.0264 | rmse_train:  2.5878 | mae_val:  2.1246 | rmse_val:  5.2097 | mae_test:  4.1072 | rmse_test:  7.4505 | mape_test:  0.9051 | Time(s)  0.1217 \n",
      "2023-05-01 10:08:23   Epoch 287 | acc_train:  0.0000 | mae_train:  1.0265 | rmse_train:  2.5869 | mae_val:  2.1238 | rmse_val:  5.2081 | mae_test:  4.1049 | rmse_test:  7.4473 | mape_test:  0.9043 | Time(s)  0.1316 \n",
      "2023-05-01 10:08:23   Epoch 288 | acc_train:  0.0000 | mae_train:  1.0265 | rmse_train:  2.5865 | mae_val:  2.1234 | rmse_val:  5.2071 | mae_test:  4.1041 | rmse_test:  7.4461 | mape_test:  0.9040 | Time(s)  0.1177 \n",
      "2023-05-01 10:08:23   Epoch 289 | acc_train:  0.0000 | mae_train:  1.0261 | rmse_train:  2.5866 | mae_val:  2.1233 | rmse_val:  5.2067 | mae_test:  4.1044 | rmse_test:  7.4464 | mape_test:  0.9043 | Time(s)  0.1204 \n",
      "2023-05-01 10:08:23   Epoch 290 | acc_train:  0.0000 | mae_train:  1.0263 | rmse_train:  2.5871 | mae_val:  2.1231 | rmse_val:  5.2063 | mae_test:  4.1048 | rmse_test:  7.4466 | mape_test:  0.9044 | Time(s)  0.1223 \n",
      "2023-05-01 10:08:23   Epoch 291 | acc_train:  0.0000 | mae_train:  1.0263 | rmse_train:  2.5871 | mae_val:  2.1222 | rmse_val:  5.2046 | mae_test:  4.1022 | rmse_test:  7.4432 | mape_test:  0.9035 | Time(s)  0.1177 \n",
      "2023-05-01 10:08:23   Epoch 292 | acc_train:  0.0000 | mae_train:  1.0260 | rmse_train:  2.5864 | mae_val:  2.1210 | rmse_val:  5.2020 | mae_test:  4.0979 | rmse_test:  7.4377 | mape_test:  0.9019 | Time(s)  0.1237 \n",
      "2023-05-01 10:08:23   Epoch 293 | acc_train:  0.0000 | mae_train:  1.0263 | rmse_train:  2.5854 | mae_val:  2.1200 | rmse_val:  5.2004 | mae_test:  4.0957 | rmse_test:  7.4346 | mape_test:  0.9010 | Time(s)  0.1216 \n",
      "2023-05-01 10:08:24   Epoch 294 | acc_train:  0.0000 | mae_train:  1.0259 | rmse_train:  2.5850 | mae_val:  2.1200 | rmse_val:  5.2000 | mae_test:  4.0959 | rmse_test:  7.4345 | mape_test:  0.9011 | Time(s)  0.1182 \n",
      "2023-05-01 10:08:24   Epoch 295 | acc_train:  0.0000 | mae_train:  1.0259 | rmse_train:  2.5853 | mae_val:  2.1195 | rmse_val:  5.1989 | mae_test:  4.0947 | rmse_test:  7.4328 | mape_test:  0.9007 | Time(s)  0.1292 \n",
      "2023-05-01 10:08:24   Epoch 296 | acc_train:  0.0000 | mae_train:  1.0258 | rmse_train:  2.5850 | mae_val:  2.1187 | rmse_val:  5.1976 | mae_test:  4.0930 | rmse_test:  7.4306 | mape_test:  0.9002 | Time(s)  0.1177 \n",
      "2023-05-01 10:08:24   Epoch 297 | acc_train:  0.0000 | mae_train:  1.0256 | rmse_train:  2.5849 | mae_val:  2.1181 | rmse_val:  5.1965 | mae_test:  4.0916 | rmse_test:  7.4287 | mape_test:  0.8997 | Time(s)  0.1217 \n",
      "2023-05-01 10:08:24   Epoch 298 | acc_train:  0.0000 | mae_train:  1.0254 | rmse_train:  2.5846 | mae_val:  2.1171 | rmse_val:  5.1944 | mae_test:  4.0887 | rmse_test:  7.4249 | mape_test:  0.8986 | Time(s)  0.1172 \n",
      "2023-05-01 10:08:24   Epoch 299 | acc_train:  0.0000 | mae_train:  1.0257 | rmse_train:  2.5838 | mae_val:  2.1164 | rmse_val:  5.1931 | mae_test:  4.0868 | rmse_test:  7.4223 | mape_test:  0.8978 | Time(s)  0.1217 \n",
      "2023-05-01 10:08:24   Epoch 300 | acc_train:  0.0000 | mae_train:  1.0255 | rmse_train:  2.5835 | mae_val:  2.1160 | rmse_val:  5.1922 | mae_test:  4.0861 | rmse_test:  7.4213 | mape_test:  0.8977 | Time(s)  0.1247 \n",
      "2023-05-01 10:08:25   Epoch 301 | acc_train:  0.0000 | mae_train:  1.0252 | rmse_train:  2.5837 | mae_val:  2.1156 | rmse_val:  5.1913 | mae_test:  4.0852 | rmse_test:  7.4200 | mape_test:  0.8974 | Time(s)  0.1376 \n",
      "2023-05-01 10:08:25   Epoch 302 | acc_train:  0.0000 | mae_train:  1.0252 | rmse_train:  2.5835 | mae_val:  2.1152 | rmse_val:  5.1903 | mae_test:  4.0840 | rmse_test:  7.4183 | mape_test:  0.8971 | Time(s)  0.1377 \n",
      "2023-05-01 10:08:25   Epoch 303 | acc_train:  0.0000 | mae_train:  1.0252 | rmse_train:  2.5835 | mae_val:  2.1147 | rmse_val:  5.1894 | mae_test:  4.0833 | rmse_test:  7.4171 | mape_test:  0.8968 | Time(s)  0.1471 \n",
      "2023-05-01 10:08:25   Epoch 304 | acc_train:  0.0000 | mae_train:  1.0251 | rmse_train:  2.5832 | mae_val:  2.1137 | rmse_val:  5.1875 | mae_test:  4.0802 | rmse_test:  7.4130 | mape_test:  0.8957 | Time(s)  0.1397 \n",
      "2023-05-01 10:08:25   Epoch 305 | acc_train:  0.0000 | mae_train:  1.0252 | rmse_train:  2.5824 | mae_val:  2.1128 | rmse_val:  5.1857 | mae_test:  4.0775 | rmse_test:  7.4096 | mape_test:  0.8947 | Time(s)  0.1800 \n",
      "2023-05-01 10:08:25   Epoch 306 | acc_train:  0.0000 | mae_train:  1.0251 | rmse_train:  2.5821 | mae_val:  2.1127 | rmse_val:  5.1854 | mae_test:  4.0778 | rmse_test:  7.4096 | mape_test:  0.8949 | Time(s)  0.1197 \n",
      "2023-05-01 10:08:26   Epoch 307 | acc_train:  0.0000 | mae_train:  1.0249 | rmse_train:  2.5824 | mae_val:  2.1122 | rmse_val:  5.1845 | mae_test:  4.0768 | rmse_test:  7.4082 | mape_test:  0.8946 | Time(s)  0.1705 \n",
      "2023-05-01 10:08:26   Epoch 308 | acc_train:  0.0000 | mae_train:  1.0248 | rmse_train:  2.5822 | mae_val:  2.1113 | rmse_val:  5.1825 | mae_test:  4.0737 | rmse_test:  7.4042 | mape_test:  0.8934 | Time(s)  0.1297 \n",
      "2023-05-01 10:08:26   Epoch 309 | acc_train:  0.0000 | mae_train:  1.0250 | rmse_train:  2.5814 | mae_val:  2.1106 | rmse_val:  5.1813 | mae_test:  4.0720 | rmse_test:  7.4019 | mape_test:  0.8929 | Time(s)  0.1387 \n",
      "2023-05-01 10:08:26   Epoch 310 | acc_train:  0.0000 | mae_train:  1.0247 | rmse_train:  2.5812 | mae_val:  2.1103 | rmse_val:  5.1807 | mae_test:  4.0718 | rmse_test:  7.4014 | mape_test:  0.8929 | Time(s)  0.1227 \n",
      "2023-05-01 10:08:26   Epoch 311 | acc_train:  0.0000 | mae_train:  1.0246 | rmse_train:  2.5815 | mae_val:  2.1099 | rmse_val:  5.1797 | mae_test:  4.0707 | rmse_test:  7.3999 | mape_test:  0.8925 | Time(s)  0.1233 \n",
      "2023-05-01 10:08:26   Epoch 312 | acc_train:  0.0000 | mae_train:  1.0246 | rmse_train:  2.5812 | mae_val:  2.1091 | rmse_val:  5.1782 | mae_test:  4.0687 | rmse_test:  7.3972 | mape_test:  0.8917 | Time(s)  0.1187 \n",
      "2023-05-01 10:08:26   Epoch 313 | acc_train:  0.0000 | mae_train:  1.0246 | rmse_train:  2.5806 | mae_val:  2.1083 | rmse_val:  5.1767 | mae_test:  4.0666 | rmse_test:  7.3944 | mape_test:  0.8909 | Time(s)  0.1376 \n",
      "2023-05-01 10:08:27   Epoch 314 | acc_train:  0.0000 | mae_train:  1.0244 | rmse_train:  2.5804 | mae_val:  2.1082 | rmse_val:  5.1763 | mae_test:  4.0667 | rmse_test:  7.3942 | mape_test:  0.8910 | Time(s)  0.1187 \n",
      "2023-05-01 10:08:27   Epoch 315 | acc_train:  0.0000 | mae_train:  1.0244 | rmse_train:  2.5806 | mae_val:  2.1077 | rmse_val:  5.1753 | mae_test:  4.0655 | rmse_test:  7.3926 | mape_test:  0.8907 | Time(s)  0.1286 \n",
      "2023-05-01 10:08:27   Epoch 316 | acc_train:  0.0000 | mae_train:  1.0243 | rmse_train:  2.5804 | mae_val:  2.1068 | rmse_val:  5.1737 | mae_test:  4.0630 | rmse_test:  7.3894 | mape_test:  0.8898 | Time(s)  0.1187 \n",
      "2023-05-01 10:08:27   Epoch 317 | acc_train:  0.0000 | mae_train:  1.0242 | rmse_train:  2.5798 | mae_val:  2.1064 | rmse_val:  5.1727 | mae_test:  4.0651 | rmse_test:  7.3923 | mape_test:  0.8891 | Time(s)  0.1261 \n",
      "2023-05-01 10:08:27   Epoch 318 | acc_train:  0.0000 | mae_train:  1.0242 | rmse_train:  2.5796 | mae_val:  2.1061 | rmse_val:  5.1720 | mae_test:  4.0649 | rmse_test:  7.3918 | mape_test:  0.8891 | Time(s)  0.1156 \n",
      "2023-05-01 10:08:27   Epoch 319 | acc_train:  0.0000 | mae_train:  1.0242 | rmse_train:  2.5798 | mae_val:  2.1056 | rmse_val:  5.1709 | mae_test:  4.0635 | rmse_test:  7.3900 | mape_test:  0.8887 | Time(s)  0.1186 \n",
      "2023-05-01 10:08:27   Epoch 320 | acc_train:  0.0000 | mae_train:  1.0242 | rmse_train:  2.5796 | mae_val:  2.1047 | rmse_val:  5.1693 | mae_test:  4.0611 | rmse_test:  7.3868 | mape_test:  0.8877 | Time(s)  0.1197 \n",
      "2023-05-01 10:08:28   Epoch 321 | acc_train:  0.0000 | mae_train:  1.0240 | rmse_train:  2.5789 | mae_val:  2.1042 | rmse_val:  5.1683 | mae_test:  4.0599 | rmse_test:  7.3851 | mape_test:  0.8873 | Time(s)  0.1346 \n",
      "2023-05-01 10:08:28   Epoch 322 | acc_train:  0.0000 | mae_train:  1.0239 | rmse_train:  2.5788 | mae_val:  2.1035 | rmse_val:  5.1671 | mae_test:  4.0581 | rmse_test:  7.3827 | mape_test:  0.8866 | Time(s)  0.1207 \n",
      "2023-05-01 10:08:28   Epoch 323 | acc_train:  0.0000 | mae_train:  1.0240 | rmse_train:  2.5783 | mae_val:  2.1027 | rmse_val:  5.1657 | mae_test:  4.0561 | rmse_test:  7.3801 | mape_test:  0.8860 | Time(s)  0.1265 \n",
      "2023-05-01 10:08:28   Epoch 324 | acc_train:  0.0000 | mae_train:  1.0236 | rmse_train:  2.5782 | mae_val:  2.1027 | rmse_val:  5.1654 | mae_test:  4.0566 | rmse_test:  7.3805 | mape_test:  0.8862 | Time(s)  0.1247 \n",
      "2023-05-01 10:08:28   Epoch 325 | acc_train:  0.0000 | mae_train:  1.0237 | rmse_train:  2.5785 | mae_val:  2.1023 | rmse_val:  5.1646 | mae_test:  4.0558 | rmse_test:  7.3794 | mape_test:  0.8860 | Time(s)  0.1188 \n",
      "2023-05-01 10:08:28   Epoch 326 | acc_train:  0.0000 | mae_train:  1.0237 | rmse_train:  2.5784 | mae_val:  2.1016 | rmse_val:  5.1632 | mae_test:  4.0537 | rmse_test:  7.3766 | mape_test:  0.8852 | Time(s)  0.1217 \n",
      "2023-05-01 10:08:28   Epoch 327 | acc_train:  0.0000 | mae_train:  1.0235 | rmse_train:  2.5778 | mae_val:  2.1003 | rmse_val:  5.1610 | mae_test:  4.0499 | rmse_test:  7.3719 | mape_test:  0.8838 | Time(s)  0.1187 \n",
      "2023-05-01 10:08:28   Epoch 328 | acc_train:  0.0000 | mae_train:  1.0237 | rmse_train:  2.5769 | mae_val:  2.0995 | rmse_val:  5.1595 | mae_test:  4.0474 | rmse_test:  7.3688 | mape_test:  0.8828 | Time(s)  0.1165 \n",
      "2023-05-01 10:08:29   Epoch 329 | acc_train:  0.0000 | mae_train:  1.0236 | rmse_train:  2.5765 | mae_val:  2.0992 | rmse_val:  5.1587 | mae_test:  4.0467 | rmse_test:  7.3677 | mape_test:  0.8827 | Time(s)  0.1187 \n",
      "2023-05-01 10:08:29   Epoch 330 | acc_train:  0.0000 | mae_train:  1.0233 | rmse_train:  2.5766 | mae_val:  2.0993 | rmse_val:  5.1588 | mae_test:  4.0479 | rmse_test:  7.3688 | mape_test:  0.8832 | Time(s)  0.1157 \n",
      "2023-05-01 10:08:29   Epoch 331 | acc_train:  0.0000 | mae_train:  1.0233 | rmse_train:  2.5771 | mae_val:  2.0991 | rmse_val:  5.1581 | mae_test:  4.0475 | rmse_test:  7.3681 | mape_test:  0.8832 | Time(s)  0.1471 \n",
      "2023-05-01 10:08:29   Epoch 332 | acc_train:  0.0000 | mae_train:  1.0233 | rmse_train:  2.5771 | mae_val:  2.0983 | rmse_val:  5.1569 | mae_test:  4.0459 | rmse_test:  7.3661 | mape_test:  0.8824 | Time(s)  0.1145 \n",
      "2023-05-01 10:08:29   Epoch 333 | acc_train:  0.0000 | mae_train:  1.0231 | rmse_train:  2.5766 | mae_val:  2.0972 | rmse_val:  5.1549 | mae_test:  4.0426 | rmse_test:  7.3619 | mape_test:  0.8811 | Time(s)  0.1328 \n",
      "2023-05-01 10:08:29   Epoch 334 | acc_train:  0.0000 | mae_train:  1.0233 | rmse_train:  2.5757 | mae_val:  2.0964 | rmse_val:  5.1534 | mae_test:  4.0399 | rmse_test:  7.3587 | mape_test:  0.8802 | Time(s)  0.1424 \n",
      "2023-05-01 10:08:30   Epoch 335 | acc_train:  0.0000 | mae_train:  1.0232 | rmse_train:  2.5754 | mae_val:  2.0963 | rmse_val:  5.1529 | mae_test:  4.0399 | rmse_test:  7.3584 | mape_test:  0.8802 | Time(s)  0.1506 \n",
      "2023-05-01 10:08:30   Epoch 336 | acc_train:  0.0000 | mae_train:  1.0229 | rmse_train:  2.5756 | mae_val:  2.0962 | rmse_val:  5.1527 | mae_test:  4.0405 | rmse_test:  7.3589 | mape_test:  0.8806 | Time(s)  0.1244 \n",
      "2023-05-01 10:08:30   Epoch 337 | acc_train:  0.0000 | mae_train:  1.0230 | rmse_train:  2.5760 | mae_val:  2.0961 | rmse_val:  5.1522 | mae_test:  4.0405 | rmse_test:  7.3587 | mape_test:  0.8807 | Time(s)  0.1936 \n",
      "2023-05-01 10:08:30   Epoch 338 | acc_train:  0.0000 | mae_train:  1.0230 | rmse_train:  2.5760 | mae_val:  2.0953 | rmse_val:  5.1507 | mae_test:  4.0383 | rmse_test:  7.3559 | mape_test:  0.8798 | Time(s)  0.1398 \n",
      "2023-05-01 10:08:30   Epoch 339 | acc_train:  0.0000 | mae_train:  1.0229 | rmse_train:  2.5755 | mae_val:  2.0943 | rmse_val:  5.1491 | mae_test:  4.0355 | rmse_test:  7.3524 | mape_test:  0.8787 | Time(s)  0.1969 \n",
      "2023-05-01 10:08:30   Epoch 340 | acc_train:  0.0000 | mae_train:  1.0228 | rmse_train:  2.5747 | mae_val:  2.0934 | rmse_val:  5.1476 | mae_test:  4.0330 | rmse_test:  7.3493 | mape_test:  0.8778 | Time(s)  0.1232 \n",
      "2023-05-01 10:08:31   Epoch 341 | acc_train:  0.0000 | mae_train:  1.0227 | rmse_train:  2.5743 | mae_val:  2.0932 | rmse_val:  5.1468 | mae_test:  4.0324 | rmse_test:  7.3484 | mape_test:  0.8776 | Time(s)  0.1546 \n",
      "2023-05-01 10:08:31   Epoch 342 | acc_train:  0.0000 | mae_train:  1.0225 | rmse_train:  2.5745 | mae_val:  2.0929 | rmse_val:  5.1462 | mae_test:  4.0320 | rmse_test:  7.3476 | mape_test:  0.8775 | Time(s)  0.1197 \n",
      "2023-05-01 10:08:31   Epoch 343 | acc_train:  0.0000 | mae_train:  1.0225 | rmse_train:  2.5743 | mae_val:  2.0920 | rmse_val:  5.1447 | mae_test:  4.0296 | rmse_test:  7.3445 | mape_test:  0.8765 | Time(s)  0.1681 \n",
      "2023-05-01 10:08:31   Epoch 344 | acc_train:  0.0000 | mae_train:  1.0226 | rmse_train:  2.5737 | mae_val:  2.0913 | rmse_val:  5.1433 | mae_test:  4.0275 | rmse_test:  7.3419 | mape_test:  0.8757 | Time(s)  0.1442 \n",
      "2023-05-01 10:08:31   Epoch 345 | acc_train:  0.0000 | mae_train:  1.0225 | rmse_train:  2.5734 | mae_val:  2.0912 | rmse_val:  5.1431 | mae_test:  4.0279 | rmse_test:  7.3420 | mape_test:  0.8760 | Time(s)  0.1506 \n",
      "2023-05-01 10:08:31   Epoch 346 | acc_train:  0.0000 | mae_train:  1.0222 | rmse_train:  2.5737 | mae_val:  2.0908 | rmse_val:  5.1423 | mae_test:  4.0272 | rmse_test:  7.3410 | mape_test:  0.8758 | Time(s)  0.1257 \n",
      "2023-05-01 10:08:32   Epoch 347 | acc_train:  0.0000 | mae_train:  1.0222 | rmse_train:  2.5735 | mae_val:  2.0901 | rmse_val:  5.1407 | mae_test:  4.0245 | rmse_test:  7.3377 | mape_test:  0.8748 | Time(s)  0.1875 \n",
      "2023-05-01 10:08:32   Epoch 348 | acc_train:  0.0000 | mae_train:  1.0225 | rmse_train:  2.5729 | mae_val:  2.0894 | rmse_val:  5.1398 | mae_test:  4.0235 | rmse_test:  7.3362 | mape_test:  0.8743 | Time(s)  0.1167 \n",
      "2023-05-01 10:08:32   Epoch 349 | acc_train:  0.0000 | mae_train:  1.0221 | rmse_train:  2.5728 | mae_val:  2.0897 | rmse_val:  5.1397 | mae_test:  4.0282 | rmse_test:  7.3422 | mape_test:  0.8744 | Time(s)  0.1745 \n",
      "2023-05-01 10:08:32   Epoch 350 | acc_train:  0.0000 | mae_train:  1.0224 | rmse_train:  2.5732 | mae_val:  2.0894 | rmse_val:  5.1390 | mae_test:  4.0276 | rmse_test:  7.3413 | mape_test:  0.8743 | Time(s)  0.1372 \n",
      "2023-05-01 10:08:32   Epoch 351 | acc_train:  0.0000 | mae_train:  1.0223 | rmse_train:  2.5730 | mae_val:  2.0882 | rmse_val:  5.1373 | mae_test:  4.0248 | rmse_test:  7.3378 | mape_test:  0.8732 | Time(s)  0.1696 \n",
      "2023-05-01 10:08:32   Epoch 352 | acc_train:  0.0000 | mae_train:  1.0220 | rmse_train:  2.5724 | mae_val:  2.0877 | rmse_val:  5.1364 | mae_test:  4.0234 | rmse_test:  7.3359 | mape_test:  0.8727 | Time(s)  0.1197 \n",
      "2023-05-01 10:08:33   Epoch 353 | acc_train:  0.0000 | mae_train:  1.0218 | rmse_train:  2.5722 | mae_val:  2.0873 | rmse_val:  5.1355 | mae_test:  4.0221 | rmse_test:  7.3342 | mape_test:  0.8722 | Time(s)  0.1347 \n",
      "2023-05-01 10:08:33   Epoch 354 | acc_train:  0.0000 | mae_train:  1.0219 | rmse_train:  2.5719 | mae_val:  2.0871 | rmse_val:  5.1350 | mae_test:  4.0218 | rmse_test:  7.3335 | mape_test:  0.8722 | Time(s)  0.1217 \n",
      "2023-05-01 10:08:33   Epoch 355 | acc_train:  0.0000 | mae_train:  1.0218 | rmse_train:  2.5719 | mae_val:  2.0867 | rmse_val:  5.1343 | mae_test:  4.0208 | rmse_test:  7.3322 | mape_test:  0.8718 | Time(s)  0.1302 \n",
      "2023-05-01 10:08:33   Epoch 356 | acc_train:  0.0000 | mae_train:  1.0217 | rmse_train:  2.5717 | mae_val:  2.0865 | rmse_val:  5.1339 | mae_test:  4.0205 | rmse_test:  7.3317 | mape_test:  0.8718 | Time(s)  0.1234 \n",
      "2023-05-01 10:08:33   Epoch 357 | acc_train:  0.0000 | mae_train:  1.0217 | rmse_train:  2.5717 | mae_val:  2.0863 | rmse_val:  5.1332 | mae_test:  4.0198 | rmse_test:  7.3306 | mape_test:  0.8715 | Time(s)  0.1243 \n",
      "2023-05-01 10:08:33   Epoch 358 | acc_train:  0.0000 | mae_train:  1.0217 | rmse_train:  2.5715 | mae_val:  2.0857 | rmse_val:  5.1324 | mae_test:  4.0183 | rmse_test:  7.3287 | mape_test:  0.8709 | Time(s)  0.1182 \n",
      "2023-05-01 10:08:33   Epoch 359 | acc_train:  0.0000 | mae_train:  1.0218 | rmse_train:  2.5710 | mae_val:  2.0853 | rmse_val:  5.1316 | mae_test:  4.0217 | rmse_test:  7.3335 | mape_test:  0.8703 | Time(s)  0.1206 \n",
      "2023-05-01 10:08:33   Epoch 360 | acc_train:  0.0000 | mae_train:  1.0216 | rmse_train:  2.5709 | mae_val:  2.0854 | rmse_val:  5.1314 | mae_test:  4.0175 | rmse_test:  7.3274 | mape_test:  0.8707 | Time(s)  0.1167 \n",
      "2023-05-01 10:08:34   Epoch 361 | acc_train:  0.0000 | mae_train:  1.0216 | rmse_train:  2.5712 | mae_val:  2.0854 | rmse_val:  5.1314 | mae_test:  4.0227 | rmse_test:  7.3343 | mape_test:  0.8708 | Time(s)  0.1257 \n",
      "2023-05-01 10:08:34   Epoch 362 | acc_train:  0.0000 | mae_train:  1.0216 | rmse_train:  2.5712 | mae_val:  2.0849 | rmse_val:  5.1305 | mae_test:  4.0212 | rmse_test:  7.3323 | mape_test:  0.8702 | Time(s)  0.1166 \n",
      "2023-05-01 10:08:34   Epoch 363 | acc_train:  0.0000 | mae_train:  1.0214 | rmse_train:  2.5707 | mae_val:  2.0841 | rmse_val:  5.1290 | mae_test:  4.0183 | rmse_test:  7.3287 | mape_test:  0.8691 | Time(s)  0.1167 \n",
      "2023-05-01 10:08:34   Epoch 364 | acc_train:  0.0000 | mae_train:  1.0218 | rmse_train:  2.5700 | mae_val:  2.0836 | rmse_val:  5.1283 | mae_test:  4.0171 | rmse_test:  7.3271 | mape_test:  0.8686 | Time(s)  0.1162 \n",
      "2023-05-01 10:08:34   Epoch 365 | acc_train:  0.0000 | mae_train:  1.0215 | rmse_train:  2.5698 | mae_val:  2.0840 | rmse_val:  5.1286 | mae_test:  4.0186 | rmse_test:  7.3285 | mape_test:  0.8691 | Time(s)  0.1157 \n",
      "2023-05-01 10:08:34   Epoch 366 | acc_train:  0.0000 | mae_train:  1.0215 | rmse_train:  2.5702 | mae_val:  2.0839 | rmse_val:  5.1283 | mae_test:  4.0186 | rmse_test:  7.3283 | mape_test:  0.8692 | Time(s)  0.1407 \n",
      "2023-05-01 10:08:34   Epoch 367 | acc_train:  0.0000 | mae_train:  1.0214 | rmse_train:  2.5701 | mae_val:  2.0830 | rmse_val:  5.1270 | mae_test:  4.0161 | rmse_test:  7.3253 | mape_test:  0.8684 | Time(s)  0.1332 \n",
      "2023-05-01 10:08:35   Epoch 368 | acc_train:  0.0000 | mae_train:  1.0214 | rmse_train:  2.5696 | mae_val:  2.0827 | rmse_val:  5.1264 | mae_test:  4.0153 | rmse_test:  7.3242 | mape_test:  0.8681 | Time(s)  0.1177 \n",
      "2023-05-01 10:08:35   Epoch 369 | acc_train:  0.0000 | mae_train:  1.0211 | rmse_train:  2.5695 | mae_val:  2.0832 | rmse_val:  5.1268 | mae_test:  4.0167 | rmse_test:  7.3254 | mape_test:  0.8687 | Time(s)  0.1207 \n",
      "2023-05-01 10:08:35   Epoch 370 | acc_train:  0.0000 | mae_train:  1.0214 | rmse_train:  2.5699 | mae_val:  2.0831 | rmse_val:  5.1265 | mae_test:  4.0168 | rmse_test:  7.3254 | mape_test:  0.8688 | Time(s)  0.1152 \n",
      "2023-05-01 10:08:35   Epoch 371 | acc_train:  0.0000 | mae_train:  1.0213 | rmse_train:  2.5699 | mae_val:  2.0825 | rmse_val:  5.1255 | mae_test:  4.0150 | rmse_test:  7.3232 | mape_test:  0.8681 | Time(s)  0.1226 \n",
      "2023-05-01 10:08:35   Epoch 372 | acc_train:  0.0000 | mae_train:  1.0211 | rmse_train:  2.5694 | mae_val:  2.0818 | rmse_val:  5.1244 | mae_test:  4.0129 | rmse_test:  7.3205 | mape_test:  0.8673 | Time(s)  0.1202 \n",
      "2023-05-01 10:08:35   Epoch 373 | acc_train:  0.0000 | mae_train:  1.0212 | rmse_train:  2.5688 | mae_val:  2.0813 | rmse_val:  5.1236 | mae_test:  4.0119 | rmse_test:  7.3191 | mape_test:  0.8668 | Time(s)  0.1227 \n",
      "2023-05-01 10:08:35   Epoch 374 | acc_train:  0.0000 | mae_train:  1.0210 | rmse_train:  2.5686 | mae_val:  2.0814 | rmse_val:  5.1235 | mae_test:  4.0121 | rmse_test:  7.3191 | mape_test:  0.8670 | Time(s)  0.1133 \n",
      "2023-05-01 10:08:35   Epoch 375 | acc_train:  0.0000 | mae_train:  1.0208 | rmse_train:  2.5688 | mae_val:  2.0813 | rmse_val:  5.1232 | mae_test:  4.0121 | rmse_test:  7.3189 | mape_test:  0.8671 | Time(s)  0.1177 \n",
      "2023-05-01 10:08:36   Epoch 376 | acc_train:  0.0000 | mae_train:  1.0209 | rmse_train:  2.5688 | mae_val:  2.0809 | rmse_val:  5.1226 | mae_test:  4.0109 | rmse_test:  7.3173 | mape_test:  0.8667 | Time(s)  0.1206 \n",
      "2023-05-01 10:08:36   Epoch 377 | acc_train:  0.0000 | mae_train:  1.0209 | rmse_train:  2.5683 | mae_val:  2.0805 | rmse_val:  5.1219 | mae_test:  4.0100 | rmse_test:  7.3160 | mape_test:  0.8663 | Time(s)  0.1216 \n",
      "2023-05-01 10:08:36   Epoch 378 | acc_train:  0.0000 | mae_train:  1.0207 | rmse_train:  2.5683 | mae_val:  2.0803 | rmse_val:  5.1212 | mae_test:  4.0091 | rmse_test:  7.3148 | mape_test:  0.8660 | Time(s)  0.1176 \n",
      "2023-05-01 10:08:36   Epoch 379 | acc_train:  0.0000 | mae_train:  1.0208 | rmse_train:  2.5680 | mae_val:  2.0801 | rmse_val:  5.1210 | mae_test:  4.0090 | rmse_test:  7.3145 | mape_test:  0.8660 | Time(s)  0.1237 \n",
      "2023-05-01 10:08:36   Epoch 380 | acc_train:  0.0000 | mae_train:  1.0206 | rmse_train:  2.5680 | mae_val:  2.0799 | rmse_val:  5.1205 | mae_test:  4.0085 | rmse_test:  7.3137 | mape_test:  0.8659 | Time(s)  0.1158 \n",
      "2023-05-01 10:08:36   Epoch 381 | acc_train:  0.0000 | mae_train:  1.0206 | rmse_train:  2.5678 | mae_val:  2.0795 | rmse_val:  5.1197 | mae_test:  4.0073 | rmse_test:  7.3121 | mape_test:  0.8652 | Time(s)  0.1196 \n",
      "2023-05-01 10:08:36   Epoch 382 | acc_train:  0.0000 | mae_train:  1.0209 | rmse_train:  2.5674 | mae_val:  2.0790 | rmse_val:  5.1189 | mae_test:  4.0056 | rmse_test:  7.3100 | mape_test:  0.8647 | Time(s)  0.1200 \n",
      "2023-05-01 10:08:37   Epoch 383 | acc_train:  0.0000 | mae_train:  1.0206 | rmse_train:  2.5672 | mae_val:  2.0792 | rmse_val:  5.1190 | mae_test:  4.0067 | rmse_test:  7.3109 | mape_test:  0.8652 | Time(s)  0.1188 \n",
      "2023-05-01 10:08:37   Epoch 384 | acc_train:  0.0000 | mae_train:  1.0205 | rmse_train:  2.5675 | mae_val:  2.0791 | rmse_val:  5.1188 | mae_test:  4.0068 | rmse_test:  7.3109 | mape_test:  0.8654 | Time(s)  0.1117 \n",
      "2023-05-01 10:08:37   Epoch 385 | acc_train:  0.0000 | mae_train:  1.0205 | rmse_train:  2.5675 | mae_val:  2.0787 | rmse_val:  5.1178 | mae_test:  4.0051 | rmse_test:  7.3087 | mape_test:  0.8647 | Time(s)  0.1148 \n",
      "2023-05-01 10:08:37   Epoch 386 | acc_train:  0.0000 | mae_train:  1.0206 | rmse_train:  2.5670 | mae_val:  2.0784 | rmse_val:  5.1174 | mae_test:  4.0047 | rmse_test:  7.3080 | mape_test:  0.8646 | Time(s)  0.1237 \n",
      "2023-05-01 10:08:37   Epoch 387 | acc_train:  0.0000 | mae_train:  1.0204 | rmse_train:  2.5670 | mae_val:  2.0784 | rmse_val:  5.1172 | mae_test:  4.0049 | rmse_test:  7.3080 | mape_test:  0.8645 | Time(s)  0.1253 \n",
      "2023-05-01 10:08:37   Epoch 388 | acc_train:  0.0000 | mae_train:  1.0205 | rmse_train:  2.5669 | mae_val:  2.0777 | rmse_val:  5.1161 | mae_test:  4.0028 | rmse_test:  7.3054 | mape_test:  0.8637 | Time(s)  0.1212 \n",
      "2023-05-01 10:08:37   Epoch 389 | acc_train:  0.0000 | mae_train:  1.0206 | rmse_train:  2.5663 | mae_val:  2.0772 | rmse_val:  5.1151 | mae_test:  4.0008 | rmse_test:  7.3029 | mape_test:  0.8631 | Time(s)  0.1255 \n",
      "2023-05-01 10:08:37   Epoch 390 | acc_train:  0.0000 | mae_train:  1.0205 | rmse_train:  2.5661 | mae_val:  2.0773 | rmse_val:  5.1151 | mae_test:  4.0016 | rmse_test:  7.3036 | mape_test:  0.8635 | Time(s)  0.1162 \n",
      "2023-05-01 10:08:38   Epoch 391 | acc_train:  0.0000 | mae_train:  1.0202 | rmse_train:  2.5664 | mae_val:  2.0774 | rmse_val:  5.1152 | mae_test:  4.0024 | rmse_test:  7.3042 | mape_test:  0.8638 | Time(s)  0.1277 \n",
      "2023-05-01 10:08:38   Epoch 392 | acc_train:  0.0000 | mae_train:  1.0203 | rmse_train:  2.5664 | mae_val:  2.0768 | rmse_val:  5.1143 | mae_test:  4.0009 | rmse_test:  7.3024 | mape_test:  0.8632 | Time(s)  0.1247 \n",
      "2023-05-01 10:08:38   Epoch 393 | acc_train:  0.0000 | mae_train:  1.0201 | rmse_train:  2.5660 | mae_val:  2.0766 | rmse_val:  5.1138 | mae_test:  4.0002 | rmse_test:  7.3014 | mape_test:  0.8629 | Time(s)  0.1177 \n",
      "2023-05-01 10:08:38   Epoch 394 | acc_train:  0.0000 | mae_train:  1.0200 | rmse_train:  2.5659 | mae_val:  2.0763 | rmse_val:  5.1131 | mae_test:  3.9993 | rmse_test:  7.3001 | mape_test:  0.8626 | Time(s)  0.1206 \n",
      "2023-05-01 10:08:38   Epoch 395 | acc_train:  0.0000 | mae_train:  1.0201 | rmse_train:  2.5656 | mae_val:  2.0763 | rmse_val:  5.1130 | mae_test:  3.9998 | rmse_test:  7.3004 | mape_test:  0.8627 | Time(s)  0.1276 \n",
      "2023-05-01 10:08:38   Epoch 396 | acc_train:  0.0000 | mae_train:  1.0201 | rmse_train:  2.5657 | mae_val:  2.0761 | rmse_val:  5.1126 | mae_test:  3.9991 | rmse_test:  7.2994 | mape_test:  0.8626 | Time(s)  0.1198 \n",
      "2023-05-01 10:08:38   Epoch 397 | acc_train:  0.0000 | mae_train:  1.0200 | rmse_train:  2.5656 | mae_val:  2.0754 | rmse_val:  5.1115 | mae_test:  3.9970 | rmse_test:  7.2969 | mape_test:  0.8618 | Time(s)  0.1246 \n",
      "2023-05-01 10:08:39   Epoch 398 | acc_train:  0.0000 | mae_train:  1.0202 | rmse_train:  2.5650 | mae_val:  2.0752 | rmse_val:  5.1111 | mae_test:  3.9969 | rmse_test:  7.2965 | mape_test:  0.8615 | Time(s)  0.1167 \n",
      "2023-05-01 10:08:39   Epoch 399 | acc_train:  0.0000 | mae_train:  1.0199 | rmse_train:  2.5650 | mae_val:  2.0753 | rmse_val:  5.1111 | mae_test:  3.9973 | rmse_test:  7.2968 | mape_test:  0.8620 | Time(s)  0.1217 \n",
      "2023-05-01 10:08:39   Epoch 400 | acc_train:  0.0000 | mae_train:  1.0199 | rmse_train:  2.5653 | mae_val:  2.0753 | rmse_val:  5.1108 | mae_test:  3.9974 | rmse_test:  7.2967 | mape_test:  0.8621 | Time(s)  0.1207 \n",
      "2023-05-01 10:08:39   Epoch 401 | acc_train:  0.0000 | mae_train:  1.0199 | rmse_train:  2.5652 | mae_val:  2.0749 | rmse_val:  5.1103 | mae_test:  3.9966 | rmse_test:  7.2955 | mape_test:  0.8617 | Time(s)  0.1262 \n",
      "2023-05-01 10:08:39   Epoch 402 | acc_train:  0.0000 | mae_train:  1.0198 | rmse_train:  2.5649 | mae_val:  2.0742 | rmse_val:  5.1092 | mae_test:  3.9943 | rmse_test:  7.2928 | mape_test:  0.8608 | Time(s)  0.1258 \n",
      "2023-05-01 10:08:39   Epoch 403 | acc_train:  0.0000 | mae_train:  1.0200 | rmse_train:  2.5643 | mae_val:  2.0738 | rmse_val:  5.1083 | mae_test:  3.9927 | rmse_test:  7.2908 | mape_test:  0.8601 | Time(s)  0.1399 \n",
      "2023-05-01 10:08:39   Epoch 404 | acc_train:  0.0000 | mae_train:  1.0200 | rmse_train:  2.5640 | mae_val:  2.0739 | rmse_val:  5.1085 | mae_test:  3.9940 | rmse_test:  7.2921 | mape_test:  0.8607 | Time(s)  0.1207 \n",
      "2023-05-01 10:08:40   Epoch 405 | acc_train:  0.0000 | mae_train:  1.0196 | rmse_train:  2.5644 | mae_val:  2.0739 | rmse_val:  5.1084 | mae_test:  3.9943 | rmse_test:  7.2922 | mape_test:  0.8608 | Time(s)  0.1501 \n",
      "2023-05-01 10:08:40   Epoch 406 | acc_train:  0.0000 | mae_train:  1.0196 | rmse_train:  2.5643 | mae_val:  2.0736 | rmse_val:  5.1078 | mae_test:  3.9932 | rmse_test:  7.2907 | mape_test:  0.8604 | Time(s)  0.1541 \n",
      "2023-05-01 10:08:40   Epoch 407 | acc_train:  0.0000 | mae_train:  1.0197 | rmse_train:  2.5640 | mae_val:  2.0733 | rmse_val:  5.1072 | mae_test:  3.9924 | rmse_test:  7.2897 | mape_test:  0.8601 | Time(s)  0.1600 \n",
      "2023-05-01 10:08:40   Epoch 408 | acc_train:  0.0000 | mae_train:  1.0195 | rmse_train:  2.5639 | mae_val:  2.0732 | rmse_val:  5.1070 | mae_test:  3.9921 | rmse_test:  7.2891 | mape_test:  0.8601 | Time(s)  0.1241 \n",
      "2023-05-01 10:08:40   Epoch 409 | acc_train:  0.0000 | mae_train:  1.0195 | rmse_train:  2.5637 | mae_val:  2.0730 | rmse_val:  5.1066 | mae_test:  3.9919 | rmse_test:  7.2887 | mape_test:  0.8600 | Time(s)  0.1474 \n",
      "2023-05-01 10:08:40   Epoch 410 | acc_train:  0.0000 | mae_train:  1.0194 | rmse_train:  2.5638 | mae_val:  2.0729 | rmse_val:  5.1062 | mae_test:  3.9916 | rmse_test:  7.2881 | mape_test:  0.8599 | Time(s)  0.1244 \n",
      "2023-05-01 10:08:40   Epoch 411 | acc_train:  0.0000 | mae_train:  1.0194 | rmse_train:  2.5636 | mae_val:  2.0725 | rmse_val:  5.1056 | mae_test:  3.9903 | rmse_test:  7.2865 | mape_test:  0.8594 | Time(s)  0.1237 \n",
      "2023-05-01 10:08:41   Epoch 412 | acc_train:  0.0000 | mae_train:  1.0196 | rmse_train:  2.5632 | mae_val:  2.0722 | rmse_val:  5.1051 | mae_test:  3.9898 | rmse_test:  7.2859 | mape_test:  0.8591 | Time(s)  0.1196 \n",
      "2023-05-01 10:08:41   Epoch 413 | acc_train:  0.0000 | mae_train:  1.0193 | rmse_train:  2.5631 | mae_val:  2.0725 | rmse_val:  5.1054 | mae_test:  3.9912 | rmse_test:  7.2871 | mape_test:  0.8597 | Time(s)  0.1481 \n",
      "2023-05-01 10:08:41   Epoch 414 | acc_train:  0.0000 | mae_train:  1.0194 | rmse_train:  2.5635 | mae_val:  2.0725 | rmse_val:  5.1052 | mae_test:  3.9914 | rmse_test:  7.2873 | mape_test:  0.8599 | Time(s)  0.1147 \n",
      "2023-05-01 10:08:41   Epoch 415 | acc_train:  0.0000 | mae_train:  1.0194 | rmse_train:  2.5635 | mae_val:  2.0721 | rmse_val:  5.1046 | mae_test:  3.9904 | rmse_test:  7.2859 | mape_test:  0.8595 | Time(s)  0.1264 \n",
      "2023-05-01 10:08:41   Epoch 416 | acc_train:  0.0000 | mae_train:  1.0193 | rmse_train:  2.5632 | mae_val:  2.0716 | rmse_val:  5.1038 | mae_test:  3.9886 | rmse_test:  7.2836 | mape_test:  0.8587 | Time(s)  0.1227 \n",
      "2023-05-01 10:08:41   Epoch 417 | acc_train:  0.0000 | mae_train:  1.0194 | rmse_train:  2.5626 | mae_val:  2.0711 | rmse_val:  5.1031 | mae_test:  3.9873 | rmse_test:  7.2821 | mape_test:  0.8582 | Time(s)  0.1207 \n",
      "2023-05-01 10:08:41   Epoch 418 | acc_train:  0.0000 | mae_train:  1.0192 | rmse_train:  2.5624 | mae_val:  2.0715 | rmse_val:  5.1033 | mae_test:  3.9884 | rmse_test:  7.2831 | mape_test:  0.8587 | Time(s)  0.1198 \n",
      "2023-05-01 10:08:42   Epoch 419 | acc_train:  0.0000 | mae_train:  1.0192 | rmse_train:  2.5628 | mae_val:  2.0713 | rmse_val:  5.1031 | mae_test:  3.9886 | rmse_test:  7.2831 | mape_test:  0.8588 | Time(s)  0.1187 \n",
      "2023-05-01 10:08:42   Epoch 420 | acc_train:  0.0000 | mae_train:  1.0191 | rmse_train:  2.5627 | mae_val:  2.0710 | rmse_val:  5.1024 | mae_test:  3.9874 | rmse_test:  7.2816 | mape_test:  0.8584 | Time(s)  0.1207 \n",
      "2023-05-01 10:08:42   Epoch 421 | acc_train:  0.0000 | mae_train:  1.0190 | rmse_train:  2.5624 | mae_val:  2.0709 | rmse_val:  5.1022 | mae_test:  3.9872 | rmse_test:  7.2811 | mape_test:  0.8583 | Time(s)  0.1226 \n",
      "2023-05-01 10:08:42   Epoch 422 | acc_train:  0.0000 | mae_train:  1.0190 | rmse_train:  2.5624 | mae_val:  2.0706 | rmse_val:  5.1016 | mae_test:  3.9864 | rmse_test:  7.2801 | mape_test:  0.8580 | Time(s)  0.1187 \n",
      "2023-05-01 10:08:42   Epoch 423 | acc_train:  0.0000 | mae_train:  1.0190 | rmse_train:  2.5621 | mae_val:  2.0705 | rmse_val:  5.1015 | mae_test:  3.9866 | rmse_test:  7.2801 | mape_test:  0.8582 | Time(s)  0.1273 \n",
      "2023-05-01 10:08:42   Epoch 424 | acc_train:  0.0000 | mae_train:  1.0190 | rmse_train:  2.5622 | mae_val:  2.0704 | rmse_val:  5.1012 | mae_test:  3.9866 | rmse_test:  7.2799 | mape_test:  0.8581 | Time(s)  0.1137 \n",
      "2023-05-01 10:08:42   Epoch 425 | acc_train:  0.0000 | mae_train:  1.0189 | rmse_train:  2.5621 | mae_val:  2.0700 | rmse_val:  5.1004 | mae_test:  3.9850 | rmse_test:  7.2779 | mape_test:  0.8575 | Time(s)  0.1193 \n",
      "2023-05-01 10:08:42   Epoch 426 | acc_train:  0.0000 | mae_train:  1.0190 | rmse_train:  2.5616 | mae_val:  2.0698 | rmse_val:  5.1001 | mae_test:  3.9846 | rmse_test:  7.2772 | mape_test:  0.8573 | Time(s)  0.1177 \n",
      "2023-05-01 10:08:43   Epoch 427 | acc_train:  0.0000 | mae_train:  1.0188 | rmse_train:  2.5616 | mae_val:  2.0695 | rmse_val:  5.0995 | mae_test:  3.9837 | rmse_test:  7.2761 | mape_test:  0.8570 | Time(s)  0.1206 \n",
      "2023-05-01 10:08:43   Epoch 428 | acc_train:  0.0000 | mae_train:  1.0189 | rmse_train:  2.5613 | mae_val:  2.0694 | rmse_val:  5.0994 | mae_test:  3.9839 | rmse_test:  7.2760 | mape_test:  0.8571 | Time(s)  0.1227 \n",
      "2023-05-01 10:08:43   Epoch 429 | acc_train:  0.0000 | mae_train:  1.0187 | rmse_train:  2.5614 | mae_val:  2.0693 | rmse_val:  5.0990 | mae_test:  3.9835 | rmse_test:  7.2755 | mape_test:  0.8570 | Time(s)  0.1246 \n",
      "2023-05-01 10:08:43   Epoch 430 | acc_train:  0.0000 | mae_train:  1.0187 | rmse_train:  2.5613 | mae_val:  2.0688 | rmse_val:  5.0983 | mae_test:  3.9822 | rmse_test:  7.2738 | mape_test:  0.8564 | Time(s)  0.1228 \n",
      "2023-05-01 10:08:43   Epoch 431 | acc_train:  0.0000 | mae_train:  1.0189 | rmse_train:  2.5608 | mae_val:  2.0687 | rmse_val:  5.0980 | mae_test:  3.9817 | rmse_test:  7.2731 | mape_test:  0.8562 | Time(s)  0.1256 \n",
      "2023-05-01 10:08:43   Epoch 432 | acc_train:  0.0000 | mae_train:  1.0187 | rmse_train:  2.5608 | mae_val:  2.0688 | rmse_val:  5.0980 | mae_test:  3.9825 | rmse_test:  7.2738 | mape_test:  0.8566 | Time(s)  0.1197 \n",
      "2023-05-01 10:08:43   Epoch 433 | acc_train:  0.0000 | mae_train:  1.0186 | rmse_train:  2.5611 | mae_val:  2.0688 | rmse_val:  5.0980 | mae_test:  3.9831 | rmse_test:  7.2743 | mape_test:  0.8570 | Time(s)  0.1217 \n",
      "2023-05-01 10:08:44   Epoch 434 | acc_train:  0.0000 | mae_train:  1.0187 | rmse_train:  2.5611 | mae_val:  2.0686 | rmse_val:  5.0973 | mae_test:  3.9817 | rmse_test:  7.2725 | mape_test:  0.8565 | Time(s)  0.1197 \n",
      "2023-05-01 10:08:44   Epoch 435 | acc_train:  0.0000 | mae_train:  1.0186 | rmse_train:  2.5608 | mae_val:  2.0679 | rmse_val:  5.0966 | mae_test:  3.9801 | rmse_test:  7.2705 | mape_test:  0.8558 | Time(s)  0.1226 \n",
      "2023-05-01 10:08:44   Epoch 436 | acc_train:  0.0000 | mae_train:  1.0187 | rmse_train:  2.5603 | mae_val:  2.0676 | rmse_val:  5.0960 | mae_test:  3.9790 | rmse_test:  7.2691 | mape_test:  0.8553 | Time(s)  0.1227 \n",
      "2023-05-01 10:08:44   Epoch 437 | acc_train:  0.0000 | mae_train:  1.0186 | rmse_train:  2.5601 | mae_val:  2.0678 | rmse_val:  5.0962 | mae_test:  3.9801 | rmse_test:  7.2700 | mape_test:  0.8558 | Time(s)  0.1228 \n",
      "2023-05-01 10:08:44   Epoch 438 | acc_train:  0.0000 | mae_train:  1.0184 | rmse_train:  2.5604 | mae_val:  2.0678 | rmse_val:  5.0959 | mae_test:  3.9802 | rmse_test:  7.2700 | mape_test:  0.8560 | Time(s)  0.1203 \n",
      "2023-05-01 10:08:44   Epoch 439 | acc_train:  0.0000 | mae_train:  1.0185 | rmse_train:  2.5604 | mae_val:  2.0675 | rmse_val:  5.0955 | mae_test:  3.9793 | rmse_test:  7.2688 | mape_test:  0.8556 | Time(s)  0.1177 \n",
      "2023-05-01 10:08:44   Epoch 440 | acc_train:  0.0000 | mae_train:  1.0184 | rmse_train:  2.5601 | mae_val:  2.0676 | rmse_val:  5.0954 | mae_test:  3.9794 | rmse_test:  7.2687 | mape_test:  0.8556 | Time(s)  0.1254 \n",
      "2023-05-01 10:08:44   Epoch 441 | acc_train:  0.0000 | mae_train:  1.0185 | rmse_train:  2.5601 | mae_val:  2.0673 | rmse_val:  5.0949 | mae_test:  3.9789 | rmse_test:  7.2679 | mape_test:  0.8555 | Time(s)  0.1241 \n",
      "2023-05-01 10:08:45   Epoch 442 | acc_train:  0.0000 | mae_train:  1.0183 | rmse_train:  2.5599 | mae_val:  2.0667 | rmse_val:  5.0940 | mae_test:  3.9769 | rmse_test:  7.2656 | mape_test:  0.8547 | Time(s)  0.1227 \n",
      "2023-05-01 10:08:45   Epoch 443 | acc_train:  0.0000 | mae_train:  1.0185 | rmse_train:  2.5594 | mae_val:  2.0665 | rmse_val:  5.0937 | mae_test:  3.9765 | rmse_test:  7.2650 | mape_test:  0.8545 | Time(s)  0.1232 \n",
      "2023-05-01 10:08:45   Epoch 444 | acc_train:  0.0000 | mae_train:  1.0183 | rmse_train:  2.5594 | mae_val:  2.0666 | rmse_val:  5.0938 | mae_test:  3.9775 | rmse_test:  7.2658 | mape_test:  0.8550 | Time(s)  0.1242 \n",
      "2023-05-01 10:08:45   Epoch 445 | acc_train:  0.0000 | mae_train:  1.0182 | rmse_train:  2.5597 | mae_val:  2.0667 | rmse_val:  5.0936 | mae_test:  3.9777 | rmse_test:  7.2660 | mape_test:  0.8552 | Time(s)  0.1233 \n",
      "2023-05-01 10:08:45   Epoch 446 | acc_train:  0.0000 | mae_train:  1.0183 | rmse_train:  2.5597 | mae_val:  2.0664 | rmse_val:  5.0933 | mae_test:  3.9772 | rmse_test:  7.2651 | mape_test:  0.8549 | Time(s)  0.1287 \n",
      "2023-05-01 10:08:45   Epoch 447 | acc_train:  0.0000 | mae_train:  1.0181 | rmse_train:  2.5594 | mae_val:  2.0658 | rmse_val:  5.0924 | mae_test:  3.9751 | rmse_test:  7.2627 | mape_test:  0.8541 | Time(s)  0.1217 \n",
      "2023-05-01 10:08:45   Epoch 448 | acc_train:  0.0000 | mae_train:  1.0183 | rmse_train:  2.5589 | mae_val:  2.0656 | rmse_val:  5.0920 | mae_test:  3.9746 | rmse_test:  7.2619 | mape_test:  0.8538 | Time(s)  0.1247 \n",
      "2023-05-01 10:08:46   Epoch 449 | acc_train:  0.0000 | mae_train:  1.0182 | rmse_train:  2.5588 | mae_val:  2.0658 | rmse_val:  5.0921 | mae_test:  3.9754 | rmse_test:  7.2626 | mape_test:  0.8542 | Time(s)  0.1247 \n",
      "2023-05-01 10:08:46   Epoch 450 | acc_train:  0.0000 | mae_train:  1.0180 | rmse_train:  2.5591 | mae_val:  2.0658 | rmse_val:  5.0919 | mae_test:  3.9755 | rmse_test:  7.2626 | mape_test:  0.8544 | Time(s)  0.1206 \n",
      "2023-05-01 10:08:46   Epoch 451 | acc_train:  0.0000 | mae_train:  1.0181 | rmse_train:  2.5590 | mae_val:  2.0655 | rmse_val:  5.0915 | mae_test:  3.9749 | rmse_test:  7.2617 | mape_test:  0.8541 | Time(s)  0.1222 \n",
      "2023-05-01 10:08:46   Epoch 452 | acc_train:  0.0000 | mae_train:  1.0180 | rmse_train:  2.5588 | mae_val:  2.0653 | rmse_val:  5.0911 | mae_test:  3.9744 | rmse_test:  7.2610 | mape_test:  0.8540 | Time(s)  0.1252 \n",
      "2023-05-01 10:08:46   Epoch 453 | acc_train:  0.0000 | mae_train:  1.0179 | rmse_train:  2.5587 | mae_val:  2.0652 | rmse_val:  5.0906 | mae_test:  3.9737 | rmse_test:  7.2602 | mape_test:  0.8537 | Time(s)  0.1217 \n",
      "2023-05-01 10:08:46   Epoch 454 | acc_train:  0.0000 | mae_train:  1.0179 | rmse_train:  2.5585 | mae_val:  2.0647 | rmse_val:  5.0901 | mae_test:  3.9726 | rmse_test:  7.2587 | mape_test:  0.8532 | Time(s)  0.1182 \n",
      "2023-05-01 10:08:46   Epoch 455 | acc_train:  0.0000 | mae_train:  1.0180 | rmse_train:  2.5581 | mae_val:  2.0645 | rmse_val:  5.0897 | mae_test:  3.9720 | rmse_test:  7.2578 | mape_test:  0.8530 | Time(s)  0.1271 \n",
      "2023-05-01 10:08:47   Epoch 456 | acc_train:  0.0000 | mae_train:  1.0178 | rmse_train:  2.5581 | mae_val:  2.0646 | rmse_val:  5.0897 | mae_test:  3.9729 | rmse_test:  7.2585 | mape_test:  0.8534 | Time(s)  0.1172 \n",
      "2023-05-01 10:08:47   Epoch 457 | acc_train:  0.0000 | mae_train:  1.0178 | rmse_train:  2.5584 | mae_val:  2.0647 | rmse_val:  5.0898 | mae_test:  3.9736 | rmse_test:  7.2591 | mape_test:  0.8538 | Time(s)  0.1267 \n",
      "2023-05-01 10:08:47   Epoch 458 | acc_train:  0.0000 | mae_train:  1.0178 | rmse_train:  2.5584 | mae_val:  2.0646 | rmse_val:  5.0894 | mae_test:  3.9729 | rmse_test:  7.2581 | mape_test:  0.8535 | Time(s)  0.1207 \n",
      "2023-05-01 10:08:47   Epoch 459 | acc_train:  0.0000 | mae_train:  1.0178 | rmse_train:  2.5581 | mae_val:  2.0639 | rmse_val:  5.0884 | mae_test:  3.9708 | rmse_test:  7.2556 | mape_test:  0.8526 | Time(s)  0.1197 \n",
      "2023-05-01 10:08:47   Epoch 460 | acc_train:  0.0000 | mae_train:  1.0180 | rmse_train:  2.5576 | mae_val:  2.0635 | rmse_val:  5.0880 | mae_test:  3.9700 | rmse_test:  7.2546 | mape_test:  0.8523 | Time(s)  0.1203 \n",
      "2023-05-01 10:08:47   Epoch 461 | acc_train:  0.0000 | mae_train:  1.0177 | rmse_train:  2.5575 | mae_val:  2.0641 | rmse_val:  5.0883 | mae_test:  3.9714 | rmse_test:  7.2559 | mape_test:  0.8529 | Time(s)  0.1170 \n",
      "2023-05-01 10:08:47   Epoch 462 | acc_train:  0.0000 | mae_train:  1.0178 | rmse_train:  2.5578 | mae_val:  2.0640 | rmse_val:  5.0882 | mae_test:  3.9718 | rmse_test:  7.2561 | mape_test:  0.8531 | Time(s)  0.1339 \n",
      "2023-05-01 10:08:47   Epoch 463 | acc_train:  0.0000 | mae_train:  1.0177 | rmse_train:  2.5578 | mae_val:  2.0635 | rmse_val:  5.0874 | mae_test:  3.9702 | rmse_test:  7.2543 | mape_test:  0.8525 | Time(s)  0.1226 \n",
      "2023-05-01 10:08:48   Epoch 464 | acc_train:  0.0000 | mae_train:  1.0176 | rmse_train:  2.5574 | mae_val:  2.0633 | rmse_val:  5.0871 | mae_test:  3.9699 | rmse_test:  7.2537 | mape_test:  0.8524 | Time(s)  0.1201 \n",
      "2023-05-01 10:08:48   Epoch 465 | acc_train:  0.0000 | mae_train:  1.0176 | rmse_train:  2.5574 | mae_val:  2.0633 | rmse_val:  5.0870 | mae_test:  3.9700 | rmse_test:  7.2536 | mape_test:  0.8524 | Time(s)  0.1200 \n",
      "2023-05-01 10:08:48   Epoch 466 | acc_train:  0.0000 | mae_train:  1.0175 | rmse_train:  2.5573 | mae_val:  2.0627 | rmse_val:  5.0861 | mae_test:  3.9683 | rmse_test:  7.2516 | mape_test:  0.8517 | Time(s)  0.1302 \n",
      "2023-05-01 10:08:48   Epoch 467 | acc_train:  0.0000 | mae_train:  1.0176 | rmse_train:  2.5568 | mae_val:  2.0626 | rmse_val:  5.0859 | mae_test:  3.9678 | rmse_test:  7.2509 | mape_test:  0.8516 | Time(s)  0.1292 \n",
      "2023-05-01 10:08:48   Epoch 468 | acc_train:  0.0000 | mae_train:  1.0174 | rmse_train:  2.5568 | mae_val:  2.0627 | rmse_val:  5.0859 | mae_test:  3.9688 | rmse_test:  7.2517 | mape_test:  0.8520 | Time(s)  0.1257 \n",
      "2023-05-01 10:08:48   Epoch 469 | acc_train:  0.0000 | mae_train:  1.0174 | rmse_train:  2.5571 | mae_val:  2.0628 | rmse_val:  5.0857 | mae_test:  3.9689 | rmse_test:  7.2517 | mape_test:  0.8522 | Time(s)  0.1336 \n",
      "2023-05-01 10:08:48   Epoch 470 | acc_train:  0.0000 | mae_train:  1.0176 | rmse_train:  2.5571 | mae_val:  2.0625 | rmse_val:  5.0854 | mae_test:  3.9683 | rmse_test:  7.2508 | mape_test:  0.8520 | Time(s)  0.1282 \n",
      "2023-05-01 10:08:49   Epoch 471 | acc_train:  0.0000 | mae_train:  1.0173 | rmse_train:  2.5568 | mae_val:  2.0619 | rmse_val:  5.0846 | mae_test:  3.9666 | rmse_test:  7.2488 | mape_test:  0.8512 | Time(s)  0.1507 \n",
      "2023-05-01 10:08:49   Epoch 472 | acc_train:  0.0000 | mae_train:  1.0174 | rmse_train:  2.5563 | mae_val:  2.0616 | rmse_val:  5.0841 | mae_test:  3.9655 | rmse_test:  7.2474 | mape_test:  0.8508 | Time(s)  0.1257 \n",
      "2023-05-01 10:08:49   Epoch 473 | acc_train:  0.0000 | mae_train:  1.0172 | rmse_train:  2.5562 | mae_val:  2.0620 | rmse_val:  5.0843 | mae_test:  3.9668 | rmse_test:  7.2485 | mape_test:  0.8514 | Time(s)  0.1356 \n",
      "2023-05-01 10:08:49   Epoch 474 | acc_train:  0.0000 | mae_train:  1.0173 | rmse_train:  2.5565 | mae_val:  2.0619 | rmse_val:  5.0842 | mae_test:  3.9670 | rmse_test:  7.2486 | mape_test:  0.8515 | Time(s)  0.1164 \n",
      "2023-05-01 10:08:49   Epoch 475 | acc_train:  0.0000 | mae_train:  1.0173 | rmse_train:  2.5565 | mae_val:  2.0616 | rmse_val:  5.0834 | mae_test:  3.9656 | rmse_test:  7.2469 | mape_test:  0.8510 | Time(s)  0.1186 \n",
      "2023-05-01 10:08:49   Epoch 476 | acc_train:  0.0000 | mae_train:  1.0173 | rmse_train:  2.5561 | mae_val:  2.0610 | rmse_val:  5.0827 | mae_test:  3.9640 | rmse_test:  7.2449 | mape_test:  0.8502 | Time(s)  0.1217 \n",
      "2023-05-01 10:08:49   Epoch 477 | acc_train:  0.0000 | mae_train:  1.0174 | rmse_train:  2.5556 | mae_val:  2.0609 | rmse_val:  5.0825 | mae_test:  3.9643 | rmse_test:  7.2453 | mape_test:  0.8500 | Time(s)  0.1307 \n",
      "2023-05-01 10:08:50   Epoch 478 | acc_train:  0.0000 | mae_train:  1.0173 | rmse_train:  2.5555 | mae_val:  2.0610 | rmse_val:  5.0825 | mae_test:  3.9643 | rmse_test:  7.2449 | mape_test:  0.8505 | Time(s)  0.1183 \n",
      "2023-05-01 10:08:50   Epoch 479 | acc_train:  0.0000 | mae_train:  1.0170 | rmse_train:  2.5558 | mae_val:  2.0610 | rmse_val:  5.0822 | mae_test:  3.9643 | rmse_test:  7.2447 | mape_test:  0.8505 | Time(s)  0.1765 \n",
      "2023-05-01 10:08:50   Epoch 480 | acc_train:  0.0000 | mae_train:  1.0171 | rmse_train:  2.5557 | mae_val:  2.0607 | rmse_val:  5.0817 | mae_test:  3.9634 | rmse_test:  7.2435 | mape_test:  0.8502 | Time(s)  0.1522 \n",
      "2023-05-01 10:08:50   Epoch 481 | acc_train:  0.0000 | mae_train:  1.0170 | rmse_train:  2.5554 | mae_val:  2.0607 | rmse_val:  5.0818 | mae_test:  3.9646 | rmse_test:  7.2449 | mape_test:  0.8503 | Time(s)  0.1706 \n",
      "2023-05-01 10:08:50   Epoch 482 | acc_train:  0.0000 | mae_train:  1.0170 | rmse_train:  2.5555 | mae_val:  2.0606 | rmse_val:  5.0815 | mae_test:  3.9644 | rmse_test:  7.2445 | mape_test:  0.8502 | Time(s)  0.1246 \n",
      "2023-05-01 10:08:50   Epoch 483 | acc_train:  0.0000 | mae_train:  1.0169 | rmse_train:  2.5553 | mae_val:  2.0600 | rmse_val:  5.0806 | mae_test:  3.9626 | rmse_test:  7.2423 | mape_test:  0.8494 | Time(s)  0.1502 \n",
      "2023-05-01 10:08:50   Epoch 484 | acc_train:  0.0000 | mae_train:  1.0171 | rmse_train:  2.5548 | mae_val:  2.0597 | rmse_val:  5.0803 | mae_test:  3.9621 | rmse_test:  7.2416 | mape_test:  0.8492 | Time(s)  0.1217 \n",
      "2023-05-01 10:08:51   Epoch 485 | acc_train:  0.0000 | mae_train:  1.0168 | rmse_train:  2.5548 | mae_val:  2.0602 | rmse_val:  5.0807 | mae_test:  3.9636 | rmse_test:  7.2430 | mape_test:  0.8499 | Time(s)  0.1237 \n",
      "2023-05-01 10:08:51   Epoch 486 | acc_train:  0.0000 | mae_train:  1.0170 | rmse_train:  2.5552 | mae_val:  2.0602 | rmse_val:  5.0807 | mae_test:  3.9641 | rmse_test:  7.2433 | mape_test:  0.8502 | Time(s)  0.1217 \n",
      "2023-05-01 10:08:51   Epoch 487 | acc_train:  0.0000 | mae_train:  1.0169 | rmse_train:  2.5552 | mae_val:  2.0599 | rmse_val:  5.0800 | mae_test:  3.9629 | rmse_test:  7.2418 | mape_test:  0.8497 | Time(s)  0.1277 \n",
      "2023-05-01 10:08:51   Epoch 488 | acc_train:  0.0000 | mae_train:  1.0168 | rmse_train:  2.5548 | mae_val:  2.0593 | rmse_val:  5.0794 | mae_test:  3.9614 | rmse_test:  7.2400 | mape_test:  0.8491 | Time(s)  0.1262 \n",
      "2023-05-01 10:08:51   Epoch 489 | acc_train:  0.0000 | mae_train:  1.0169 | rmse_train:  2.5543 | mae_val:  2.0594 | rmse_val:  5.0792 | mae_test:  3.9611 | rmse_test:  7.2394 | mape_test:  0.8489 | Time(s)  0.1277 \n",
      "2023-05-01 10:08:51   Epoch 490 | acc_train:  0.0000 | mae_train:  1.0169 | rmse_train:  2.5543 | mae_val:  2.0595 | rmse_val:  5.0793 | mae_test:  3.9619 | rmse_test:  7.2401 | mape_test:  0.8494 | Time(s)  0.1237 \n",
      "2023-05-01 10:08:51   Epoch 491 | acc_train:  0.0000 | mae_train:  1.0167 | rmse_train:  2.5545 | mae_val:  2.0594 | rmse_val:  5.0790 | mae_test:  3.9619 | rmse_test:  7.2400 | mape_test:  0.8495 | Time(s)  0.1260 \n",
      "2023-05-01 10:08:52   Epoch 492 | acc_train:  0.0000 | mae_train:  1.0167 | rmse_train:  2.5545 | mae_val:  2.0591 | rmse_val:  5.0785 | mae_test:  3.9611 | rmse_test:  7.2388 | mape_test:  0.8491 | Time(s)  0.1187 \n",
      "2023-05-01 10:08:52   Epoch 493 | acc_train:  0.0000 | mae_train:  1.0165 | rmse_train:  2.5542 | mae_val:  2.0587 | rmse_val:  5.0780 | mae_test:  3.9596 | rmse_test:  7.2371 | mape_test:  0.8485 | Time(s)  0.1196 \n",
      "2023-05-01 10:08:52   Epoch 494 | acc_train:  0.0000 | mae_train:  1.0168 | rmse_train:  2.5537 | mae_val:  2.0583 | rmse_val:  5.0774 | mae_test:  3.9585 | rmse_test:  7.2357 | mape_test:  0.8480 | Time(s)  0.1183 \n",
      "2023-05-01 10:08:52   Epoch 495 | acc_train:  0.0000 | mae_train:  1.0166 | rmse_train:  2.5535 | mae_val:  2.0586 | rmse_val:  5.0776 | mae_test:  3.9596 | rmse_test:  7.2366 | mape_test:  0.8486 | Time(s)  0.1211 \n",
      "2023-05-01 10:08:52   Epoch 496 | acc_train:  0.0000 | mae_train:  1.0164 | rmse_train:  2.5538 | mae_val:  2.0586 | rmse_val:  5.0776 | mae_test:  3.9600 | rmse_test:  7.2369 | mape_test:  0.8488 | Time(s)  0.1233 \n",
      "2023-05-01 10:08:52   Epoch 497 | acc_train:  0.0000 | mae_train:  1.0164 | rmse_train:  2.5538 | mae_val:  2.0584 | rmse_val:  5.0769 | mae_test:  3.9588 | rmse_test:  7.2353 | mape_test:  0.8483 | Time(s)  0.1387 \n",
      "2023-05-01 10:08:52   Epoch 498 | acc_train:  0.0000 | mae_train:  1.0166 | rmse_train:  2.5534 | mae_val:  2.0582 | rmse_val:  5.0768 | mae_test:  3.9588 | rmse_test:  7.2351 | mape_test:  0.8484 | Time(s)  0.1247 \n",
      "2023-05-01 10:08:52   Epoch 499 | acc_train:  0.0000 | mae_train:  1.0163 | rmse_train:  2.5535 | mae_val:  2.0584 | rmse_val:  5.0768 | mae_test:  3.9591 | rmse_test:  7.2351 | mape_test:  0.8485 | Time(s)  0.1236 \n",
      "2023-05-01 10:08:53   Epoch 500 | acc_train:  0.0000 | mae_train:  1.0165 | rmse_train:  2.5534 | mae_val:  2.0579 | rmse_val:  5.0762 | mae_test:  3.9576 | rmse_test:  7.2333 | mape_test:  0.8479 | Time(s)  0.1267 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop!!\n",
      "Avg acc: 0.0\n",
      "Optimization Finished!\n",
      "mae:  3.9576, rmse:  7.2333, mape:  84.7877\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = pretrain_model_path.split(os.path.sep)\n",
    "b = []\n",
    "for i in a:\n",
    "    if \"pkl\" not in i:\n",
    "        b.append(i)\n",
    "local_path_generate(os.path.sep.join(b), create_folder_only=True)\n",
    "\n",
    "if os.path.exists(pretrain_model_path):\n",
    "    print(f'Loading pretrained model at {pretrain_model_path}')\n",
    "    state = torch.load(pretrain_model_path, map_location='cpu')\n",
    "else:\n",
    "    print(f'No existing pretrained model at {pretrain_model_path}')\n",
    "    args.val = args.test = False\n",
    "    datasets = [\"4\", \"7\", \"8\"]\n",
    "    dataset_bak = args.dataset\n",
    "    labelrate_bak = args.labelrate\n",
    "    args.labelrate = 100\n",
    "    dataset_count = 0\n",
    "\n",
    "    for dataset in [item for item in datasets if item not in [dataset_bak]]:\n",
    "        dataset_count = dataset_count + 1\n",
    "\n",
    "        print(\n",
    "            f'\\n\\n****************************************************************************************************************')\n",
    "        print(f'dataset: {dataset}, model: {args.model}, pre_len: {args.pre_len}, labelrate: {args.labelrate}')\n",
    "        print(\n",
    "            f'****************************************************************************************************************\\n\\n')\n",
    "\n",
    "        if dataset == '4':\n",
    "            g = vec_pems04\n",
    "        elif dataset == '7':\n",
    "            g = vec_pems07\n",
    "        elif dataset == '8':\n",
    "            g = vec_pems08\n",
    "\n",
    "        args.dataset = dataset\n",
    "        train_dataloader, val_dataloader, test_dataloader, adj, max_speed, scaler = load_data(args)\n",
    "        model = DASTNet(input_dim=args.vec_dim, hidden_dim=args.hidden_dim, encode_dim=args.enc_dim,\n",
    "                        device=device, batch_size=args.batch_size, etype=args.etype, pre_len=args.pre_len,\n",
    "                        dataset=args.dataset, ft_dataset=dataset_bak,\n",
    "                        adj_pems04=adj_pems04, adj_pems07=adj_pems07, adj_pems08=adj_pems08).to(device)\n",
    "        optimizer = optim.SGD([{'params': model.parameters()},\n",
    "                               {'params': domain_classifier.parameters()}], lr=args.learning_rate, momentum=0.8)\n",
    "\n",
    "        if dataset_count != 1:\n",
    "            model.load_state_dict(state['model'])\n",
    "            optimizer.load_state_dict(state['optim'])\n",
    "\n",
    "        state = model_train(args, model, optimizer)\n",
    "\n",
    "    print(f'Saving model to {pretrain_model_path} ...')\n",
    "    torch.save(state, pretrain_model_path)\n",
    "    args.dataset = dataset_bak\n",
    "    args.labelrate = labelrate_bak\n",
    "    args.val = bak_val\n",
    "    args.test = bak_test\n",
    "\n",
    "type = 'fine-tune'\n",
    "args.epoch = args.fine_epoch\n",
    "\n",
    "print(f'\\n\\n*******************************************************************************************')\n",
    "print(\n",
    "    f'dataset: {args.dataset}, model: {args.model}, pre_len: {args.pre_len}, labelrate: {args.labelrate}, seed: {args.division_seed}')\n",
    "print(f'*******************************************************************************************\\n\\n')\n",
    "\n",
    "if args.dataset == '4':\n",
    "    g = vec_pems04\n",
    "elif args.dataset == '7':\n",
    "    g = vec_pems07\n",
    "elif args.dataset == '8':\n",
    "    g = vec_pems08\n",
    "\n",
    "train_dataloader, val_dataloader, test_dataloader, adj, max_speed, scaler = load_data(args, cut=True)\n",
    "model = DASTNet(input_dim=args.vec_dim, hidden_dim=args.hidden_dim, encode_dim=args.enc_dim,\n",
    "                device=device, batch_size=args.batch_size, etype=args.etype, pre_len=args.pre_len,\n",
    "                dataset=args.dataset, ft_dataset=args.dataset,\n",
    "                adj_pems04=adj_pems04, adj_pems07=adj_pems07, adj_pems08=adj_pems08).to(device)\n",
    "optimizer = optim.SGD([{'params': model.parameters()},\n",
    "                       {'params': domain_classifier.parameters()}], lr=args.learning_rate, momentum=0.8)\n",
    "model.load_state_dict(state['model'])\n",
    "optimizer.load_state_dict(state['optim'])\n",
    "\n",
    "if args.labelrate != 0:\n",
    "    test_state = model_train(args, model, optimizer)\n",
    "    model.load_state_dict(test_state['model'])\n",
    "    optimizer.load_state_dict(test_state['optim'])\n",
    "\n",
    "test_mae, test_rmse, test_mape = test()\n",
    "print(f'mae: {test_mae * (maxs - mins): .4f}, rmse: {test_rmse * (maxs - mins): .4f}, mape: {test_mape * 100: .4f}\\n\\n')\n",
    "if args.c != \"default\":\n",
    "    if args.need_remark == 1:\n",
    "        record.update(record_id, get_timestamp(),\n",
    "                      \"%.4f,%.4f,%.4f\" %\n",
    "                      (test_rmse, test_mae, test_mape * 100),\n",
    "                      remark=\"{}C {} {} {} {}\".format(\"2\" if args.need_third == 0 else \"3\", str(args.data_amount),\n",
    "                                                      args.dataname, args.datatype, args.machine_code))\n",
    "    else:\n",
    "        record.update(record_id, get_timestamp(),\n",
    "                      \"%.4f,%.4f, %.4f\" %\n",
    "                      (test_rmse, test_mae, test_mape * 100),\n",
    "                      remark=\"{}\".format(args.machine_code))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
