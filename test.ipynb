{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2023/3/31 16:39\n",
    "# @Author  : 银尘\n",
    "# @FileName: main3.py\n",
    "# @Software: PyCharm\n",
    "# @Email   : liwudi@liwudi.fun\n",
    "# @Info    : 单城市\n",
    "import argparse\n",
    "import torch\n",
    "import copy\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from utils.funcs import load_data, load_all_adj\n",
    "from utils.funcs import masked_loss\n",
    "from utils.vec import generate_vector\n",
    "from model import DASTNet, Domain_classifier_DG\n",
    "from PaperCrawlerUtil.common_util import *\n",
    "from PaperCrawlerUtil.research_util import *\n",
    "import ast\n",
    "\n",
    "basic_config(logs_style=LOG_STYLE_ALL)\n",
    "\n",
    "\n",
    "def arg_parse(parser):\n",
    "    parser.add_argument('--dataset', type=str, default='4', help='dataset')\n",
    "    parser.add_argument('--seed', type=int, default=0, help='seed')\n",
    "    parser.add_argument('--division_seed', type=int, default=0, help='division_seed')\n",
    "    parser.add_argument('--model', type=str, default='DASTNet', help='model')\n",
    "    parser.add_argument('--labelrate', type=float, default=23, help='percent')\n",
    "    parser.add_argument('--patience', type=int, default=200, help='patience')\n",
    "    parser.add_argument(\"--hidden_dim\", type=int, default=64)\n",
    "    parser.add_argument(\"--vec_dim\", type=int, default=64)\n",
    "    parser.add_argument(\"--enc_dim\", type=int, default=64)\n",
    "    parser.add_argument(\"--walk_length\", \"--wl\", type=int, default=8)\n",
    "    parser.add_argument(\"--num_walks\", type=int, default=200)\n",
    "    parser.add_argument(\"--theta\", type=float, default=1)\n",
    "    parser.add_argument(\"--p\", type=float, default=1)\n",
    "    parser.add_argument(\"--q\", type=float, default=1)\n",
    "    parser.add_argument(\"--learning_rate\", \"--lr\", type=float, default=1e-4)\n",
    "    parser.add_argument(\"--epoch\", type=int, default=10)\n",
    "    parser.add_argument('--device', type=int, default=0, help='CUDA Device')\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=64)\n",
    "    parser.add_argument(\"--seq_len\", type=int, default=12)\n",
    "    parser.add_argument(\"--pre_len\", type=int, default=3)\n",
    "    parser.add_argument(\"--split_ratio\", type=float, default=0.7)\n",
    "    parser.add_argument(\"--alpha\", type=float, default=0.1)\n",
    "    parser.add_argument(\"--beta\", type=float, default=0.2)\n",
    "    parser.add_argument(\"--normalize\", type=bool, default=True)\n",
    "    parser.add_argument('--val', action='store_true', default=False, help='eval')\n",
    "    parser.add_argument('--test', action='store_true', default=False, help='test')\n",
    "    parser.add_argument('--train', action='store_true', default=False, help='train')\n",
    "    parser.add_argument('--etype', type=str, default=\"gin\", choices=[\"gin\"], help='feature type')\n",
    "    parser.add_argument('--dataname', type=str, default='Taxi', help='Within [Bike, Taxi]')\n",
    "    parser.add_argument('--datatype', type=str, default='pickup', help='Within [pickup, dropoff]')\n",
    "    parser.add_argument('--data_amount', type=int, default=3, help='0: full data, 30/7/3 correspond to days of data')\n",
    "    parser.add_argument('--need_third', type=int, default=0)\n",
    "    parser.add_argument(\"--c\", type=str, default=\"default\", help=\"research record\")\n",
    "    parser.add_argument(\"--machine_code\", type=str, default=\"my-1060\", help=\"code of machine\")\n",
    "    parser.add_argument(\"--need_remark\", type=int, default=0)\n",
    "    parser.add_argument(\"--fine_epoch\", type=int, default=80)\n",
    "    parser.add_argument(\"--need_road\", action='store_false', default=True, help='test')\n",
    "    parser.add_argument(\"--cut_data\", type=int, default=8784)\n",
    "    return parser.parse_args(args=[])\n",
    "\n",
    "\n",
    "def select_mask(a):\n",
    "    if a == 420:\n",
    "        return dcmask\n",
    "    elif a == 476:\n",
    "        return chimask\n",
    "    elif a == 460:\n",
    "        return nymask\n",
    "\n",
    "\n",
    "def train(dur, model, optimizer, total_step, start_step):\n",
    "    t0 = time.time()\n",
    "    train_mae, val_mae, train_rmse, val_rmse, train_acc = list(), list(), list(), list(), list()\n",
    "    train_correct = 0\n",
    "\n",
    "    model.train()\n",
    "    if type == 'pretrain':\n",
    "        domain_classifier.train()\n",
    "\n",
    "    for i, (feat, label) in enumerate(train_dataloader.get_iterator()):\n",
    "        mask = select_mask(feat.shape[2])\n",
    "        Reverse = False\n",
    "        if i > 0:\n",
    "            if train_acc[-1] > 0.333333:\n",
    "                Reverse = True\n",
    "        p = float(i + start_step) / total_step\n",
    "        constant = 2. / (1. + np.exp(-10 * p)) - 1\n",
    "\n",
    "        feat = torch.FloatTensor(feat).to(device)\n",
    "        label = torch.FloatTensor(label).to(device)\n",
    "        if torch.sum(scaler.inverse_transform(label)) <= 0.001:\n",
    "            continue\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        if args.model not in ['DCRNN', 'STGCN', 'HA']:\n",
    "            if type == 'pretrain':\n",
    "                pred, shared_pems04_feat, shared_pems07_feat, shared_pems08_feat = model(vec_pems04, vec_pems07,\n",
    "                                                                                         vec_pems08, feat, False,\n",
    "                                                                                         need_road=args.need_road)\n",
    "            elif type == 'fine-tune':\n",
    "                pred = model(vec_pems04, vec_pems07, vec_pems08, feat, False)\n",
    "\n",
    "            pred = pred.transpose(1, 2).reshape((-1, feat.size(2)))\n",
    "            label = label.reshape((-1, label.size(2)))\n",
    "\n",
    "            if type == 'pretrain' and args.need_road == True:\n",
    "                pems04_pred = domain_classifier(shared_pems04_feat, constant, Reverse)\n",
    "                pems07_pred = domain_classifier(shared_pems07_feat, constant, Reverse)\n",
    "                pems08_pred = domain_classifier(shared_pems08_feat, constant, Reverse)\n",
    "\n",
    "                pems04_label = 0 * torch.ones(pems04_pred.shape[0]).long().to(device)\n",
    "                pems07_label = 1 * torch.ones(pems07_pred.shape[0]).long().to(device)\n",
    "                pems08_label = 2 * torch.ones(pems08_pred.shape[0]).long().to(device)\n",
    "\n",
    "                pems04_pred_label = pems04_pred.max(1, keepdim=True)[1]\n",
    "                pems04_correct = pems04_pred_label.eq(pems04_label.view_as(pems04_pred_label)).sum()\n",
    "                pems07_pred_label = pems07_pred.max(1, keepdim=True)[1]\n",
    "                pems07_correct = pems07_pred_label.eq(pems07_label.view_as(pems07_pred_label)).sum()\n",
    "                pems08_pred_label = pems08_pred.max(1, keepdim=True)[1]\n",
    "                pems08_correct = pems08_pred_label.eq(pems08_label.view_as(pems08_pred_label)).sum()\n",
    "\n",
    "                pems04_loss = domain_criterion(pems04_pred, pems04_label)\n",
    "                pems07_loss = domain_criterion(pems07_pred, pems07_label)\n",
    "                pems08_loss = domain_criterion(pems08_pred, pems08_label)\n",
    "\n",
    "                domain_loss = pems04_loss + pems08_loss + pems07_loss\n",
    "\n",
    "        if type == 'pretrain' and args.need_road:\n",
    "            train_correct = pems04_correct + pems08_correct\n",
    "\n",
    "        mae_train, rmse_train, mape_train = masked_loss(scaler.inverse_transform(pred), scaler.inverse_transform(label),\n",
    "                                                        maskp=mask)\n",
    "\n",
    "        if type == 'pretrain' and args.need_road:\n",
    "            loss = mae_train + args.beta * (args.theta * domain_loss)\n",
    "        elif type == 'pretrain':\n",
    "            loss = mae_train\n",
    "        elif type == 'fine-tune':\n",
    "            loss = mae_train\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_mae.append(mae_train.item())\n",
    "        train_rmse.append(rmse_train.item())\n",
    "\n",
    "        if type == 'pretrain' and args.need_road:\n",
    "            train_acc.append(train_correct.item() / 855)\n",
    "        elif type == 'pretrain':\n",
    "            train_acc.append(0)\n",
    "        elif type == 'fine-tune':\n",
    "            train_acc.append(0)\n",
    "\n",
    "    if type == 'pretrain':\n",
    "        domain_classifier.eval()\n",
    "    model.eval()\n",
    "\n",
    "    for i, (feat, label) in enumerate(val_dataloader.get_iterator()):\n",
    "        mask = select_mask(feat.shape[2])\n",
    "        feat = torch.FloatTensor(feat).to(device)\n",
    "        label = torch.FloatTensor(label).to(device)\n",
    "        if torch.sum(scaler.inverse_transform(label)) <= 0.001:\n",
    "            continue\n",
    "        pred = model(vec_pems04, vec_pems07, vec_pems08, feat, True)\n",
    "        pred = pred.transpose(1, 2).reshape((-1, feat.size(2)))\n",
    "        label = label.reshape((-1, label.size(2)))\n",
    "        mae_val, rmse_val, mape_val = masked_loss(scaler.inverse_transform(pred), scaler.inverse_transform(label),\n",
    "                                                  maskp=mask)\n",
    "        val_mae.append(mae_val.item())\n",
    "        val_rmse.append(rmse_val.item())\n",
    "\n",
    "    test_mae, test_rmse, test_mape = test()\n",
    "    dur.append(time.time() - t0)\n",
    "    return np.mean(train_mae), np.mean(train_rmse), np.mean(val_mae), np.mean(\n",
    "        val_rmse), test_mae, test_rmse, test_mape, np.mean(train_acc)\n",
    "\n",
    "\n",
    "def test():\n",
    "    if type == 'pretrain':\n",
    "        domain_classifier.eval()\n",
    "    model.eval()\n",
    "\n",
    "    test_mape, test_rmse, test_mae = list(), list(), list()\n",
    "\n",
    "    for i, (feat, label) in enumerate(test_dataloader.get_iterator()):\n",
    "        feat = torch.FloatTensor(feat).to(device)\n",
    "        label = torch.FloatTensor(label).to(device)\n",
    "        mask = select_mask(feat.shape[2])\n",
    "        if torch.sum(scaler.inverse_transform(label)) <= 0.001:\n",
    "            continue\n",
    "\n",
    "        pred = model(vec_pems04, vec_pems07, vec_pems08, feat, True)\n",
    "        pred = pred.transpose(1, 2).reshape((-1, feat.size(2)))\n",
    "        label = label.reshape((-1, label.size(2)))\n",
    "\n",
    "        mae_test, rmse_test, mape_test = masked_loss(scaler.inverse_transform(pred), scaler.inverse_transform(label),\n",
    "                                                     maskp=mask)\n",
    "\n",
    "        test_mae.append(mae_test.item())\n",
    "        test_rmse.append(rmse_test.item())\n",
    "        test_mape.append(mape_test.item())\n",
    "\n",
    "    test_rmse = np.mean(test_rmse)\n",
    "    test_mae = np.mean(test_mae)\n",
    "    test_mape = np.mean(test_mape)\n",
    "\n",
    "    return test_mae, test_rmse, test_mape\n",
    "\n",
    "\n",
    "def model_train(args, model, optimizer):\n",
    "    dur = []\n",
    "    epoch = 1\n",
    "    best = 999999999999999\n",
    "    acc = list()\n",
    "\n",
    "    step_per_epoch = train_dataloader.get_num_batch()\n",
    "    total_step = 200 * step_per_epoch\n",
    "\n",
    "    while epoch <= args.epoch:\n",
    "        start_step = epoch * step_per_epoch\n",
    "        if type == 'fine-tune' and epoch > 1000:\n",
    "            args.val = True\n",
    "        mae_train, rmse_train, mae_val, rmse_val, mae_test, rmse_test, mape_test, train_acc = train(dur, model,\n",
    "                                                                                                    optimizer,\n",
    "                                                                                                    total_step,\n",
    "                                                                                                    start_step)\n",
    "        log(f'Epoch {epoch} | acc_train: {train_acc: .4f} | mae_train: {mae_train: .4f} | rmse_train: {rmse_train: .4f} | mae_val: {mae_val: .4f} | rmse_val: {rmse_val: .4f} | mae_test: {mae_test: .4f} | rmse_test: {rmse_test: .4f} | mape_test: {mape_test: .4f} | Time(s) {dur[-1]: .4f}')\n",
    "        epoch += 1\n",
    "        acc.append(train_acc)\n",
    "        if mae_val <= best:\n",
    "            if type == 'fine-tune' and mae_val > 0.001:\n",
    "                best = mae_val\n",
    "                state = dict([('model', copy.deepcopy(model.state_dict())),\n",
    "                              ('optim', copy.deepcopy(optimizer.state_dict())),\n",
    "                              ('domain_classifier', copy.deepcopy(domain_classifier.state_dict()))])\n",
    "                cnt = 0\n",
    "            elif type == 'pretrain':\n",
    "                best = mae_val\n",
    "                state = dict([('model', copy.deepcopy(model.state_dict())),\n",
    "                              ('optim', copy.deepcopy(optimizer.state_dict())),\n",
    "                              ('domain_classifier', copy.deepcopy(domain_classifier.state_dict()))])\n",
    "                cnt = 0\n",
    "        else:\n",
    "            cnt += 1\n",
    "        if cnt == args.patience or epoch > args.epoch:\n",
    "            print(f'Stop!!')\n",
    "            print(f'Avg acc: {np.mean(acc)}')\n",
    "            break\n",
    "    print(\"Optimization Finished!\")\n",
    "    return state\n",
    "\n",
    "\n",
    "args = arg_parse(argparse.ArgumentParser())\n",
    "print(args)\n",
    "device = torch.device(\"cuda:\" + str(args.device) if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'device: {device}')\n",
    "if args.c != \"default\":\n",
    "    c = ast.literal_eval(args.c)\n",
    "    record = ResearchRecord(**c)\n",
    "    record_id = record.insert(__file__, get_timestamp(), args.__str__())\n",
    "torch.manual_seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "\n",
    "if args.labelrate > 100:\n",
    "    args.labelrate = 100\n",
    "\n",
    "from funcs import add_self_loop, idx_1d22d\n",
    "def load_all_adj(device):\n",
    "    dirs = \"./data/{}/{}_roads.npy\"\n",
    "    ny, chi, dc = None, None, None\n",
    "    for i in [\"NY\", \"CHI\", \"DC\"]:\n",
    "        t = dirs.format(i, i)\n",
    "        t = np.load(t)\n",
    "        t = t.reshape((t.shape[0] * t.shape[1], t.shape[0] * t.shape[1]))\n",
    "        t = np.where(t >= 1, 1, t)\n",
    "        t = add_self_loop(t)\n",
    "        for m in range(t.shape[0]):\n",
    "            for n in range(t.shape[1]):\n",
    "                a, b = idx_1d22d(m, t.shape)\n",
    "                c, d = idx_1d22d(n, t.shape)\n",
    "                dis = abs(a - c) + abs(b - d)\n",
    "                if t[m][n] - 0 > 1e-6 and dis != 0:\n",
    "                    t[m][n] = t[m][n] / dis\n",
    "        if t.shape[0] == 460:\n",
    "            ny = t\n",
    "        elif t.shape[0] == 476:\n",
    "            chi = t\n",
    "        elif t.shape[0] == 420:\n",
    "            dc = t\n",
    "\n",
    "    return torch.tensor(ny).to(device), torch.tensor(chi).to(device), torch.tensor(dc).to(device)\n",
    "\n",
    "\n",
    "\n",
    "adj_pems04, adj_pems07, adj_pems08 = load_all_adj(device)\n",
    "vec_pems04 = vec_pems07 = vec_pems08 = None, None, None\n",
    "dc = np.load(\"./data/DC/{}DC_{}.npy\".format(args.dataname, args.datatype))\n",
    "dcmask = dc.sum(0) > 0\n",
    "\n",
    "chi = np.load(\"./data/CHI/{}CHI_{}.npy\".format(args.dataname, args.datatype))\n",
    "chimask = chi.sum(0) > 0\n",
    "\n",
    "ny = np.load(\"./data/NY/{}NY_{}.npy\".format(args.dataname, args.datatype))\n",
    "nymask = ny.sum(0) > 0\n",
    "\n",
    "cur_dir = os.getcwd()\n",
    "if cur_dir[-2:] == 'sh':\n",
    "    cur_dir = cur_dir[:-2]\n",
    "\n",
    "pems04_emb_path = os.path.join('{}'.format(cur_dir), 'embeddings', 'node2vec', 'pems04',\n",
    "                               '{}_vecdim.pkl'.format(args.vec_dim))\n",
    "pems07_emb_path = os.path.join('{}'.format(cur_dir), 'embeddings', 'node2vec', 'pems07',\n",
    "                               '{}_vecdim.pkl'.format(args.vec_dim))\n",
    "pems08_emb_path = os.path.join('{}'.format(cur_dir), 'embeddings', 'node2vec', 'pems08',\n",
    "                               '{}_vecdim.pkl'.format(args.vec_dim))\n",
    "\n",
    "for i in [pems04_emb_path, pems07_emb_path, pems08_emb_path]:\n",
    "    a = i.split(\"/\")\n",
    "    b = []\n",
    "    for i in a:\n",
    "        if \"pkl\" in i:\n",
    "            continue\n",
    "        else:\n",
    "            b.append(i)\n",
    "    local_path_generate(folder_name=\"/\".join(b), create_folder_only=True)\n",
    "\n",
    "if os.path.exists(pems04_emb_path):\n",
    "    print(f'Loading pems04 embedding...')\n",
    "    vec_pems04 = torch.load(pems04_emb_path, map_location='cpu')\n",
    "    vec_pems04 = vec_pems04.to(device)\n",
    "else:\n",
    "    print(f'Generating pems04 embedding...')\n",
    "    args.dataset = '4'\n",
    "    vec_pems04, _ = generate_vector(adj_pems04.cpu().numpy(), args)\n",
    "    vec_pems04 = vec_pems04.to(device)\n",
    "    print(f'Saving pems04 embedding...')\n",
    "    torch.save(vec_pems04.cpu(), pems04_emb_path)\n",
    "\n",
    "if os.path.exists(pems07_emb_path):\n",
    "    print(f'Loading pems07 embedding...')\n",
    "    vec_pems07 = torch.load(pems07_emb_path, map_location='cpu')\n",
    "    vec_pems07 = vec_pems07.to(device)\n",
    "else:\n",
    "    print(f'Generating pems07 embedding...')\n",
    "    args.dataset = '7'\n",
    "    vec_pems07, _ = generate_vector(adj_pems07.cpu().numpy(), args)\n",
    "    vec_pems07 = vec_pems07.to(device)\n",
    "    print(f'Saving pems07 embedding...')\n",
    "    torch.save(vec_pems07.cpu(), pems07_emb_path)\n",
    "\n",
    "if os.path.exists(pems08_emb_path):\n",
    "    print(f'Loading pems08 embedding...')\n",
    "    vec_pems08 = torch.load(pems08_emb_path, map_location='cpu')\n",
    "    vec_pems08 = vec_pems08.to(device)\n",
    "else:\n",
    "    print(f'Generating pems08 embedding...')\n",
    "    args.dataset = '8'\n",
    "    vec_pems08, _ = generate_vector(adj_pems08.cpu().numpy(), args)\n",
    "    vec_pems08 = vec_pems08.to(device)\n",
    "    print(f'Saving pems08 embedding...')\n",
    "    torch.save(vec_pems08.cpu(), pems08_emb_path)\n",
    "\n",
    "print(f'Successfully load embeddings, 4: {vec_pems04.shape}, 7: {vec_pems07.shape}, 8: {vec_pems08.shape}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def masked_loss(y_pred, y_true, maskp=None, weight=None):\n",
    "\n",
    "    mask_true = (y_true > 0.01).float()\n",
    "    mask_pred = (y_pred > 0.01).float()\n",
    "    mask = torch.mul(mask_true, mask_pred)\n",
    "    if mask.mean() > 1e-6:\n",
    "        mask /= mask.mean()\n",
    "    else:\n",
    "        mask = (torch.ones(mask.shape) * 0.01).to(mask.device)\n",
    "    mae_loss = torch.abs(y_pred - y_true)\n",
    "    mse_loss = torch.square(y_pred - y_true)\n",
    "    y_true = torch.where(y_true.abs() < torch.tensor(0.01, dtype=y_true.dtype, device=y_true.device), torch.tensor(0, dtype=y_true.dtype, device=y_true.device), y_true)\n",
    "    mae_pe = mae_loss[:, torch.from_numpy(maskp).to(y_pred.device).reshape((-1))]\n",
    "    ytrue_pe = y_true[:, torch.from_numpy(maskp).to(y_pred.device).reshape((-1))]\n",
    "    mape_loss = mae_pe / ytrue_pe\n",
    "    # mape_loss = mae_loss / y_true.abs()\n",
    "    mape_loss = torch.where(torch.isinf(mape_loss), torch.tensor(0, dtype=y_true.dtype, device=y_true.device), mape_loss)\n",
    "    if maskp is not None:\n",
    "        mask = maskp\n",
    "    if weight is None:\n",
    "        mae_loss = mae_loss[:, torch.from_numpy(maskp).to(y_pred.device).reshape((-1))]\n",
    "    else:\n",
    "        mmmm = (torch.from_numpy(maskp).to(y_pred.device).reshape((-1)))\n",
    "        mae_loss = mae_loss[:, mmmm]\n",
    "        mae_loss = torch.mul(mae_loss.reshape(y_true.shape[0], -1), weight.repeat((y_true.shape[0], 1)))\n",
    "    mse_loss = mse_loss[:, torch.from_numpy(maskp).to(y_pred.device).reshape((-1))]\n",
    "    mape_loss = mape_loss.sum() / torch.count_nonzero(mape_loss)\n",
    "    mae_loss[mae_loss != mae_loss] = 0\n",
    "    mse_loss[mse_loss != mse_loss] = 0\n",
    "    mape_loss[mape_loss != mape_loss] = 0\n",
    "\n",
    "    return mae_loss.mean(), torch.sqrt(mse_loss.mean()), mape_loss\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "domain_criterion = torch.nn.NLLLoss()\n",
    "domain_classifier = Domain_classifier_DG(num_class=3, encode_dim=args.enc_dim)\n",
    "\n",
    "domain_classifier = domain_classifier.to(device)\n",
    "state = g = None, None\n",
    "\n",
    "batch_seen = 0\n",
    "cur_dir = os.getcwd()\n",
    "if cur_dir[-2:] == 'sh':\n",
    "    cur_dir = cur_dir[:-2]\n",
    "assert args.model in [\"DASTNet\"]\n",
    "\n",
    "bak_epoch = args.epoch\n",
    "bak_val = args.val\n",
    "bak_test = args.test\n",
    "type = 'pretrain'\n",
    "pretrain_model_path = os.path.join('{}'.format(cur_dir), 'pretrained', 'transfer_models',\n",
    "                                   '{}'.format(args.dataset), '{}_prelen'.format(args.pre_len),\n",
    "                                   'flow_model4_{}_epoch_{}{}{}{}.pkl'.format(args.model, args.epoch,\n",
    "                                                                            args.dataname,\n",
    "                                                                            args.datatype,\n",
    "                                                                              get_timestamp(\"\")))\n",
    "\n",
    "a = pretrain_model_path.split(\"/\")\n",
    "b = []\n",
    "for i in a:\n",
    "    if \"pkl\" not in i:\n",
    "        b.append(i)\n",
    "local_path_generate(\"/\".join(b), create_folder_only=True)\n",
    "args.dataset = \"8\"\n",
    "if os.path.exists(pretrain_model_path):\n",
    "    print(f'Loading pretrained model at {pretrain_model_path}')\n",
    "    state = torch.load(pretrain_model_path, map_location='cpu')\n",
    "else:\n",
    "    print(f'No existing pretrained model at {pretrain_model_path}')\n",
    "    args.val = args.test = False\n",
    "    datasets = [\"4\"]\n",
    "    dataset_bak = args.dataset\n",
    "    labelrate_bak = args.labelrate\n",
    "    args.labelrate = 100\n",
    "    dataset_count = 0\n",
    "\n",
    "    for dataset in [item for item in datasets if item not in [dataset_bak]]:\n",
    "        dataset_count = dataset_count + 1\n",
    "\n",
    "        print(\n",
    "            f'\\n\\n****************************************************************************************************************')\n",
    "        print(f'dataset: {dataset}, model: {args.model}, pre_len: {args.pre_len}, labelrate: {args.labelrate}')\n",
    "        print(\n",
    "            f'****************************************************************************************************************\\n\\n')\n",
    "\n",
    "        if dataset == '4':\n",
    "            g = vec_pems04\n",
    "        elif dataset == '7':\n",
    "            g = vec_pems07\n",
    "        elif dataset == '8':\n",
    "            g = vec_pems08\n",
    "\n",
    "        args.dataset = dataset\n",
    "        train_dataloader, val_dataloader, test_dataloader, adj, max_speed, scaler = load_data(args)\n",
    "        model = DASTNet(input_dim=args.vec_dim, hidden_dim=args.hidden_dim, encode_dim=args.enc_dim,\n",
    "                        device=device, batch_size=args.batch_size, etype=args.etype, pre_len=args.pre_len,\n",
    "                        dataset=args.dataset, ft_dataset=dataset_bak,\n",
    "                        adj_pems04=adj_pems04, adj_pems07=adj_pems07, adj_pems08=adj_pems08).to(device)\n",
    "        optimizer = optim.SGD([{'params': model.parameters()},\n",
    "                               {'params': domain_classifier.parameters()}], lr=args.learning_rate, momentum=0.8)\n",
    "\n",
    "        if dataset_count != 1:\n",
    "            model.load_state_dict(state['model'])\n",
    "            optimizer.load_state_dict(state['optim'])\n",
    "\n",
    "        state = model_train(args, model, optimizer)\n",
    "\n",
    "    print(f'Saving model to {pretrain_model_path} ...')\n",
    "    torch.save(state, pretrain_model_path)\n",
    "    args.dataset = dataset_bak\n",
    "    args.labelrate = labelrate_bak\n",
    "    args.val = bak_val\n",
    "    args.test = bak_test\n",
    "\n",
    "type = 'fine-tune'\n",
    "args.epoch = args.fine_epoch\n",
    "\n",
    "print(f'\\n\\n*******************************************************************************************')\n",
    "print(\n",
    "    f'dataset: {args.dataset}, model: {args.model}, pre_len: {args.pre_len}, labelrate: {args.labelrate}, seed: {args.division_seed}')\n",
    "print(f'*******************************************************************************************\\n\\n')\n",
    "\n",
    "if args.dataset == '4':\n",
    "    g = vec_pems04\n",
    "elif args.dataset == '7':\n",
    "    g = vec_pems07\n",
    "elif args.dataset == '8':\n",
    "    g = vec_pems08\n",
    "\n",
    "train_dataloader, val_dataloader, test_dataloader, adj, max_speed, scaler = load_data(args, cut=True)\n",
    "model = DASTNet(input_dim=args.vec_dim, hidden_dim=args.hidden_dim, encode_dim=args.enc_dim,\n",
    "                device=device, batch_size=args.batch_size, etype=args.etype, pre_len=args.pre_len,\n",
    "                dataset=args.dataset, ft_dataset=args.dataset,\n",
    "                adj_pems04=adj_pems04, adj_pems07=adj_pems07, adj_pems08=adj_pems08).to(device)\n",
    "optimizer = optim.SGD([{'params': model.parameters()},\n",
    "                       {'params': domain_classifier.parameters()}], lr=args.learning_rate, momentum=0.8)\n",
    "model.load_state_dict(state['model'])\n",
    "optimizer.load_state_dict(state['optim'])\n",
    "\n",
    "if args.labelrate != 0:\n",
    "    test_state = model_train(args, model, optimizer)\n",
    "    model.load_state_dict(test_state['model'])\n",
    "    optimizer.load_state_dict(test_state['optim'])\n",
    "\n",
    "test_mae, test_rmse, test_mape = test()\n",
    "print(f'mae: {test_mae: .4f}, rmse: {test_rmse: .4f}, mape: {test_mape * 100: .4f}\\n\\n')\n",
    "if args.c != \"default\":\n",
    "    if args.need_remark == 1:\n",
    "        record.update(record_id, get_timestamp(),\n",
    "                      \"%.4f,%.4f,%.4f\" %\n",
    "                      (test_rmse, test_mae, test_mape * 100),\n",
    "                      remark=\"{}C {} {} {} {}\".format(\"2\" if args.need_third == 0 else \"3\", str(args.data_amount),\n",
    "                                                      args.dataname, args.datatype, args.machine_code))\n",
    "    else:\n",
    "        record.update(record_id, get_timestamp(),\n",
    "                      \"%.4f,%.4f, %.4f\" %\n",
    "                      (test_rmse, test_mae, test_mape * 100),\n",
    "                      remark=\"{}\".format(args.machine_code))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.17300966]\n",
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "class StandardScaler:\n",
    "    \"\"\"\n",
    "    Standard the input\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def transform(self, data):\n",
    "        return (data - self.mean) / self.std\n",
    "\n",
    "    def inverse_transform(self, data):\n",
    "        return (data * self.std) + self.mean\n",
    "\n",
    "s = StandardScaler(np.array([0.7355654846185]), np.array([4.251586181358]))\n",
    "a = s.transform(np.array([0.0]))\n",
    "print(a)\n",
    "print(s.inverse_transform(a))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "yt = torch.Tensor([1.0, 2.0, 0.0, 3.0 ,3.0])\n",
    "yp = torch.Tensor([1.5, 0.008, 0.0, 3.0 ,3.0])\n",
    "def masked_loss(y_pred, y_true):\n",
    "    mask_true = (y_true > 0.01).float()\n",
    "\n",
    "    mask_pred = (y_pred > 0.01).float()\n",
    "\n",
    "    mask = torch.mul(mask_true, mask_pred)\n",
    "\n",
    "    mask /= mask.mean()\n",
    "    print(\"mask\", mask)\n",
    "    mae_loss = torch.abs(y_pred - y_true)\n",
    "    mse_loss = torch.square(y_pred - y_true)\n",
    "    mape_loss = mae_loss / y_true\n",
    "    print(mape_loss)\n",
    "    mae_loss = mae_loss * mask\n",
    "    mse_loss = mse_loss * mask\n",
    "    mape_loss = mape_loss * mask\n",
    "    print(mape_loss)\n",
    "    mae_loss[mae_loss != mae_loss] = 0\n",
    "    mse_loss[mse_loss != mse_loss] = 0\n",
    "    mape_loss[mape_loss != mape_loss] = 0\n",
    "    print(mape_loss)\n",
    "    return mae_loss.mean(), torch.sqrt(mse_loss.mean()), mape_loss.mean()\n",
    "print(masked_loss(yp, yt))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
